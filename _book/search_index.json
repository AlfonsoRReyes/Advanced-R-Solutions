[
["index.html", "Advanced R Solutions Prerequisites", " Advanced R Solutions Malte Grosser, Henning Bumann, Peter Hurford &amp; Robert Krzyzanowski 2017-07-20 Prerequisites This book aims to contribute solutions to Hadley Wickham’s book Advanced R. It is planned to finish until July 2017. The code can be found on github. The date of the exercise versions in Hadley’s book is January 25th 2017. This work by Malte Grosser, Henning Bumann, Peter Hurford &amp; Robert Krzyzanowski is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License "],
["data-structures.html", "1 Data structures 1.1 Vectors 1.2 Attributes 1.3 Matrices and arrays 1.4 Data frames", " 1 Data structures 1.1 Vectors Q: What are the six types of atomic vector? How does a list differ from an atomic vector? A: The six types are logical, integer, double, character, complex and raw. The elements of a list don’t have to be of the same type. Q: What makes is.vector() and is.numeric() fundamentally different to is.list() and is.character()? A: The first two tests don’t check for a specific type. Q: Test your knowledge of vector coercion rules by predicting the output of the following uses of c(): c(1, FALSE) # will be coerced to numeric -&gt; 1 0 c(&quot;a&quot;, 1) # will be coerced to character -&gt; &quot;a&quot; &quot;1&quot; c(list(1), &quot;a&quot;) # will be coerced to a list (since not all elements are atomic) # with two elements of type double and character c(TRUE, 1L) # will be coerced to integer -&gt; 1 1 Q: Why do you need to use unlist() to convert a list to an atomic vector? Why doesn’t as.vector() work? A: To get rid of (flatten) the nested structure. Recall that lists are considered vectors, so as.vector() will leave it the same. as.vector() can be used to convert a non-recursive list to an atomic vector if the desired mode is passed explicitly. But the core problem is that as.vector() cannot handle recursion within lists. Only unlist() (or purrr::flatten() functions) can do that. Q: Why is 1 == &quot;1&quot; true? Why is -1 &lt; FALSE true? Why is &quot;one&quot; &lt; 2 false? A: These operators are all functions which coerce their arguments (in these cases) to character, double and character. To enlighten the latter case: “one” comes after “2” in ASCII. Q: Why is the default missing value, NA, a logical vector? What’s special about logical vectors? (Hint: think about c(FALSE, NA_character_).) A: It is a practical thought. When you combine NAs in c() with other atomic types they will be coerced like TRUE and FALSE to integer (NA_integer_), double (NA_real_), complex (NA_complex_) and character (NA_character_). Recall that in R there is a hierarchy of recursion that goes logical -&gt; integer -&gt; double -&gt; character. If NA were, for example, a character, including NA in a set of integers or logicals would result in them getting coerced to characters which would be undesirable. Making NA a logical means that involving an NA in a dataset (which happens often) will not result in coercion. 1.2 Attributes Q: An early draft used this code to illustrate structure(): structure(1:5, comment = &quot;my attribute&quot;) #&gt; [1] 1 2 3 4 5 But when you print that object you don’t see the comment attribute. Why? Is the attribute missing, or is there something else special about it? (Hint: try using help.) A: From the help of comment (?comment): Contrary to other attributes, the comment is not printed (by print or print.default). Also from the help of attributes (?attributes): Note that some attributes (namely class, comment, dim, dimnames, names, row.names and tsp) are treated specially and have restrictions on the values which can be set. Q: What happens to a factor when you modify its levels? f1 &lt;- factor(letters) levels(f1) &lt;- rev(levels(f1)) A: Both, the entries of the factor and also its levels are being reversed: f1 #&gt; [1] z y x w v u t s r q p o n m l k j i h g f e d c b a #&gt; Levels: z y x w v u t s r q p o n m l k j i h g f e d c b a Q: What does this code do? How do f2 and f3 differ from f1? f2 &lt;- rev(factor(letters)) # changes only the entries of the factor f3 &lt;- factor(letters, levels = rev(letters)) # changes only the levels of the factor A: Unlike f1 f2 and f3 change only one thing. They change the order of the factor or its levels, but not both at the same time. 1.3 Matrices and arrays Q: What does dim() return when applied to a vector? A: NULL Q: If is.matrix(x) is TRUE, what will is.array(x) return? A: TRUE, as also documented in ?array: A two-dimensional array is the same thing as a matrix. Q: How would you describe the following three objects? What makes them different to 1:5? x1 &lt;- array(1:5, c(1, 1, 5)) # 1 row, 1 column, 5 in third dimension x2 &lt;- array(1:5, c(1, 5, 1)) # 1 row, 5 columns, 1 in third dimension x3 &lt;- array(1:5, c(5, 1, 1)) # 5 rows, 1 column, 1 in third dimension A: They are of class array and so they have a dim attribute. 1.4 Data frames Q: What attributes does a data frame possess? A: names, row.names and class. Q: What does as.matrix() do when applied to a data frame with columns of different types? A: From ?as.matrix: The method for data frames will return a character matrix if there is only atomic columns and any non-(numeric/logical/complex) column, applying as.vector to factors and format to other non-character columns. Otherwise the usual coercion hierarchy (logical &lt; integer &lt; double &lt; complex) will be used, e.g., all-logical data frames will be coerced to a logical matrix, mixed logical-integer will give a integer matrix, etc. Q: Can you have a data frame with 0 rows? What about 0 columns? A: Yes, you can create them easily. Also both dimensions can be 0: # here we use the recycling rules for logical subsetting, but you could # also subset with 0, a negative index or a zero length atomic (i.e. # logical(0), character(0), integer(0), double(0)) iris[FALSE,] #&gt; [1] Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;0 rows&gt; (or 0-length row.names) iris[ , FALSE] # or iris[FALSE] #&gt; data frame with 0 columns and 150 rows iris[FALSE, FALSE] # or just data.frame() #&gt; data frame with 0 columns and 0 rows "],
["subsetting.html", "2 Subsetting 2.1 Data types 2.2 Subsetting operators 2.3 Applications", " 2 Subsetting 2.1 Data types Q: Fix each of the following common data frame subsetting errors: mtcars[mtcars$cyl = 4, ] # = -&gt; == mtcars[-1:4, ] # -1:4 -&gt; -(1:4) mtcars[mtcars$cyl &lt;= 5] # &quot;,&quot; is missing mtcars[mtcars$cyl == 4 | 6, ] # 6 -&gt; mtcars$cyl == 6 Q: Why does x &lt;- 1:5; x[NA] yield five missing values? (Hint: why is it different from x[NA_real_]?) A: NA is of class logical, so x[NA] becomes recycled to x[NA, NA, NA, NA, NA]. Since subsetting an atomic with NA leads to an NA, you will get 5 of them returned. (Note that the recycling won’t happen, if you subset with NA_real_, NA_integer, NA_character or NA_complex. In fact the letter gives an error). Q: What does upper.tri() return? How does subsetting a matrix with it work? Do we need any additional subsetting rules to describe its behaviour? x &lt;- outer(1:5, 1:5, FUN = &quot;*&quot;) x[upper.tri(x)] A: upper.tri() has really intuitive source code. It coerces its input to a matrix and returns a logical matrix. Hence describing it’s behaviour for the use of subsetting is based on everything that applies to subsetting with logical matrices. Q: Why does mtcars[1:20] return an error? How does it differ from the similar mtcars[1:20, ]? A: In the first case mtcars is subsetted with a vector and the statement should return a data.frame of the first 20 columns in mtcars (this is like listsubsetting in the sense, that each element is a column and the result is typestable). Since mtcars only has 11 columns, the index is out of bounds, which explains the error. The biggest difference of mtcars[1:20, ] to the former case, is that now mtcars is subsetted with two vectors. In this case you will get returned the first 20 rows and all columns (like subsetting a matrix). Q: Implement your own function that extracts the diagonal entries from a matrix (it should behave like diag(x) where x is a matrix). A: First we copy the relevant part of the source code from the diag() function: function (x = 1, nrow, ncol){ if (is.matrix(x)) { if (nargs() &gt; 1L) # this and the next line will be dropped stop(&quot;&#39;nrow&#39; or &#39;ncol&#39; cannot be specified when &#39;x&#39; is a matrix&quot;) if ((m &lt;- min(dim(x))) == 0L) return(vector(typeof(x), 0L)) y &lt;- x[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)] nms &lt;- dimnames(x) if (is.list(nms) &amp;&amp; !any(sapply(nms, is.null)) &amp;&amp; identical((nm &lt;- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)])) names(y) &lt;- nm return(y) } } In the next step we drop the unncessary nrow and ncol argument and the related code in the 3rd and 4th line: diag_v &lt;- function (x = 1) { if (is.matrix(x)) { if ((m &lt;- min(dim(x))) == 0L) return(vector(typeof(x), 0L)) y &lt;- x[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)] # subsetting with a vector nms &lt;- dimnames(x) if (is.list(nms) &amp;&amp; !any(sapply(nms, is.null)) &amp;&amp; identical((nm &lt;- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)])) names(y) &lt;- nm return(y) } } If we look for the idea to capture the diagonal elements, we can see that the input matrix is subsetted with a vector, so we called this function diag_v(). Of course we can implement our own function diag_m(), where we subset with a matrix. diag_m &lt;- function (x = 1) { if (is.matrix(x)) { if ((m &lt;- min(dim(x))) == 0L) return(vector(typeof(x), 0L)) y &lt;- x[matrix(c(1:m,1:m), m)] # subsetting with a matrix nms &lt;- dimnames(x) if (is.list(nms) &amp;&amp; !any(sapply(nms, is.null)) &amp;&amp; identical((nm &lt;- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)])) names(y) &lt;- nm return(y) } } Now we can check if we get the same results as the original function and also compare the speed. Therefore we convert the relatively large diamonds dataset from the ggplot2 package into a matrix. diamonds_m &lt;- as.matrix(ggplot2::diamonds) stopifnot(all.equal(diag(diamonds_m), diag_v(diamonds_m), diag_m(diamonds_m))) # our functions succeed the little test microbenchmark::microbenchmark( diag(diamonds_m), diag_v(diamonds_m), diag_m(diamonds_m) ) #&gt; Unit: microseconds #&gt; expr min lq mean median uq max neval #&gt; diag(diamonds_m) 12.464 13.929 15.81398 14.297 15.029 129.763 100 #&gt; diag_v(diamonds_m) 12.830 13.563 14.48710 14.296 14.846 24.927 100 #&gt; diag_m(diamonds_m) 14.663 15.762 115.80829 16.496 17.229 9880.293 100 #&gt; cld #&gt; a #&gt; a #&gt; a The original function seems to be a little bit faster than the trimmed and our matrix version. Maybe this is due to compiling issues diag_c &lt;- compiler::cmpfun(diag) diag_v_c &lt;- compiler::cmpfun(diag_v) diag_m_c &lt;- compiler::cmpfun(diag_m) # Now we can make a fair comparison of the speed: microbenchmark::microbenchmark( diag_c(diamonds_m), diag_v_c(diamonds_m), diag_m_c(diamonds_m) ) #&gt; Unit: microseconds #&gt; expr min lq mean median uq max neval #&gt; diag_c(diamonds_m) 12.830 14.297 18.54854 15.029 19.612 112.535 100 #&gt; diag_v_c(diamonds_m) 13.196 14.113 18.09037 14.663 20.162 67.081 100 #&gt; diag_m_c(diamonds_m) 14.663 16.129 19.19374 16.863 21.811 42.888 100 #&gt; cld #&gt; a #&gt; a #&gt; a We can see that our diag_m() version is only a little bit slower than the original version. However the source code of the matrix version could be a bit easier to read. We could also take an idea from the source code of upper.tri() and subset with a logical vector (but it turns out to be really slow): diag_lv &lt;- function (x = 1) { if (is.matrix(x)) { if ((m &lt;- min(dim(x))) == 0L) return(vector(typeof(x), 0L)) y &lt;- x[row(x) == col(x)] nms &lt;- dimnames(x) if (is.list(nms) &amp;&amp; !any(sapply(nms, is.null)) &amp;&amp; identical((nm &lt;- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)])) names(y) &lt;- nm return(y) } } compile it and compare it with the other versions diag_lv_c &lt;- compiler::cmpfun(diag_lv) stopifnot(all.equal(diag(diamonds_m), diag_v_c(diamonds_m), diag_m_c(diamonds_m), diag_lv_c(diamonds_m))) # our functions succeed the little test microbenchmark::microbenchmark( diag(diamonds_m), diag_v_c(diamonds_m), diag_m_c(diamonds_m), diag_lv_c(diamonds_m) ) #&gt; Unit: microseconds #&gt; expr min lq mean median uq #&gt; diag(diamonds_m) 13.930 15.7625 23.07928 20.3445 27.6760 #&gt; diag_v_c(diamonds_m) 13.564 15.3960 21.13282 18.6960 25.1100 #&gt; diag_m_c(diamonds_m) 15.763 17.2290 26.56892 27.3090 33.1745 #&gt; diag_lv_c(diamonds_m) 2481.621 2648.5890 3949.52209 3815.1700 5025.0055 #&gt; max neval cld #&gt; 94.940 100 a #&gt; 46.554 100 a #&gt; 51.319 100 a #&gt; 6952.568 100 b Q: What does df[is.na(df)] &lt;- 0 do? How does it work? A: It replaces all NAs within df with the value 0. is.na(df) returns a logical matrix which is used to subset df. Since you can combine subsetting and assignment (specifically [&lt;- is called), only the matched part of df (the NAs) is replaced with 0 entries. 2.2 Subsetting operators Q: Given a linear model, e.g., mod &lt;- lm(mpg ~ wt, data = mtcars), extract the residual degrees of freedom. Extract the R squared from the model summary (summary(mod)) A: Since mod is of type list we can expect several possibilities: mod$df.residual # simplifying output mod$df.r # simplifying output with partial matching mod[&quot;df.residual&quot;] # preserving list output (without partial matching) mod[[&quot;df.residual&quot;]] # simplifying output (without partial matching) The same states for summary(mod), so we can use for example: summary(mod)$r.squared (To get tidy output from r-models in general also the broom package is a good alternative). 2.3 Applications Q: How would you randomly permute the columns of a data frame? (This is an important technique in random forests.) Can you simultaneously permute the rows and columns in one step? A: Combine `[` with the sample() function: iris[sample(ncol(iris))] # permute columns iris[sample(nrow(iris)), sample(ncol(iris)), drop = FALSE] # permute both at the same time Q: How would you select a random sample of m rows from a data frame? What if the sample had to be contiguous (i.e., with an initial row, a final row, and every row in between)? A: For example m=10 iris[sample(nrow(iris), m), , drop = FALSE] # Blockversion start &lt;- sample(nrow(iris) - m + 1, 1) end &lt;- start + m - 1 iris[start:end, , drop = FALSE] Q: How could you put the columns in a data frame in alphabetical order? A: We can sort the names and subset by name: iris[sort(names(iris))] "],
["functions.html", "3 Functions 3.1 Function components 3.2 Lexical Scoping 3.3 Function arguments 3.4 Special calls 3.5 Return Values", " 3 Functions 3.1 Function components Q: What function allows you to tell if an object is a function? What function allows you to tell if a function is a primitive function? A: You can test objects with is.function() and is.primitive(). Q: This code makes a list of all functions in the base package. objs &lt;- mget(ls(&quot;package:base&quot;), inherits = TRUE) funs &lt;- Filter(is.function, objs) Use it to answer the following questions: Which base function has the most arguments? How many base functions have no arguments? What’s special about those functions? How could you adapt the code to find all primitive functions? A: First we create a named vector that returns the number of arguments per function and then we subset it with the index of it’s maximum entry: f_arg_length &lt;- sapply(funs, function(x) length(formals(x))) f_arg_length[which.max(f_arg_length)] #&gt; scan #&gt; 22 We check the number of functions with formals() returning 0 or NULL. Then we will see, that all of these functions have formals equal to NULL, which means, that they should be primitive functions. sum(sapply(funs, function(x) is.null(formals(x)) | length(formals(x)) == 0)) #&gt; [1] 226 sum(sapply(funs, function(x) !is.null(formals(x)) &amp; length(formals(x)) == 0)) #&gt; [1] 0 sum(sapply(funs, function(x) is.null(formals(x)))) #&gt; [1] 226 sum(sapply(funs, function(x) is.null(formals(x)) &amp; is.primitive(x))) #&gt; [1] 183 Hence not all functions with formals equal to NULL are primitive functions, there must be non primitive functions with this property too. Change the predicate in Filter to is.primitive: funs &lt;- Filter(is.primitive, objs) Q: What are the three important components of a function? A: body(), formals() and environment(). There is one exception to the rule that functions have three components. Primitive functions, like sum(), call C code directly with .Primitive() and contain no R code. Therefore their formals(), body(), and environment() are all NULL. Q: When does printing a function not show what environment it was created in? A: When the function is a primitive or it was created in the global environment. 3.2 Lexical Scoping Q: What does the following code return? Why? What does each of the three c’s mean? c &lt;- 10 c(c = c) A: A named vector c, which first field has the value 10 and the name “c”. The first “c” is the c() function, the second is the name of the first entry and the third is the value of the first entry. Q: What are the four principles that govern how R looks for values? A: As stated in the book: There are four basic principles behind R’s implementation of lexical scoping: name masking (Variables are evaluated according to the highest-precedence environment in which they are defined, starting from the local environment and working upwards through each parent environment.) functions vs. variables (For all intents and purposes, function names are evaluated by the same rules as for variables. If it is implicit that a function is being used, R will ignore objects with the same name that are not functions.) a fresh start (Every time a function is called, a new environment is created to host execution.) dynamic lookup (R looks for values, when a function is run. Not when it is created) Q: What does the following function return? Make a prediction before running the code yourself. f &lt;- function(x) { f &lt;- function(x) { f &lt;- function(x) { x ^ 2 } f(x) + 1 } f(x) * 2 } f(10) A: 202 3.3 Function arguments Q: Clarify the following list of odd function calls: x &lt;- sample(replace = TRUE, 20, x = c(1:10, NA)) # -&gt; sample(x = c(1:10, NA), size = 20, replace = TRUE) y &lt;- runif(min = 0, max = 1, 20) # -&gt; runif(n = 20, min = 0, max = 1) cor(m = &quot;k&quot;, y = y, u = &quot;p&quot;, x = x) # -&gt; cor(x = x, y = y, use = &quot;pairwise.complete.obs&quot;, method = &quot;kendall&quot;) Q: What does this function return? Why? Which principle does it illustrate? f1 &lt;- function(x = {y &lt;- 1; 2}, y = 0) { x + y } f1() A: It returns 3 and illustrates lazy evaluation. As you can see, y becomes 1, but only when x is evaluated (before y) inside the function (otherwise it is 0): f2 &lt;- function(x = {y &lt;- 1; 2}, y = 0) { y } f2() #&gt; [1] 0 Note that funny things can happen if we switch the evaluation order (even within one line) f3 &lt;- function(x = {y &lt;- 1; 2}, y = 0) { y + x } f3() #&gt; [1] 2 or we evaluate y once before and once after the evaluation of x f4 &lt;- function(x = {y &lt;- 1; 2}, y = 0) { y_before_x &lt;- y x y_after_x &lt;- y c(y_before_x, y_after_x) } f4() #&gt; [1] 0 1 Q: What does this function return? Why? Which principle does it illustrate? f2 &lt;- function(x = z) { z &lt;- 100 x } f2() A: 100, lazy evaluation. If we changed the order of z &lt;- 100 and x inside the body of the function, we would get an error, while assigning z to x, because z wouldn`t be defined. 3.4 Special calls Q: Create a list of all the replacement functions found in the base package. Which ones are primitive functions? A: We can find replacementfunctions by searching for functions that end on “&lt;-”: repls &lt;- funs[grepl(&quot;&lt;-$&quot;, names(funs))] names(repls) #&gt; [1] &quot;$&lt;-&quot; &quot;@&lt;-&quot; &quot;[[&lt;-&quot; #&gt; [4] &quot;[&lt;-&quot; &quot;&lt;-&quot; &quot;&lt;&lt;-&quot; #&gt; [7] &quot;attr&lt;-&quot; &quot;attributes&lt;-&quot; &quot;body&lt;-&quot; #&gt; [10] &quot;class&lt;-&quot; &quot;colnames&lt;-&quot; &quot;comment&lt;-&quot; #&gt; [13] &quot;diag&lt;-&quot; &quot;dim&lt;-&quot; &quot;dimnames&lt;-&quot; #&gt; [16] &quot;Encoding&lt;-&quot; &quot;environment&lt;-&quot; &quot;formals&lt;-&quot; #&gt; [19] &quot;is.na&lt;-&quot; &quot;length&lt;-&quot; &quot;levels&lt;-&quot; #&gt; [22] &quot;mode&lt;-&quot; &quot;mostattributes&lt;-&quot; &quot;names&lt;-&quot; #&gt; [25] &quot;oldClass&lt;-&quot; &quot;parent.env&lt;-&quot; &quot;regmatches&lt;-&quot; #&gt; [28] &quot;row.names&lt;-&quot; &quot;rownames&lt;-&quot; &quot;split&lt;-&quot; #&gt; [31] &quot;storage.mode&lt;-&quot; &quot;substr&lt;-&quot; &quot;substring&lt;-&quot; #&gt; [34] &quot;units&lt;-&quot; names(Filter(is.primitive, repls)) #&gt; [1] &quot;$&lt;-&quot; &quot;@&lt;-&quot; &quot;[[&lt;-&quot; &quot;[&lt;-&quot; #&gt; [5] &quot;&lt;-&quot; &quot;&lt;&lt;-&quot; &quot;attr&lt;-&quot; &quot;attributes&lt;-&quot; #&gt; [9] &quot;class&lt;-&quot; &quot;dim&lt;-&quot; &quot;dimnames&lt;-&quot; &quot;environment&lt;-&quot; #&gt; [13] &quot;length&lt;-&quot; &quot;levels&lt;-&quot; &quot;names&lt;-&quot; &quot;oldClass&lt;-&quot; #&gt; [17] &quot;storage.mode&lt;-&quot; Q: What are valid names for user-created infix functions? A: From the textbook: All user-created infix functions must start and end with % … they can contain any sequence of characters (except “%”, of course). Q: Create an infix xor() operator. A: `%xor_%` &lt;- function(a, b){ (a | b) &amp; !(a &amp; b) } Q: Create infix versions of the set functions intersect(), union(), and setdiff(). A: `%intersect_%` &lt;- function(a, b){ unique(a[a %in% b]) } `%union_%` &lt;- function(a, b){ unique(c(a, b)) } `%setdiff_%` &lt;- function(a, b){ unique(a[! a %in% b]) } Q: Create a replacement function that modifies a random location in a vector. A: `random_replacement&lt;-` &lt;- function(x, value){ x[sample(length(x), 1)] &lt;- value x } 3.5 Return Values Q: How does the chdir parameter of source() compare to in_dir()? Why might you prefer one approach to the other? The in_dir() approach was given in the book as in_dir &lt;- function(dir, code) { old &lt;- setwd(dir) on.exit(setwd(old)) force(code) } A: in_dir() takes a path to a working directory as an argument. At the beginning of the function the working directory is changed to this specification and with a call to on.exit it is guranteed, that when the function finishes the working directory also equals to this specification. In source() you need the chdir argument to specify, if the working directory should be changed during the evaluation to the file argument, if this is a pathname. The difference in source() is, that the actual working directory as output of getwd() is saved to set it in on.exit before changing the directory to the pathname (given to the file argument) for the rest of the execution of the source() function. The methodology used in in_dir() is more free, allowing more programmer customization, whereas the methodology in chdir() is more constrained, reducing programmer error. This is generally a trade-off that different people will want to take different sides of, usually depending on how much they know what they are doing. Q: What function undoes the action of library()? How do you save and restore the values of options() and par()? A: Use detach() with &quot;package:packagename&quot; as first argument. Type options() (or par()) to see the actual settings and save them via old_opt &lt;- options()[[&quot;optionname&quot;]] (or old_par &lt;- par()[[&quot;parname&quot;]]). For options you could also use getOption() with &quot;optionname&quot; as argument. To restore (or overwriting) just use options(optionname = old_opt) or par(parname = old_par). Q: Write a function that opens a graphics device, runs the supplied code, and closes the graphics device (always, regardless of whether or not the plotting code worked). A: plot_pdf &lt;- function(code){ pdf(&quot;test.pdf&quot;) on.exit(dev.off()) code } Q: We can use on.exit() to implement a simple version of capture.output(). capture.output2 &lt;- function(code) { temp &lt;- tempfile() on.exit(file.remove(temp), add = TRUE) sink(temp) on.exit(sink(), add = TRUE) force(code) readLines(temp) } capture.output2(cat(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, sep = &quot;\\n&quot;)) #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; Compare capture.output() to capture.output2(). How do the functions differ? What features have I removed to make the key ideas easier to see? How have I rewritten the key ideas to be easier to understand? A: Using body(capture.output), we can see the source code for the original capture.output() function. capture.output() is a good clip longer (39 lines vs. 7 lines). The reason for this is that capture.output2() is more modular, since capture.output() writes out entire methods like readLines() instead of invoking them. This makes capture.output2 easier to understand if you understand the underlying methods. However, capture.output2() does remove potentially important functionality, as capture.output() appears to handle important exceptions not handled in capture.output2(), and capture.output() offers the ability to chose between overwriting or appending to a file. "],
["oo-field-guide.html", "4 OO field guide 4.1 S3 4.2 S4 4.3 RC", " 4 OO field guide 4.1 S3 Q: Read the source code for t() and t.test() and confirm that t.test() is an S3 generic and not an S3 method. What happens if you create an object with class test and call t() with it? A: We can see that t.test() is a generic, because it calls UseMethod() t.test #&gt; function (x, ...) #&gt; UseMethod(&quot;t.test&quot;) #&gt; &lt;bytecode: 0x00000000178332c0&gt; #&gt; &lt;environment: namespace:stats&gt; If we create an object with class “test” t.test() will cause R to call t.test.default() unless you create a method t.test() for the generic t(). Q: What classes have a method for the Math group generic in base R? Read the source code. How do the methods work? A: methods(&quot;Math&quot;) #&gt; [1] Math,nonStructure-method Math,structure-method #&gt; [3] Math.data.frame Math.Date #&gt; [5] Math.difftime Math.factor #&gt; [7] Math.POSIXt #&gt; see &#39;?methods&#39; for accessing help and source code Q: R has two classes for representing date time data, POSIXct and POSIXlt, which both inherit from POSIXt. Which generics have different behaviours for the two classes? Which generics share the same behaviour? A: Since both inherit from “POSIXt”, these should be the same for both classes: methods(class = &quot;POSIXt&quot;) #&gt; [1] - + all.equal as.character Axis #&gt; [6] coerce cut diff hist initialize #&gt; [11] is.numeric julian Math months Ops #&gt; [16] pretty quantile quarters round seq #&gt; [21] show slotsFromS3 str trunc weekdays #&gt; see &#39;?methods&#39; for accessing help and source code And these should be different (or only existing for one of the classes): methods(class = &quot;POSIXct&quot;) #&gt; [1] [ [[ [&lt;- as.data.frame as.Date #&gt; [6] as.list as.POSIXlt c coerce format #&gt; [11] initialize mean print rep show #&gt; [16] slotsFromS3 split summary Summary weighted.mean #&gt; [21] xtfrm #&gt; see &#39;?methods&#39; for accessing help and source code methods(class = &quot;POSIXlt&quot;) #&gt; [1] [ [&lt;- anyNA as.data.frame as.Date #&gt; [6] as.double as.matrix as.POSIXct c coerce #&gt; [11] duplicated format initialize is.na length #&gt; [16] mean names names&lt;- print rep #&gt; [21] show slotsFromS3 sort summary Summary #&gt; [26] unique weighted.mean xtfrm #&gt; see &#39;?methods&#39; for accessing help and source code Q: Which base generic has the greatest number of defined methods? A: library(methods) objs &lt;- mget(ls(&quot;package:base&quot;), inherits = TRUE) funs &lt;- Filter(is.function, objs) generics &lt;- Filter(function(x) (&quot;generic&quot; %in% pryr::ftype(x)), funs) sort(sapply(names(generics), function(x) length(methods(x))), decreasing = TRUE)[1] #&gt; print #&gt; 203 Q: UseMethod() calls methods in a special way. Predict what the following code will return, then run it and read the help for UseMethod() to figure out what’s going on. Write down the rules in the simplest form possible. y &lt;- 1 g &lt;- function(x) { y &lt;- 2 UseMethod(&quot;g&quot;) } g.numeric &lt;- function(x) y g(10) h &lt;- function(x) { x &lt;- 10 UseMethod(&quot;h&quot;) } h.character &lt;- function(x) paste(&quot;char&quot;, x) h.numeric &lt;- function(x) paste(&quot;num&quot;, x) h(&quot;a&quot;) A: g(10) will return 2. Since 2 is of class numeric, g.numeric() is called. It has only x in its execution environment and R will search for y in the enclosing environment, where y is defined as 2. From ?UseMethod: UseMethod creates a new function call with arguments matched as they came in to the generic. Any local variables defined before the call to UseMethod are retained (unlike S). So generics look at the class of their first argument (default) for method dispatch. Then a call to the particular method is made. Since the methods are created by the generic, R will look in the generics environment (including all objects defined before (!) the UseMethod statement) when an object is not found in the environment of the called method. h(&quot;a&quot;) will return &quot;char a&quot;, because x = &quot;a&quot; is given as input to the called method, which is of class character and so h.character is called and R also doesn’t need to look elsewhere for x. Q: Internal generics don’t dispatch on the implicit class of base types. Carefully read ?&quot;internal generic&quot; to determine why the length of f and g is different in the example below. What function helps distinguish between the behaviour of f and g? f &lt;- function() 1 g &lt;- function() 2 class(g) &lt;- &quot;function&quot; class(f) #&gt; [1] &quot;function&quot; class(g) #&gt; [1] &quot;function&quot; length.function &lt;- function(x) &quot;function&quot; length(f) #&gt; [1] 1 length(g) #&gt; [1] &quot;function&quot; A: From ?&quot;internal generic&quot;: Many R objects have a class attribute, a character vector giving the names of the classes from which the object inherits. If the object does not have a class attribute, it has an implicit class, “matrix”, “array” or the result of mode(x) (except that integer vectors have implicit class “integer”). (Functions oldClass and oldClass&lt;- get and set the attribute, which can also be done directly.) In the first case, the internal generic length does not find the class of f (“function”), so the method length.function is not called. This is because f doesn’t have a class - which is needed for the S3 method dispatch of internal generics (those that are implemented in C, you can check if they are generics with pryr::ftype) - only an implicit class. It is very confusing, because class(f) returns this (implicit) class. You can check if a class is only implicit by using one of the following approaches: is.object(f) returns FALSE oldClass(f) returns NULL attributes(f) doesn’t contain a $class field 4.2 S4 Q: Which S4 generic has the most methods defined for it? Which S4 class has the most methods associated with it? A: generics: We restrict our search to those packages that everyone should have installed: search() #&gt; [1] &quot;.GlobalEnv&quot; &quot;package:methods&quot; &quot;package:stats&quot; #&gt; [4] &quot;package:graphics&quot; &quot;package:grDevices&quot; &quot;package:utils&quot; #&gt; [7] &quot;package:datasets&quot; &quot;Autoloads&quot; &quot;package:base&quot; Then we start our search for generics and keep those of otype S4: generics &lt;- getGenerics(where = search()) is_gen_s4 &lt;- vapply(generics@.Data, function(x) pryr::otype(get(x)) == &quot;S4&quot;, logical(1)) generics &lt;- generics[is_gen_s4] Finally we calculate the S4-generic with the most methods: sort(sapply(generics, function(x) length(methods(x))), decreasing = TRUE)[1] #&gt; coerce #&gt; 27 classes: We collect all S4 classes within a character vector: s4classes &lt;- getClasses(where = .GlobalEnv, inherits = TRUE) Then we are going to steal the following function from S4 system development in Bioconductor that returns all methods to a given class s4Methods &lt;- function(class){ methods &lt;- showMethods(classes = class, printTo = FALSE) # notice the last setting methods &lt;- methods[grep(&quot;^Function:&quot;, methods)] sapply(strsplit(methods, &quot; &quot;), &quot;[&quot;, 2) } Finally we apply this function to get the methods of each class and format a little bit to answer the question: s4class_methods &lt;- lapply(s4classes, s4Methods) names(s4class_methods) &lt;- s4classes sort(lengths(s4class_methods), decreasing = TRUE)[1] #&gt; ANY #&gt; 66 Q: What happens if you define a new S4 class that doesn’t “contain” an existing class? (Hint: read about virtual classes in ?Classes.) A: Since ?Classes is deprecated we refer to ?setClass: Calls to setClass() will also create a virtual class, either when only the Class argument is supplied (no slots or superclasses) or when the contains= argument includes the special class name “VIRTUAL”. In the latter case, a virtual class may include slots to provide some common behavior without fully defining the object—see the class traceable for an example. Note that “VIRTUAL” does not carry over to subclasses; a class that contains a virtual class is not itself automatically virtual. Q: What happens if you pass an S4 object to an S3 generic? What happens if you pass an S3 object to an S4 generic? (Hint: read ?setOldClass for the second case.) A: 4.3 RC Q: Use a field function to prevent the account balance from being directly manipulated. (Hint: create a “hidden” .balance field, and read the help for the fields argument in setRefClass().) A: We are not that experienced in general RC classes, but it is easy with R6 classes. You can find all the information you need here. To solve the exercise this introduction should be sufficient: # definition of the class Account2 &lt;- R6::R6Class(&quot;Account&quot;, public = list( initialize = function(balance = 0){ private$balance = balance }, withdraw = function(x){ if (private$balance &lt; x) stop(&quot;Not enough money&quot;) private$balance &lt;- private$balance - x }, deposit = function(x) { private$balance &lt;- private$balance + x } ), private = list( balance = NULL ) ) # Checking the behaviour # a &lt;- Account2$new(100) # a$withdraw(50); a # a$balance # a$balance &lt;- 5000 # a$deposit(100); a # a$withdraw(200); a Q: I claimed that there aren’t any RC classes in base R, but that was a bit of a simplification. Use getClasses() and find which classes extend() from envRefClass. What are the classes used for? (Hint: recall how to look up the documentation for a class.) A: We get these classes as described in the exercise: classes &lt;- getClasses(where = .GlobalEnv, inherits = TRUE) classes[unlist(lapply(classes, function(x) methods::extends(x, &quot;envRefClass&quot;)))] #&gt; [1] &quot;envRefClass&quot; &quot;refGeneratorSlot&quot; &quot;localRefClass&quot; Their need is best described in class?envRefClass “Purpose of the Class”: This class implements basic reference-style semantics for R objects. Objects normally do not come directly from this class, but from subclasses defined by a call to setRefClass. The documentation below is technical background describing the implementation, but applications should use the interface documented under setRefClass, in particular the $ operator and field accessor functions as described there. "],
["environments.html", "5 Environments 5.1 Environment basics 5.2 Recursing over environments 5.3 Function environments 5.4 Binding names to values", " 5 Environments 5.1 Environment basics Q: List three ways in which an environment differs from a list. A: The most important differences are: environments have reference semantics environments have parents environments are not ordered elements of environments need to be (uniquely) named Q: If you don’t supply an explicit environment, where do ls() and rm() look? Where does &lt;- make bindings? The A: ls() and rm look in their calling environments which they find by as.environment(-1). From the book: Assignment is the act of binding (or rebinding) a name to a value in an environment. From ?`&lt;-`: The operators &lt;- and = assign into the environment in which they are evaluated. The operator &lt;- can be used anywhere, whereas the operator = is only allowed at the top level (e.g., in the complete expression typed at the command prompt) or as one of the subexpressions in a braced list of expressions. Q: Using parent.env() and a loop (or a recursive function), verify that the ancestors of globalenv() include baseenv() and emptyenv(). Use the same basic idea to implement your own version of search(). A: We can print the ancestors for example by using a recursive function: ancestors &lt;- function(env = globalenv()){ if (identical(env, emptyenv())) { print(environmentName(env))} else { print(environmentName(env)) ancestors(parent.env(env)) } } ancestors() #&gt; [1] &quot;R_GlobalEnv&quot; #&gt; [1] &quot;package:stats&quot; #&gt; [1] &quot;package:graphics&quot; #&gt; [1] &quot;package:grDevices&quot; #&gt; [1] &quot;package:utils&quot; #&gt; [1] &quot;package:datasets&quot; #&gt; [1] &quot;Autoloads&quot; #&gt; [1] &quot;base&quot; #&gt; [1] &quot;R_EmptyEnv&quot; To implement a new version of search() we use a while statement: search2 &lt;- function(env = globalenv()){ envs &lt;- character() while (!identical(env, emptyenv())) { ename &lt;- environmentName(env) if (ename == &quot;base&quot;) ename &lt;- &quot;package:base&quot; if (ename == &quot;R_GlobalEnv&quot;) ename &lt;- &quot;.GlobalEnv&quot; envs &lt;- c(envs, ename) env &lt;- parent.env(env) } return(envs) } search2() #&gt; [1] &quot;.GlobalEnv&quot; &quot;package:stats&quot; &quot;package:graphics&quot; #&gt; [4] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; #&gt; [7] &quot;Autoloads&quot; &quot;package:base&quot; # visual check that results are identical to the original search() function search() #&gt; [1] &quot;.GlobalEnv&quot; &quot;package:stats&quot; &quot;package:graphics&quot; #&gt; [4] &quot;package:grDevices&quot; &quot;package:utils&quot; &quot;package:datasets&quot; #&gt; [7] &quot;Autoloads&quot; &quot;package:base&quot; 5.2 Recursing over environments Q: Modify where() to find all environments that contain a binding for name. A: We look at the source code of the original pryr::where(): pryr::where function (name, env = parent.frame()) { stopifnot(is.character(name), length(name) == 1) env &lt;- to_env(env) if (identical(env, emptyenv())) { # &quot;base case&quot; stop(&quot;Can&#39;t find &quot;, name, call. = FALSE) } if (exists(name, env, inherits = FALSE)) { # &quot;success case&quot; env } else { # &quot;recursive case&quot; where(name, parent.env(env)) # we will copy this line in the success case } } Since where() stops searching when a match appears, we copy the recursive call in the else block to the block of the matching (“success”) case, so that our new function where2 will look for a binding within the complete search path. We also need to pay attention to other details. We have to take care to save the bindings in an object, while not overriding it in our recursive calls. So we create a list object for that and define a new function within where2() that we call where2.internal. where2.internal() will do the recursive work and whenever it finds a binding it will write it via &lt;&lt;- to the especially created list in its enclosing environment: where2 &lt;- function(name, env = parent.frame()){ # we need to collect all environments where name has a binding env_list &lt;- list() # since our function will be recursive and env_list would be overwritten # when it is inside the recursive function, we put it on the outside of # the recursive function and concatenate every binding environment # that we find via the `&lt;&lt;-` operator on its end. # In the following we start by defining the recursive function: where2.internal &lt;- function(name, env = parent.frame()) { stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) # note that we need to call to_env via pryr::: # when we reach the empty environment, we return all binding environments # (if we found some) if we found no bindings, we give the same error message # as pryr::where does if (identical(env, emptyenv())) { if (length(env_list) != 0){ return(env_list) } stop(&quot;Can&#39;t find &quot;, name, call. = FALSE) } if (exists(name, env, inherits = FALSE)) { # this is a case where we find a binding. the main difference to # pryr::where is that we don&#39;t return immediately. Instead we save # the binding environment to env_list and call where2.internal again env_list &lt;&lt;- c(env_list, env) where2.internal(name, parent.env(env)) } else { where2.internal(name, parent.env(env)) } } # as a last step we just call where2.internal() to start the recursion where2.internal(name, env = parent.frame()) } Note that where2.internal() still provides the same structure as pryr::where does and you can also divide it in “base case”, “success case” and “recursive case”. Q: Write your own version of get() using a function written in the style of where(). A: Note that get() provides a bit more arguments than our following version, but it should be easy to build up on that. However, we can change pryr::where to get2() with just changing one line of code (and the function name for the recursive call): get2 &lt;- function(name, env = parent.frame()) { stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) if (identical(env, emptyenv())) { stop(&quot;Can&#39;t find &quot;, name, call. = FALSE) } if (exists(name, env, inherits = FALSE)) { # we cancel env and substitute it with the following line, where we subset # the environment (like a list) by the name of our object and return it return(env[[name]]) } else { get2(name, parent.env(env)) } } Q: Write a function called fget() that finds only function objects. It should have two arguments, name and env, and should obey the regular scoping rules for functions: if there’s an object with a matching name that’s not a function, look in the parent. For an added challenge, also add an inherits argument which controls whether the function recurses up the parents or only looks in one environment. A: We can build up our function on the implementation of get2() in the last exercise. We only need to add a check via is.function(), change the name (also in the recursive call) and the error message: fget2 &lt;- function(name, env = parent.frame()){ stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) if (identical(env, emptyenv())) { stop(&quot;Could not find function called &quot;, name, call. = FALSE) # } # here we add the is.function() check if (exists(name, env, inherits = FALSE) &amp;&amp; is.function(env[[name]])) { return(env[[name]]) } else { fget2(name, parent.env(env)) } } Note that this function is almost the same as the implementation of pryr::fget(): pryr::fget #&gt; function (name, env = parent.frame()) #&gt; { #&gt; env &lt;- to_env(env) #&gt; if (identical(env, emptyenv())) { #&gt; stop(&quot;Could not find function called &quot;, name, call. = FALSE) #&gt; } #&gt; if (exists(name, env, inherits = FALSE) &amp;&amp; is.function(env[[name]])) { #&gt; env[[name]] #&gt; } #&gt; else { #&gt; fget(name, parent.env(env)) #&gt; } #&gt; } #&gt; &lt;environment: namespace:pryr&gt; We add an inherits parameter as described in the exercise: fget3 &lt;- function(name, env = parent.frame(), inherits = TRUE){ stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) if (identical(env, emptyenv())) { stop(&quot;Could not find function called &quot;, name, call. = FALSE) } if (exists(name, env, inherits = FALSE) &amp;&amp; is.function(env[[name]])) { return(env[[name]]) } # after the environment, which is specified in the env parameter, is checked # we stop our function in case the new inherits parameter is set to FALSE if(inherits == FALSE){ stop(&quot;Could not find function called &quot;, name,&quot; within &quot;, environmentName(env), call. = FALSE) } else { fget3(name, parent.env(env)) } } Q: Write your own version of exists(inherits = FALSE) (Hint: use ls().) Write a recursive version that behaves like exists(inherits = TRUE). A: We write two versions. exists2() will be the case inherits = FALSE and exists3() inherits = TRUE: exists2 &lt;- function(name, env = parent.frame()){ stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) name %in% ls(env, sorted = FALSE) # set sorted to FALSE for a small speedup } exists3 &lt;- function(name, env = parent.frame()){ stopifnot(is.character(name), length(name) == 1) env &lt;- pryr:::to_env(env) if (identical(env, emptyenv())) { return(FALSE) } if (name %in% ls(env, sorted = FALSE)){ TRUE } else { exists3(name, parent.env(env)) } } 5.3 Function environments Q: List the four environments associated with a function. What does each one do? Why is the distinction between enclosing and binding environments particularly important? A: Enclosing: where the function is created Binding: where the function was assigned Execution: a temporary environment which is created when the function is executed Calling: the environment from where the function was called The difference between binding and enclosing environment is important, because of R’s lexical scoping rules. If R can’t find an object in the current environment while executing a function, it will look for it in the enclosing environment. Q: Draw a diagram that shows the enclosing environments of this function: f1 &lt;- function(x1) { f2 &lt;- function(x2) { f3 &lt;- function(x3) { x1 + x2 + x3 } f3(3) } f2(2) } f1(1) A: Q: Expand your previous diagram to show function bindings. A: Q: Expand it again to show the execution and calling environments. A: Q: Write an enhanced version of str() that provides more information about functions. Show where the function was found and what environment it was defined in. A: Additionally we provide the function type in the sense of pryr::ftype. We use functions from the pryr package, since it provides helpers for all requested features: fstr &lt;- function(object){ if(!is.function(object)){stop(&quot;fstr works only for functions&quot;)} object_str &lt;- lazyeval::expr_text(object) flist &lt;- list(ftype = pryr::ftype(object), where = pryr::where(object_str), enclosing_env = pryr::enclosing_env(object), args = pryr::fun_args(object) ) return(flist) } Note that we wanted to have non standard evaluation like the original str() function. Since pryr::where() doesn’t support non standard evaluation, we needed to catch the name of the supplied object. Therefore we used expr_text() from the lazyeval package. As a result, fstr(object = packagename::functionname) will result in an error in contrast to str(). 5.4 Binding names to values Q: What does this function do? How does it differ from &lt;&lt;- and why might you prefer it? rebind &lt;- function(name, value, env = parent.frame()) { if (identical(env, emptyenv())) { stop(&quot;Can&#39;t find &quot;, name, call. = FALSE) } else if (exists(name, envir = env, inherits = FALSE)) { assign(name, value, envir = env) } else { rebind(name, value, parent.env(env)) } } rebind(&quot;a&quot;, 10) #&gt; Error: Can&#39;t find a a &lt;- 5 rebind(&quot;a&quot;, 10) a #&gt; [1] 10 A: The function does “more or less” the same as &lt;&lt;-. Additionally to &lt;&lt;- it has an env argument, but this is not a big advantage, since also assign() provides this functionality. The main difference is that rebind() only does an assignment, when it finds a binding in one of the parent environments of env. Whereas: If &lt;&lt;- doesn’t find an existing variable, it will create one in the global environment. This is usually undesirable, because global variables introduce non-obvious dependencies between functions. Q: Create a version of assign() that will only bind new names, never re-bind old names. Some programming languages only do this, and are known as [single assignment languages][single assignment]. A: We take the formals from assign()’s source code and define our new function. If x already exists, we give a message and return NULL (since this is the same as return()). Otherwise we let the body of the assign() function do the work: assign_non_existant &lt;- function(x, value, pos = -1, envir = as.environment(pos), inherits = FALSE, immediate = TRUE) { if(exists(x)){ message(&quot;No new assignment: &#39;&quot;, x, &quot;&#39; already exists&quot;) return(NULL)} .Internal(assign(x, value, envir, inherits)) } Note that .Internal(assign(x, value, envir, inherits)), is not inside an else block or any other function. This is important. Otherwise we would change more of assign() than we want (in case of the assignment of a new function, the enclosing environment for that function would differ). Q: Write an assignment function that can do active, delayed, and locked bindings. What might you call it? What arguments should it take? Can you guess which sort of assignment it should do based on the input? A: The following might be no optimal solution, but we can at least handle two of three cases via if statements. The problem already occured in the last exercise, were we had to do an assignment in an if statement and did a workaround. This workaround only works for one assignment (for logical reasons). We still use the workaround for the “delay case”, but we found a solution for the other two cases. The main aspect in it is to unify the environment were assign(), makeActiveBinding() and delayedAssign() act. We also had to test that cases like this makeActiveBinding(sym = &quot;test1&quot;, fun = function() function(x, y = sample(1:3, 1)){x^y}, env = parent.frame()) work with our new function and our function creates bindings (and so enclosing environments) in the same places as assign() would do, also when used inside funceions. The usage of pryr:::to_env() simplified this process a lot: # found at https://github.com/hadley/pryr/blob/master/R/utils.r function(x, quiet = FALSE) { if (is.environment(x)) { x } else if (is.list(x)) { list2env(x) } else if (is.function(x)) { environment(x) } else if (length(x) == 1 &amp;&amp; is.character(x)) { if (!quiet) message(&quot;Using environment &quot;, x) as.environment(x) } else if (length(x) == 1 &amp;&amp; is.numeric(x) &amp;&amp; x &gt; 0) { if (!quiet) message(&quot;Using environment &quot;, search()[x]) as.environment(x) } else { stop(&quot;Input can not be coerced to an environment&quot;, call. = FALSE) } } We used all these thoughts to create the following function: special_assign &lt;- function(x, value, atype, envir = pryr:::to_env(parent.frame())){ if(atype == &quot;locked&quot;){ assign(x, value, envir = envir, inherits) lockBinding(sym = x, env = envir) } if(atype == &quot;active&quot;){makeActiveBinding(sym = x, fun = value, env = envir)} if(atype != &quot;delayed&quot;){stop(&quot;atype must be `locked`, `active` or `delayed`&quot;)} delayedAssign(x, value, eval.env = environment(), assign.env = envir) } At the moment we have no idea for a good default guess routine, so that a specific atype of assignment would be done based on the input. "],
["exceptions-and-debugging.html", "6 Exceptions and debugging 6.1 Condition handling 6.2 Defensive programming", " 6 Exceptions and debugging 6.1 Condition handling Q: Compare the following two implementations of message2error(). What is the main advantage of withCallingHandlers() in this scenario? (Hint: look carefully at the traceback.) message2error &lt;- function(code) { withCallingHandlers(code, message = function(e) stop(e)) } message2error &lt;- function(code) { tryCatch(code, message = function(e) stop(e)) } A: 6.2 Defensive programming Q: The goal of the col_means() function defined below is to compute the means of all numeric columns in a data frame. col_means &lt;- function(df) { numeric &lt;- sapply(df, is.numeric) numeric_cols &lt;- df[, numeric] data.frame(lapply(numeric_cols, mean)) } However, the function is not robust to unusual inputs. Look at the following results, decide which ones are incorrect, and modify col_means() to be more robust. (Hint: there are two function calls in col_means() that are particularly prone to problems.) col_means(mtcars) col_means(mtcars[, 0]) col_means(mtcars[0, ]) col_means(mtcars[, &quot;mpg&quot;, drop = F]) col_means(1:10) col_means(as.matrix(mtcars)) col_means(as.list(mtcars)) mtcars2 &lt;- mtcars mtcars2[-1] &lt;- lapply(mtcars2[-1], as.character) col_means(mtcars2) A: We divide the tests according their input types and look at the results: # data.frame input col_means(mtcars) # correct (return: 1 row numeric data.frame) col_means(mtcars[, 0]) # incorrect (return: error. An empty data.frame would be better) col_means(mtcars[0, ])[[1]] # correct (return: 1 row numeric (NaN) data.frame, # which becomes an atomic after subsetting col_means(mtcars[, &quot;mpg&quot;, drop = F]) # incorrect (returns complete the numeric column as a # data.frame with new names) # other input col_means(1:10) # correct (specific error) col_means(as.matrix(mtcars)) # correct (specific error) col_means(as.list(mtcars)) # correct (specific error) # data.fame (numeric + character columns) mtcars2 &lt;- mtcars mtcars2[-1] &lt;- lapply(mtcars2[-1], as.character) col_means(mtcars2) # incorrect (returns the complete numeric column as a data.frame # with new names) We can make the following changes: col_means2 &lt;- function(df) { # stopifnot(is.data.frame(df)) numeric &lt;- vapply(df, is.numeric, logical(1)) # sapply() to vapply() numeric_cols &lt;- df[, numeric, drop = FALSE] # add drop = FALSE data.frame(lapply(numeric_cols, mean)) } And look at the tests again: # data.frame input col_means2(mtcars) # correct col_means2(mtcars[, 0]) # correct col_means2(mtcars[0, ])[[1]] # correct col_means2(mtcars[, &quot;mpg&quot;, drop = F]) #correct # other input col_means2(1:10) # correct (specific error) col_means2(as.matrix(mtcars)) # correct (specific error) col_means2(as.list(mtcars)) # correct (specific error) # data.frame (numeric + character columns) col_means2(mtcars2) # correct For faster failing in the error cases (where the input is not a data.frame), we can add stopifnot(is.data.frame(df)) in the first line of col_means(). Q: The following function “lags” a vector, returning a version of x that is n values behind the original. Improve the function so that it (1) returns a useful error message if n is not a vector, and (2) has reasonable behaviour when n is 0 or longer than x. lag &lt;- function(x, n = 1L) { xlen &lt;- length(x) c(rep(NA, n), x[seq_len(xlen - n)]) } A: First we test lag()’s actual bahaviour: v &lt;- 1:3 lag(v, 1) # -&gt; NA 1 2 ; correct lag(v, 0) # -&gt; 1 2 3 ; correct lag(v, 3) # -&gt; NA NA NA; correct lag(v, 4) # -&gt; Error in seq_len(xlen - n) : # argument must be coercible to non-negative integer # in my opinion the result should be NA NA NA lag(v, iris) # -&gt; Error in lag(v, iris) : (list) object cannot be coerced to type &#39;integer&#39; We can adjust lag(), to get better bahaviour in the latter two error cases: lag2 &lt;- function(x, n = 1L) { # we make sure that a double or integer is supplied if (!is.numeric(n)) stop(&quot;n is not a numeric vector&quot;) xlen &lt;- length(x) # and we change n so that xlen - n will become 0 in case of n &gt; length(x) # to get the desired behaviour for lag(v, 4) n &lt;- min(xlen, n) c(rep(NA, n), x[seq_len(xlen - n)]) } Now we look again at the tests: lag2(v, 1) # -&gt; correct lag2(v, 0) # -&gt; correct lag2(v, 3) # -&gt; correct lag2(v, 4) # -&gt; NA NA NA; correct lag2(v, iris) # -&gt; Error in lag2(v, iris) : n is not a numeric vector Note that we didn’t test/specify lag()’s behaviour for negative, decimal or length(n) != 1 inputs of n. "],
["functional-programming.html", "7 Functional programming 7.1 Annonymous functions 7.2 Closures 7.3 Lists of functions 7.4 Case study: numerical integration", " 7 Functional programming 7.1 Annonymous functions Q: Given a function, like &quot;mean&quot;, match.fun() lets you find a function. Given a function, can you find its name? Why doesn’t that make sense in R? A: If you know body(), formals() and environment() it can be possible to find the function. However, this won’t be possible for primitive functions, since they return NULL for those three properties. Also annonymous functions won’t be found, because they are not bound to a name. On the other hand it could be that different names in an environment contain binding to one (or more functions) with the same body(), formals() and environment() which means that the solution wouldn’t be unique. More general: In R a (function) name has an object, but an object (i.e. a function) doesn’t have a name (just a binding sometimes). Q: Use lapply() and an anonymous function to find the coefficient of variation (the standard deviation divided by the mean) for all columns in the mtcars dataset A: lapply(mtcars, function(x) sd(x)/mean(x)). Q: Use integrate() and an anonymous function to find the area under the curve for the following functions. Use Wolfram Alpha to check your answers. y = x ^ 2 - x, x in [0, 10] y = sin(x) + cos(x), x in [-\\(\\pi\\), \\(\\pi\\)] y = exp(x) / x, x in [10, 20] A: integrate(function(x) x^2 - x, 0, 10) integrate(function(x) sin(x) + cos(x), -pi, pi) integrate(function(x) exp(x) / x, 10, 20) Q: A good rule of thumb is that an anonymous function should fit on one line and shouldn’t need to use {}. Review your code. Where could you have used an anonymous function instead of a named function? Where should you have used a named function instead of an anonymous function? A: 7.2 Closures Q: Why are functions created by other functions called closures? A: As stated in the book: because they enclose the environment of the parent function and can access all its variables. Q: What does the following statistical function do? What would be a better name for it? (The existing name is a bit of a hint.) bc &lt;- function(lambda) { if (lambda == 0) { function(x) log(x) } else { function(x) (x ^ lambda - 1) / lambda } } A: It is the logarithm, when lambda equals zero and x ^ lambda - 1 / lambda otherwise. A better name might be box_cox_transformation (one parametric), you can read about it (here)[https://en.wikipedia.org/wiki/Power_transform]. Q: What does approxfun() do? What does it return? A: approxfun basically takes a combination of 2-dimensional data points + some extra specifications as arguments and returns a stepwise linear or constant interpolation function (defined on the range of given x-values, by default). Q: What does ecdf() do? What does it return? A: “ecdf” means empirical density function. For a numeric vector, ecdf() returns the appropriate density function (of class “ecdf”, which is inheriting from class “stepfun”). You can describe it’s behaviour in 2 steps. In the first part of it’s body, the (x,y) pairs for the nodes of the density function are calculated. In the second part these pairs are given to approxfun. Q: Create a function that creates functions that compute the ith central moment of a numeric vector. You can test it by running the following code: m1 &lt;- moment(1) m2 &lt;- moment(2) x &lt;- runif(100) stopifnot(all.equal(m1(x), 0)) stopifnot(all.equal(m2(x), var(x) * 99 / 100)) A: For a discrete formulation look here moment &lt;- function(i){ function(x) sum((x - mean(x)) ^ i) / length(x) } Q: Create a function pick() that takes an index, i, as an argument and returns a function with an argument x that subsets x with i. lapply(mtcars, pick(5)) # should do the same as this lapply(mtcars, function(x) x[[5]]) A: pick &lt;- function(i){ function(x) x[[i]] } stopifnot(identical(lapply(mtcars, pick(5)), lapply(mtcars, function(x) x[[5]])) ) 7.3 Lists of functions Q: Implement a summary function that works like base::summary(), but uses a list of functions. Modify the function so it returns a closure, making it possible to use it as a function factory. A: We have two possibilities, we can imitate base::summary() completely or create a new summary based on our preferences. Both is not so easy, since it involves a lot of design decisions. We choose the second option, since we just like to create a first draft to apply what we have learned and get some feeling for the challenges that might appear. Some properties, that our new summary function summary2 should have are nice default actions for specific data types and they should of course be changeable as this is also a part of the exercise. To limit our efforts, we focus on summaries for data frames. Everything else will be explained, via comments on the code: # The arguments of our function factory are the lists of functions that are # applied to data frame columns, depending on their type. # We focus on the most important, so they can be set for characters, integer, # double, logical, factor and date. By default they are set to NULL, but if you # supply a list with functions, this will override the real default, for the # specific type, which is set inside the function factory. summary2 &lt;- function(character_functions = NULL, integer_functions = NULL, double_functions = NULL, logical_functions = NULL, factor_functions = NULL, date_functions = NULL){ # The following functional will later be six times applied on the data frame, # one time for every column type in the scope of our function apply_typefunction &lt;- function(df, pred, functions){ lapply(df[vapply(df, pred, logical(1))], function(x) unlist(lapply(functions, function(y) y(x)))) } # The following lists of functions are &quot;somehow&quot; similar to those, that are used # by base::summary, so we define them once... default_1 &lt;- list(Table = table) default_2 &lt;- list(Min = min, `1st Qu.` = function(x) quantile(x)[[2]], Median = median, Mean = mean, `3rd Qu.` = function(x) quantile(x)[[4]], Max = max) # All those function list, that are not specified, when calling the # function factory, are now set to their default values if(is.null(character_functions)) {character_functions = default_1} if(is.null(integer_functions)) {integer_functions = default_2} if(is.null(double_functions)) {double_functions = default_2} if(is.null(logical_functions)) {logical_functions = default_1} if(is.null(factor_functions)) {factor_functions = default_1} if(is.null(date_functions)) {date_functions = default_2} # Finally the returned function is created function(df){ # For every column type, the specific functions will be applied to the # appropriate columns. characters &lt;- apply_typefunction(df, is.character, character_functions) integers &lt;- apply_typefunction(df, is.integer , integer_functions ) doubles &lt;- apply_typefunction(df, is.double , double_functions ) logicals &lt;- apply_typefunction(df, is.logical , logical_functions ) factors &lt;- apply_typefunction(df, is.factor , factor_functions ) dates &lt;- apply_typefunction(df, function(x) inherits(x, &#39;Date&#39;), date_functions) # The results will be collected in a list and if empty lists appear, because # of non occuring columntypes, these empty lists will be removed from the output. # There are a lot of formatting steps, like ordering, naming and converting # output, that we could do, but we think that the idea is more important for now out &lt;- list(characters, integers, doubles, logicals, factors, dates) out[lengths(out) != 0] } } # Now we can apply the function factory summary2_default &lt;- summary2() # And the resulting function summary2_default(df = iris) #&gt; [[1]] #&gt; [[1]]$Sepal.Length #&gt; Min 1st Qu. Median Mean 3rd Qu. Max #&gt; 4.300000 5.100000 5.800000 5.843333 6.400000 7.900000 #&gt; #&gt; [[1]]$Sepal.Width #&gt; Min 1st Qu. Median Mean 3rd Qu. Max #&gt; 2.000000 2.800000 3.000000 3.057333 3.300000 4.400000 #&gt; #&gt; [[1]]$Petal.Length #&gt; Min 1st Qu. Median Mean 3rd Qu. Max #&gt; 1.000 1.600 4.350 3.758 5.100 6.900 #&gt; #&gt; [[1]]$Petal.Width #&gt; Min 1st Qu. Median Mean 3rd Qu. Max #&gt; 0.100000 0.300000 1.300000 1.199333 1.800000 2.500000 #&gt; #&gt; #&gt; [[2]] #&gt; [[2]]$Species #&gt; Table.setosa Table.versicolor Table.virginica #&gt; 50 50 50 # Unfortunately, we will fail if there are any NAs in integer columns df_nas &lt;- data.frame(integers_na = c(NA, 2:19)) summary2_default(df_nas) #&gt; Error in quantile.default(x): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE # But since, we can define new functions for integer columns, we can solve this summary2_naversion &lt;- summary2(integer_functions = list( Mean_na = function(x) mean(x, na.rm = TRUE), Median_na = function(x) median(x, na.rm = TRUE), NAs = function(x) sum(is.na(x))) ) summary2_naversion(df_nas) #&gt; [[1]] #&gt; [[1]]$integers_na #&gt; Mean_na Median_na NAs #&gt; 10.5 10.5 1.0 Q: Which of the following commands is equivalent to with(x, f(z))? x$f(x$z). f(x$z). x$f(z). f(z). It depends. A: b is equivalent. If x is the current environment, also d would work. 7.4 Case study: numerical integration Q: Instead of creating individual functions (e.g., midpoint(), trapezoid(), simpson(), etc.), we could store them in a list. If we did that, how would that change the code? Can you create the list of functions from a list of coefficients for the Newton-Cotes formulae? A: Q: The trade-off between integration rules is that more complex rules are slower to compute, but need fewer pieces. For sin() in the range [0, \\(\\pi\\)], determine the number of pieces needed so that each rule will be equally accurate. Illustrate your results with a graph. How do they change for different functions? sin(1 / x^2) is particularly challenging. A: "],
["functionals.html", "8 Functionals 8.1 My first functional: lapply() 8.2 For loops functionals: friends of lapply(): 8.3 Manipulating matrices and data frames 8.4 Manipulating lists 8.5 Mathematical functionals 8.6 A family of functions", " 8 Functionals 8.1 My first functional: lapply() Q: Why are the following two invocations of lapply() equivalent? trims &lt;- c(0, 0.1, 0.2, 0.5) x &lt;- rcauchy(100) lapply(trims, function(trim) mean(x, trim = trim)) lapply(trims, mean, x = x) A: In the first statement each element of trims is explicitly supplied to mean()’s second argument. In the latter statement this happens via positional matching, since mean()’s first argument is supplied via name in lapply()’s third argument (...). Q: The function below scales a vector so it falls in the range [0, 1]. How would you apply it to every column of a data frame? How would you apply it to every numeric column in a data frame? scale01 &lt;- function(x) { rng &lt;- range(x, na.rm = TRUE) (x - rng[1]) / (rng[2] - rng[1]) } A: Since this function needs numeric input, one can check this via an if clause. If one also wants to return non-numeric input columns, these can be supplied to the else argument of the if() “function”: data.frame(lapply(iris, function(x) if (is.numeric(x)) scale01(x) else x)) Q: Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list: formulas &lt;- list( mpg ~ disp, mpg ~ I(1 / disp), mpg ~ disp + wt, mpg ~ I(1 / disp) + wt ) A: Like in the first exercise, we can create two lapply() versions: # lapply (2 versions) la1 &lt;- lapply(formulas, lm, data = mtcars) la2 &lt;- lapply(formulas, function(x) lm(formula = x, data = mtcars)) # for loop lf1 &lt;- vector(&quot;list&quot;, length(formulas)) for (i in seq_along(formulas)){ lf1[[i]] &lt;- lm(formulas[[i]], data = mtcars) } Note that all versions return the same content, but they won’t be identical, since the values of the “call” element will differ between each version. Q: Fit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below by using a for loop and lapply(). Can you do it without an anonymous function? bootstraps &lt;- lapply(1:10, function(i) { rows &lt;- sample(1:nrow(mtcars), rep = TRUE) mtcars[rows, ] }) A: # lapply without anonymous function la &lt;- lapply(bootstraps, lm, formula = mpg ~ disp) # for loop lf &lt;- vector(&quot;list&quot;, length(bootstraps)) for (i in seq_along(bootstraps)){ lf[[i]] &lt;- lm(mpg ~ disp, data = bootstraps[[i]]) } Q: For each model in the previous two exercises, extract \\(R^2\\) using the function below. rsq &lt;- function(mod) summary(mod)$r.squared A: For the models in exercise 3: sapply(la1, rsq) #&gt; [1] 0.7183433 0.8596865 0.7809306 0.8838038 sapply(la2, rsq) #&gt; [1] 0.7183433 0.8596865 0.7809306 0.8838038 sapply(lf1, rsq) #&gt; [1] 0.7183433 0.8596865 0.7809306 0.8838038 And the models in exercise 4: sapply(la, rsq) #&gt; [1] 0.7207897 0.6324568 0.7241623 0.7637960 0.7478840 0.6720768 0.6811906 #&gt; [8] 0.6742183 0.7644756 0.7440796 sapply(lf, rsq) #&gt; [1] 0.7207897 0.6324568 0.7241623 0.7637960 0.7478840 0.6720768 0.6811906 #&gt; [8] 0.6742183 0.7644756 0.7440796 8.2 For loops functionals: friends of lapply(): Q: Use vapply() to: Compute the standard deviation of every column in a numeric data frame. Compute the standard deviation of every numeric column in a mixed data frame. (Hint: you’ll need to use vapply() twice.) A: As a numeric data.frame we choose cars: vapply(cars, sd, numeric(1)) And as a mixed data.frame we choose iris: vapply(iris[vapply(iris, is.numeric, logical(1))], sd, numeric(1)) Q: Why is using sapply() to get the class() of each element in a data frame dangerous? A: Columns of data.frames might have more than one class, so the class of sapply()’s output may differ from time to time (silently). If … all columns have one class: sapply() returns a character vector one column has more classes than the others: sapply() returns a list all columns have the same number of classes, which is more than one: sapply() returns a matrix For example: a &lt;- letters[1:3] class(a) &lt;- c(&quot;class1&quot;, &quot;class2&quot;) df &lt;- data.frame(a = character(3)) df$a &lt;- a df$b &lt;- a class(sapply(df, class)) #&gt; [1] &quot;matrix&quot; Note that this case often appears, wile working with the POSIXt types, POSIXct and POSIXlt. Q: The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial. trials &lt;- replicate( 100, t.test(rpois(10, 10), rpois(7, 10)), simplify = FALSE ) Extra challenge: get rid of the anonymous function by using [[ directly. A: # anonymous function: sapply(trials, function(x) x[[&quot;p.value&quot;]]) # without anonymous function: sapply(trials, &quot;[[&quot;, &quot;p.value&quot;) Q: What does replicate() do? What sort of for loop does it eliminate? Why do its arguments differ from lapply() and friends? A: As stated in ?replicate: replicate is a wrapper for the common use of sapply for repeated evaluation of an expression (which will usually involve random number generation). We can see this clearly in the source code: #&gt; function (n, expr, simplify = &quot;array&quot;) #&gt; sapply(integer(n), eval.parent(substitute(function(...) expr)), #&gt; simplify = simplify) #&gt; &lt;bytecode: 0x00000000175406f0&gt; #&gt; &lt;environment: namespace:base&gt; Like sapply() replicate() eliminates a for loop. As explained for Map() in the textbook, also every replicate() could have been written via lapply(). But using replicate() is more concise, and more clearly indicates what you’re trying to do. Q: Implement a version of lapply() that supplies FUN with both the name and the value of each component. A: lapply_nms &lt;- function(X, FUN, ...){ Map(FUN, X, names(X), ...) } lapply_nms(iris, function(x, y) c(class(x), y)) #&gt; $Sepal.Length #&gt; [1] &quot;numeric&quot; &quot;Sepal.Length&quot; #&gt; #&gt; $Sepal.Width #&gt; [1] &quot;numeric&quot; &quot;Sepal.Width&quot; #&gt; #&gt; $Petal.Length #&gt; [1] &quot;numeric&quot; &quot;Petal.Length&quot; #&gt; #&gt; $Petal.Width #&gt; [1] &quot;numeric&quot; &quot;Petal.Width&quot; #&gt; #&gt; $Species #&gt; [1] &quot;factor&quot; &quot;Species&quot; Q: Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take? A As we understand this exercise, it is about working with a list of lists, like in the following example: testlist &lt;- list(iris, mtcars, cars) lapply(testlist, function(x) vapply(x, mean, numeric(1))) #&gt; Warning in mean.default(X[[i]], ...): argument is not numeric or logical: #&gt; returning NA #&gt; [[1]] #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; 5.843333 3.057333 3.758000 1.199333 NA #&gt; #&gt; [[2]] #&gt; mpg cyl disp hp drat wt #&gt; 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 #&gt; qsec vs am gear carb #&gt; 17.848750 0.437500 0.406250 3.687500 2.812500 #&gt; #&gt; [[3]] #&gt; speed dist #&gt; 15.40 42.98 So we can get the same result with a more specialized function: lmapply &lt;- function(X, FUN, FUN.VALUE, simplify = FALSE){ out &lt;- Map(function(x) vapply(x, FUN, FUN.VALUE), X) if(simplify == TRUE){return(simplify2array(out))} out } lmapply(testlist, mean, numeric(1)) #&gt; Warning in mean.default(X[[i]], ...): argument is not numeric or logical: #&gt; returning NA #&gt; [[1]] #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; 5.843333 3.057333 3.758000 1.199333 NA #&gt; #&gt; [[2]] #&gt; mpg cyl disp hp drat wt #&gt; 20.090625 6.187500 230.721875 146.687500 3.596563 3.217250 #&gt; qsec vs am gear carb #&gt; 17.848750 0.437500 0.406250 3.687500 2.812500 #&gt; #&gt; [[3]] #&gt; speed dist #&gt; 15.40 42.98 Q: Implement mcsapply(), a multicore version of sapply(). Can you implement mcvapply(), a parallel version of vapply()? Why or why not? 8.3 Manipulating matrices and data frames Q: How does apply() arrange the output? Read the documentation and perform some experiments. A: apply() arranges its output columns (or list elements) according to the order of the margin. The rows are ordered by the other dimensions, starting with the “last” dimension of the input object. What this means should become clear by looking at the three and four dimensional cases of the following example: # for two dimensional cases everything is sorted by the other dimension arr2 &lt;- array(1:9, dim = c(3, 3), dimnames = list(paste0(&quot;row&quot;, 1:3), paste0(&quot;col&quot;, 1:3))) arr2 apply(arr2, 1, head, 1) # Margin is row apply(arr2, 1, head, 9) # sorts by col apply(arr2, 2, head, 1) # Margin is col apply(arr2, 2, head, 9) # sorts by row # 3 dimensional arr3 &lt;- array(1:27, dim = c(3,3,3), dimnames = list(paste0(&quot;row&quot;, 1:3), paste0(&quot;col&quot;, 1:3), paste0(&quot;time&quot;, 1:3))) arr3 apply(arr3, 1, head, 1) # Margin is row apply(arr3, 1, head, 27) # sorts by time and col apply(arr3, 2, head, 1) # Margin is col apply(arr3, 2, head, 27) # sorts by time and row apply(arr3, 3, head, 1) # Margin is time apply(arr3, 3, head, 27) # sorts by col and row # 4 dimensional arr4 &lt;- array(1:81, dim = c(3,3,3,3), dimnames = list(paste0(&quot;row&quot;, 1:3), paste0(&quot;col&quot;, 1:3), paste0(&quot;time&quot;, 1:3), paste0(&quot;var&quot;, 1:3))) arr4 apply(arr4, 1, head, 1) # Margin is row apply(arr4, 1, head, 81) # sorts by var, time, col apply(arr4, 2, head, 1) # Margin is col apply(arr4, 2, head, 81) # sorts by var, time, row apply(arr4, 3, head, 1) # Margin is time apply(arr4, 3, head, 81) # sorts by var, col, row apply(arr4, 4, head, 1) # Margin is var apply(arr4, 4, head, 81) # sorts by time, col, row Q: There’s no equivalent to split() + vapply(). Should there be? When would it be useful? Implement one yourself. A: We can modify the tapply2() approach from the book, where split() and sapply() were combined: v_tapply &lt;- function(x, group, f, FUN.VALUE, ..., USE.NAMES = TRUE) { pieces &lt;- split(x, group) vapply(pieces, f, FUN.VALUE, ..., USE.NAMES = TRUE) } tapply() has a SIMPLIFY argument. When you set it to FALSE, tapply() will always return a list. It is easy to create cases where the length and the types/classes of the list elements vary depending on the input. The vapply() version could be useful, if you want to control the structure of the output to get an error according to some logic of a specific usecase or you want typestable output to build up other functions on top of it. Q: Implement a pure R version of split(). (Hint: use unique() and subsetting.) Can you do it without a for loop? A: split2 &lt;- function(x, f, drop = FALSE, ...){ # there are three relevant cases for f. f is a character, f is a factor and all # levels occur, f is a factor and some levels don&#39;t occur. # first we check if f is a factor fact &lt;- is.factor(f) # if drop it set to TRUE, we drop the non occuring levels. # (If f is a character, this has no effect.) if(drop){f &lt;- f[, drop = TRUE]} # now we want all unique elements/levels of f levs &lt;- if (fact) {unique(levels(f))} else {as.character(unique(f))} # we use these levels to subset x and supply names for the resulting output. setNames(lapply(levs, function(lv) x[f == lv, , drop = FALSE]), levs) } Q: What other types of input and output are missing? Brainstorm before you look up some answers in the plyr paper. A: From the suggested plyr paper, we can extract a lot of possible combinations and list them up on a table. Sean C. Anderson already has done this based on a presentation from Hadley Wickham and provided the following result here. object type array data frame list nothing array apply . . . data frame . aggregate by . list sapply . lapply . n replicates replicate . replicate . function arguments mapply . mapply . Note the column nothing, which is specifically for usecases, where sideeffects like plotting or writing data are intended. 8.4 Manipulating lists Q: Why isn’t is.na() a predicate function? What base R function is closest to being a predicate version of is.na()? A: Because a predicate function always returns TRUE or FALSE. is.na(NULL) returns logical(0), which excludes it from being a predicate function. The closest in base that we are aware of is anyNA(), if one applies it elementwise. Q: Use Filter() and vapply() to create a function that applies a summary statistic to every numeric column in a data frame. A: vapply_num &lt;- function(X, FUN, FUN.VALUE){ vapply(Filter(is.numeric, X), FUN, FUN.VALUE) } Q: What’s the relationship between which() and Position()? What’s the relationship between where() and Filter()? A: which() returns all indices of true entries from a logical vector. Position() returns just the first (default) or the last integer index of all true entries that occur by applying a predicate function on a vector. So the default relation is Position(f, x) &lt;=&gt; min(which(f(x))). where(), defined in the book as: where &lt;- function(f, x) { vapply(x, f, logical(1)) } is useful to return a logical vector from a condition asked on elements of a list or a data frame. Filter(f, x) returns all elements of a list or a data frame, where the supplied predicate function returns TRUE. So the relation is Filter(f, x) &lt;=&gt; x[where(f, x)]. Q: Implement Any(), a function that takes a list and a predicate function, and returns TRUE if the predicate function returns TRUE for any of the inputs. Implement All() similarly. A: Any(): Any &lt;- function(l, pred){ stopifnot(is.list(l)) for (i in seq_along(l)){ if (pred(l[[i]])) return(TRUE) } return(FALSE) } All(): All &lt;- function(l, pred){ stopifnot(is.list(l)) for (i in seq_along(l)){ if (!pred(l[[i]])) return(FALSE) } return(TRUE) } Q: Implement the span() function from Haskell: given a list x and a predicate function f, span returns the location of the longest sequential run of elements where the predicate is true. (Hint: you might find rle() helpful.) A: Our span_r() function returns the first index of the longest sequential run of elements where the predicate is true. In case of more than one longest sequenital, more than one first_index is returned. span_r &lt;- function(l, pred){ # We test if l is a list stopifnot(is.list(l)) # we preallocate a logical vector and save the result # of the predicate function applied to each element of the list test &lt;- vector(&quot;logical&quot;, length(l)) for (i in seq_along(l)){ test[i] &lt;- (pred(l[[i]])) } # we return NA, if the output of pred is always FALSE if(!any(test)) return(NA_integer_) # Otherwise we look at the length encoding of TRUE and FALSE values. rle_test &lt;- rle(test) # Since it might happen, that more than one maximum series of TRUE&#39;s appears, # we have to implement some logic, which might be easier, if we save the rle # output in a data.frmame rle_test &lt;- data.frame(lengths = rle_test[[&quot;lengths&quot;]], values = rle_test[[&quot;values&quot;]], cumsum = cumsum(rle_test[[&quot;lengths&quot;]])) rle_test[[&quot;first_index&quot;]] &lt;- rle_test[[&quot;cumsum&quot;]] - rle_test[[&quot;lengths&quot;]] + 1 # In the last line we calculated the first index in the original list for every encoding # In the next line we calculate a column, which gives the maximum # encoding length among all encodings with the value TRUE rle_test[[&quot;max&quot;]] &lt;- max(rle_test[rle_test[, &quot;values&quot;] == TRUE, ][,&quot;lengths&quot;]) # Now we just have to subset for maximum length among all TRUE values and return the # according &quot;first index&quot;: rle_test[rle_test$lengths == rle_test$max &amp; rle_test$values == TRUE, ]$first_index } 8.5 Mathematical functionals Q: Implement arg_max(). It should take a function and a vector of inputs, and return the elements of the input where the function returns the highest value. For example, arg_max(-10:5, function(x) x ^ 2) should return -10. arg_max(-5:5, function(x) x ^ 2) should return c(-5, 5). Also implement the matching arg_min() function. A: arg_max(): arg_max &lt;- function(x, f){ x[f(x) == max(f(x))] } arg_min(): arg_min &lt;- function(x, f){ x[f(x) == min(f(x))] } Q: Challenge: read about the fixed point algorithm. Complete the exercises using R. 8.6 A family of functions Q: Implement smaller and larger functions that, given two inputs, return either the smaller or the larger value. Implement na.rm = TRUE: what should the identity be? (Hint: smaller(x, smaller(NA, NA, na.rm = TRUE), na.rm = TRUE) must be x, so smaller(NA, NA, na.rm = TRUE) must be bigger than any other value of x.) Use smaller and larger to implement equivalents of min(), max(), pmin(), pmax(), and new functions row_min() and row_max(). A: We can do almost everything as shown in the case study in the textbook. First we define the functions smaller_() and larger_(). We use the underscore suffix, to built up non suffixed versions on top, which will include the na.rm parameter. In contrast to the add() example from the book, we change two things at this step. We won’t include errorchecking, since this is done later at the top level and we return NA_integer_ if any of the arguments is NA (this is important, if na.rm is set to FALSE and wasn’t needed by the add() example, since + already returns NA in this case.) smaller_ &lt;- function(x, y){ if(anyNA(c(x, y))){return(NA_integer_)} out &lt;- x if(y &lt; x) {out &lt;- y} out } larger_ &lt;- function(x, y){ if(anyNA(c(x, y))){return(NA_integer_)} out &lt;- x if(y &gt; x) {out &lt;- y} out } We can take na.rm() from the book: rm_na &lt;- function(x, y, identity) { if (is.na(x) &amp;&amp; is.na(y)) { identity } else if (is.na(x)) { y } else { x } } To find the identity value, we can apply the same argument as in the textbook, hence our functions are also associative and the following equation should hold: 3 = smaller(smaller(3, NA), NA) = smaller(3, smaller(NA, NA)) = 3 So the identidy has to be greater than 3. When we generalize from 3 to any real number this means that the identity has to be greater than any number, which leads us to infinity. Hence identity has to be Inf for smaller() (and -Inf for larger()), which we implement next: smaller &lt;- function(x, y, na.rm = FALSE) { stopifnot(length(x) == 1, length(y) == 1, is.numeric(x) | is.logical(x), is.numeric(y) | is.logical(y)) if (na.rm &amp;&amp; (is.na(x) || is.na(y))) rm_na(x, y, Inf) else smaller_(x,y) } larger &lt;- function(x, y, na.rm = FALSE) { stopifnot(length(x) == 1, length(y) == 1, is.numeric(x) | is.logical(x), is.numeric(y) | is.logical(y)) if (na.rm &amp;&amp; (is.na(x) || is.na(y))) rm_na(x, y, -Inf) else larger_(x,y) } Like min() and max() can act on vectors, we can implement this easyly for our new functions. As shown in the book, we also have to set the init parameter to the identity value. r_smaller &lt;- function(xs, na.rm = TRUE) { Reduce(function(x, y) smaller(x, y, na.rm = na.rm), xs, init = Inf) } # some tests r_smaller(c(1:3, 4:(-1))) #&gt; [1] -1 r_smaller(NA, na.rm = TRUE) #&gt; [1] Inf r_smaller(numeric()) #&gt; [1] Inf r_larger &lt;- function(xs, na.rm = TRUE) { Reduce(function(x, y) larger(x, y, na.rm = na.rm), xs, init = -Inf) } # some tests r_larger(c(1:3), c(4:1)) #&gt; [1] 3 r_larger(NA, na.rm = TRUE) #&gt; [1] -Inf r_larger(numeric()) #&gt; [1] -Inf We can also create vectorised versions as shown in the book. We will just show the smaller() case to become not too verbose. v_smaller1 &lt;- function(x, y, na.rm = FALSE){ stopifnot(length(x) == length(y), is.numeric(x) | is.logical(x), is.numeric(y)| is.logical(x)) if (length(x) == 0) return(numeric()) simplify2array( Map(function(x, y) smaller(x, y, na.rm = na.rm), x, y) ) } v_smaller2 &lt;- function(x, y, na.rm = FALSE) { stopifnot(length(x) == length(y), is.numeric(x) | is.logical(x), is.numeric(y)| is.logical(x)) vapply(seq_along(x), function(i) smaller(x[i], y[i], na.rm = na.rm), numeric(1)) } # Both versions give the same results v_smaller1(1:10, c(2,1,4,3,6,5,8,7,10,9)) #&gt; [1] 1 1 3 3 5 5 7 7 9 9 v_smaller2(1:10, c(2,1,4,3,6,5,8,7,10,9)) #&gt; [1] 1 1 3 3 5 5 7 7 9 9 v_smaller1(numeric(), numeric()) #&gt; numeric(0) v_smaller2(numeric(), numeric()) #&gt; numeric(0) v_smaller1(c(1, NA), c(1, NA), na.rm = FALSE) #&gt; [1] 1 NA v_smaller2(c(1, NA), c(1, NA), na.rm = FALSE) #&gt; [1] 1 NA v_smaller1(NA,NA) #&gt; [1] NA v_smaller2(NA,NA) #&gt; [1] NA Of course, we are also able to copy paste the rest from the textbook, to solve the last part of the exercise: row_min &lt;- function(x, na.rm = FALSE) { apply(x, 1, r_smaller, na.rm = na.rm) } col_min &lt;- function(x, na.rm = FALSE) { apply(x, 2, r_smaller, na.rm = na.rm) } arr_min &lt;- function(x, dim, na.rm = FALSE) { apply(x, dim, r_smaller, na.rm = na.rm) } Q: Create a table that has and, or, add, multiply, smaller, and larger in the columns and binary operator, reducing variant, vectorised variant, and array variants in the rows. Fill in the cells with the names of base R functions that perform each of the roles. Compare the names and arguments of the existing R functions. How consistent are they? How could you improve them? Complete the matrix by implementing any missing functions. A In the following table we can see the requested base R functions, that we are aware of: and or add multiply smaller larger binary &amp;&amp; || reducing all any sum prod min max vectorised &amp; | + * pmin pmax array Notice that we were relatively strict about the binary row. Since the vectorised and reducing versions are more general, then the binary versions, we could have used them twice. However, this doesn’t seem to be the intention of this exercise. The last part of this exercise can be solved via copy pasting from the book and the last exercise for the binary row and creating combinations of apply() and the reducing versions for the array row. We think the array functions just need a dimension and an rm.na argument. We don’t know how we would name them, but sth. like sum_array(1, na.rm = TRUE) could be ok. The second part of the exercise is hard to solve complete. But in our opinion, there are two important parts. The behaviour for special inputs like NA, NaN, NULL and zero length atomics should be consistent and all versions should have a rm.na argument, for which the functions also behave consistent. In the follwing table, we return the output of `f`(x, 1), where f is the function in the first column and x is the special input in the header (the named functions also have an rm.na argument, which is FALSE by default). The order of the arguments is important, because of lazy evaluation. NA NaN NULL logical(0) integer(0) &amp;&amp; NA NA error NA NA all NA NA TRUE TRUE TRUE &amp; NA NA error logical(0) logical(0) || TRUE TRUE error TRUE TRUE any TRUE TRUE TRUE TRUE TRUE | TRUE TRUE error logical(0) logical(0) sum NA NaN 1 1 1 + NA NaN numeric(0) numeric(0) numeric(0) prod NA NaN 1 1 1 * NA NaN numeric(0) numeric(0) numeric(0) min NA NaN 1 1 1 pmin NA NaN numeric(0) numeric(0) numeric(0) max NA NaN 1 1 1 pmax NA NaN numeric(0) numeric(0) numeric(0) We can see, that the vectorised and reduced numerical functions are all consistent. However it is not, that the first three logical functions return NA for NA and NaN, while the 4th till 6th function all return TRUE. Then FALSE would be more consistent for the first three or the return of NA for all and an extra na.rm argument. In seems relatively hard to find an easy rule for all cases and especially the different behaviour for NULL is relatively confusing. Another good opportunity for sorting the functions would be to differentiate between “numerical” and “logical” operators first and then between binary, reduced and vectorised, like below (we left the last colum, which is redundant, because of coercion, as intended): `f(x,1)` NA NaN NULL logical(0) &amp;&amp; NA NA error NA || TRUE TRUE error TRUE all NA NA TRUE TRUE any TRUE TRUE TRUE TRUE &amp; NA NA error logical(0) | TRUE TRUE error logical(0) sum NA NaN 1 1 prod NA NaN 1 1 min NA NaN 1 1 max NA NaN 1 1 + NA NaN numeric(0) numeric(0) * NA NaN numeric(0) numeric(0) pmin NA NaN numeric(0) numeric(0) pmax NA NaN numeric(0) numeric(0) The other point are the naming conventions. We think they are clear, but it could be useful to provide the missing binary operators and name them for example ++, **, &lt;&gt;, &gt;&lt; to be consistent. Q: How does paste() fit into this structure? What is the scalar binary function that underlies paste()? What are the sep and collapse arguments to paste() equivalent to? Are there any paste variants that don’t have existing R implementations? A paste() behaves like a mix. If you supply only length one arguments, it will behave like a reducing function, i.e. : paste(&quot;a&quot;, &quot;b&quot;, sep = &quot;&quot;) #&gt; [1] &quot;ab&quot; paste(&quot;a&quot;, &quot;b&quot;,&quot;&quot;, sep = &quot;&quot;) #&gt; [1] &quot;ab&quot; If you supply at least one element with length greater then one, it behaves like a vectorised function, i.e. : paste(1:3) #&gt; [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; paste(1:3, 1:2) #&gt; [1] &quot;1 1&quot; &quot;2 2&quot; &quot;3 1&quot; paste(1:3, 1:2, 1) #&gt; [1] &quot;1 1 1&quot; &quot;2 2 1&quot; &quot;3 1 1&quot; We think it should be possible to implement a new paste() starting from p_binary &lt;- function(x, y = &quot;&quot;) { stopifnot(length(x) == 1, length(y) == 1) paste0(x,y) } The sep argument is equivalent to bind sep on every ... input supplied to paste(), but the last and then bind these results together. In relations: paste(n1, n2, ...,nm , sep = sep) &lt;=&gt; paste0(paste0(n1, sep), paste(n2, n3, ..., nm, sep = sep)) &lt;=&gt; paste0(paste0(n1, sep), paste0(n2, sep), ..., paste0(nn, sep), paste0(nm)) We can check this for scalar and non scalar input # scalar: paste(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, sep = &quot;_&quot;) #&gt; [1] &quot;a_b_c&quot; paste0(paste0(&quot;a&quot;, &quot;_&quot;), paste(&quot;b&quot;, &quot;c&quot;, sep = &quot;_&quot;)) #&gt; [1] &quot;a_b_c&quot; paste0(paste0(&quot;a&quot;, &quot;_&quot;), paste0(&quot;b&quot;, &quot;_&quot;), paste0(&quot;c&quot;)) #&gt; [1] &quot;a_b_c&quot; # non scalar paste(1:2, &quot;b&quot;, &quot;c&quot;, sep = &quot;_&quot;) #&gt; [1] &quot;1_b_c&quot; &quot;2_b_c&quot; paste0(paste0(1:2, &quot;_&quot;), paste(&quot;b&quot;, &quot;c&quot;, sep = &quot;_&quot;)) #&gt; [1] &quot;1_b_c&quot; &quot;2_b_c&quot; paste0(paste0(1:2, &quot;_&quot;), paste0(&quot;b&quot;, &quot;_&quot;), paste0(&quot;c&quot;)) #&gt; [1] &quot;1_b_c&quot; &quot;2_b_c&quot; collapse just binds the outputs for non scalar input together with the collapse input. In relations: for input A1, ..., An, where Ai = a1i:ami, paste(A1 , A2 , ..., An, collapse = collapse) &lt;=&gt; paste0( paste0(paste( a11, a12, ..., a1n), collapse), paste0(paste( a21, a22, ..., a2n), collapse), ................................................. paste0(paste(am-11, am-12, ..., am-1n), collapse), paste( am1, am2, ..., amn) ) One can see this easily by intuition from examples: paste(1:5, 1:5, 6, sep = &quot;&quot;, collapse = &quot;_x_&quot;) #&gt; [1] &quot;116_x_226_x_336_x_446_x_556&quot; paste(1,2,3,4, collapse = &quot;_x_&quot;) #&gt; [1] &quot;1 2 3 4&quot; paste(1:2,1:2,2:3,3:4, collapse = &quot;_x_&quot;) #&gt; [1] &quot;1 1 2 3_x_2 2 3 4&quot; We think the only paste version that is not implemented in base R is an array version. At least we are not aware of sth. like row_paste or paste_apply etc. "],
["function-operators.html", "9 Function operators 9.1 Behavioural FOs 9.2 Output FOs 9.3 Input FOs 9.4 Combining FOs", " 9 Function operators 9.1 Behavioural FOs Q: Write a FO that logs a time stamp and message to a file every time a function is run. A: Note that the example will create a file file in your current working directory: logger &lt;- function(f, filename){ force(f) filename_tmp &lt;- paste(filename, basename(tempfile()), sep = &quot;_&quot;) write(paste(&quot;created at:&quot;, Sys.time()), filename_tmp, append = TRUE) function(..., message = &quot;you can add a message at each call&quot;) { write(paste0(&quot;used at: &quot;, Sys.time(), &quot;, &quot;, message), filename_tmp, append = TRUE) f(...) } } # the following line creates a file, which name starts with &quot;mean_log_&quot; mean2 &lt;- logger(mean, &quot;mean_log&quot;) mean2(1:4, message = &quot;first time&quot;) mean2(1:4, message = &quot;second_time&quot;) Q: What does the following function do? What would be a good name for it? f &lt;- function(g) { force(g) result &lt;- NULL function(...) { if (is.null(result)) { result &lt;&lt;- g(...) } result } } runif2 &lt;- f(runif) runif2(5) #&gt; [1] 0.1090973 0.8933546 0.6849637 0.7362727 0.8324138 runif2(10) #&gt; [1] 0.1090973 0.8933546 0.6849637 0.7362727 0.8324138 A: It returns a new version of the inputfunction. That version will always return the result of it’s first run (in case this not NULL), no matter how the input changes. Good names could be first_run() or initial_return(). Q: Modify delay_by() so that instead of delaying by a fixed amount of time, it ensures that a certain amount of time has elapsed since the function was last called. That is, if you called g &lt;- delay_by(1, f); g(); Sys.sleep(2); g() there shouldn’t be an extra delay. A: We can do this with three little tricks (and the help of 42): delay_by_v2 &lt;- function(delay, f) { force(f) # we initialise the timestamp for the last run. We set a specific default value, # to ensure that the first run of the returned function will never be delayed last_runtime &lt;- Sys.time() - (delay + 42) function(...) { # we continually check if enough time passed with an (empty) while statement. while (Sys.time() &lt; last_runtime + delay) {} # we override the start for the next waiting interval. # Note that this is done on exit (after the function is evaluated) on.exit(last_runtime &lt;&lt;- Sys.time()) return(f(...)) } } Alternatively to the empty while statement we could have used Sys.sleep(). I would not recommend this solution, since ?Sys.sleep indicates that Sys.sleep() might have some overhead and seems not to be as exact as we need. Q: Write wait_until() which delays execution until a specific time. A: wait_until &lt;- function(time, f) { force(f) function(...) { while (Sys.time() &lt; time) {} return(f(...)) } } # a little test ptm &lt;- proc.time() m &lt;- wait_until(Sys.time() + 10, mean) m(1:3) proc.time() - ptm Q: There are three places we could have added a memoise call: why did we choose the one we did? download &lt;- memoise(dot_every(10, delay_by(1, download_file))) download &lt;- dot_every(10, memoise(delay_by(1, download_file))) download &lt;- dot_every(10, delay_by(1, memoise(download_file))) A: The second was chosen. It’s easy to see why, if we eliminate the other two options: The first version only prints a dot at every tenth download() call with a new input. This is because dot_every() is inside of memoise() and the counter created by dot_every() is not “activated” if the input is known. The third version takes one second for every call. Even if we already know the result and don’t download anything again. Q: Why is the remember() function inefficient? How could you implement it in more efficient way? Q: Why does the following code, from stackoverflow, not do what you expect? # return a linear function with slope a and intercept b. f &lt;- function(a, b) function(x) a * x + b # create a list of functions with different parameters. fs &lt;- Map(f, a = c(0, 1), b = c(0, 1)) fs[[1]](3) #&gt; [1] 0 # should return 0 * 3 + 0 = 0 How can you modify f so that it works correctly? A: You can read in the stackoverflow link that the question arose, because the original return of fs[[1]](3) was 4, which is due to lazy evaluation and could be solved by two users via force(): f &lt;- function(a, b) {force(a); force(b); function(x) a * x + b} However you can see in the result within the question that R’s behaviour was changed in this case and as Jan Kislinger points out on twitter: The real question should be: “How did they modify #rstats so that it works correctly?” otherwise it’s a tricky question :D Note that the same issue appears in the textbook: In the following example, we take a list of functions and delay each one. But when we try to evaluate the mean, we get the sum instead. funs &lt;- list(mean = mean, sum = sum) funs_m &lt;- lapply(funs, delay_by, delay = 0.1) funs_m$mean(1:10) #&gt; [1] 5.5 Which (as one can see) is not true anymore…actually it changed in R version 3.2: Higher order functions such as the apply functions and Reduce() now force arguments to the functions they apply in order to eliminate undesirable interactions between lazy evaluation and variable capture in closures. This resolves PR#16093. For further interested: PR#16093 will lead you to the subject “iterated lapply” within the R-devel Archives. Note that the behaviour in for loops is still as “the old lapply()” behaviour. 9.2 Output FOs Q: Create a negative() FO that flips the sign of the output of the function to which it is applied. A: negative &lt;- function(f){ force(f) function(...){ -f(...) } } Q: The evaluate package makes it easy to capture all the outputs (results, text, messages, warnings, errors, and plots) from an expression. Create a function like capture_it() that also captures the warnings and errors generated by a function. A: One way is just to capture the output of tryCatch() with identity handlers for errors and warnings: capture_trials &lt;- function(f){ force(f) function(...){ capture.output(tryCatch(f(...), error = function(e) e, warning = function(w) w) ) } } # we test the behaviour log_t &lt;- capture_trials(log) elements &lt;- list(1:10, c(-1, 10), c(TRUE, FALSE), letters) results &lt;- lapply(elements, function(x) log_t(x)) results #&gt; [[1]] #&gt; [1] &quot; [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 1.7917595 1.9459101&quot; #&gt; [2] &quot; [8] 2.0794415 2.1972246 2.3025851&quot; #&gt; #&gt; [[2]] #&gt; [1] &quot;&lt;simpleWarning in f(...): NaNs produced&gt;&quot; #&gt; #&gt; [[3]] #&gt; [1] &quot;[1] 0 -Inf&quot; #&gt; #&gt; [[4]] #&gt; [1] &quot;&lt;simpleError in f(...): non-numeric argument to mathematical function&gt;&quot; # further # results_detailed &lt;- lapply(elements, function(x) lapply(x, function(y))log2(x)) # results_detailed Q: Create a FO that tracks files created or deleted in the working directory (Hint: use dir() and setdiff().) What other global effects of functions might you want to track? A: We start with a short version to show the idea: track_dir &lt;- function(f){ force(f) function(...){ dir_old &lt;- dir() on.exit(if(!setequal(dir(), dir_old)){ message(&quot;files in your working directory were deleted or added by this function&quot;)}) f(...) } } # the following test will create the file &quot;delete_me&quot; in your working directory td &lt;- track_dir(dir.create) td(&quot;delete_me&quot;) Of course we can provide more information on the type of changes: track_dir &lt;- function(f){ force(f) function(...){ dir_old &lt;- dir() on.exit(if(!setequal(dir(), dir_old)){ message(&quot;Files in your working directory were deleted or added by this function.&quot;)}, add = TRUE) on.exit(if(length(setdiff(dir_old, dir()) != 0)){ message(paste0(&quot;The following files were deleted: &quot;, paste(setdiff(dir_old, dir()), collapse = &quot;, &quot;) ))}, add = TRUE) on.exit(if(length(setdiff(dir(), dir_old) != 0)){ message(paste0(&quot;The following files were added: &quot;, paste(setdiff(dir(), dir_old), collapse = &quot;, &quot;) ))}, add = TRUE) f(...) } } # the following test will again create two files in your working directory td &lt;- track_dir(sapply) td(c(&quot;delete_me&quot;, &quot;me_too&quot;), dir.create) Other global effects that might be worth tracking include changes regarding: the search path and/or introduced conflicts() options() and par() which modify global settings the path of the working directory environment variables the locale. 9.3 Input FOs Q: Our previous download() function only downloads a single file. How can you use partial() and lapply() to create a function that downloads multiple files at once? What are the pros and cons of using partial() vs. writing a function by hand? Q: Read the source code for plyr::colwise(). How does the code work? What are colwise()’s three main tasks? How could you make colwise() simpler by implementing each task as a function operator? (Hint: think about partial().) A: We describe how it works by commenting the source code: function (.fun, .cols = true, ...) { # We check if .cols is not a function, since it is possible to supply a # predicate function. # if so, the .cols arguments will be &quot;quoted&quot;, and filter() will # be a function that checks and evaluates these .cols within its other argument if (!is.function(.cols)) { .cols &lt;- as.quoted(.cols) filter &lt;- function(df) eval.quoted(.cols, df) } # otherwise, filter will be be Filter(), which applies the function # in .cols to every element of its other argument else { filter &lt;- function(df) Filter(.cols, df) } # the ... arguments are caught in the list dots dots &lt;- list(...) # a function is created, which will also be the return value. # it checks if its input is a data frame function(df, ...) { stopifnot(is.data.frame(df)) # if df is split (in &quot;plyr&quot; speaking), this will be taken into account... df &lt;- strip_splits(df) # now the columns of the data frame are chosen, depending on the input of .cols # this can chosen directly, via a predicate function, or all columns (default) filtered &lt;- filter(df) # if this means, that no columns are selected, an empty data frame will be returned if (length(filtered) == 0) return(data.frame()) # otherwise lapply will be called on all filtered columns, with # the .fun argument, which has to be provided by the user, and some other # arguments provided by the user, when calling the function (...) and # when defining the function (dots) out &lt;- do.call(&quot;lapply&quot;, c(list(filtered, .fun, ...), dots)) # the output will be named and converted from list into a data frame again names(out) &lt;- names(filtered) quickdf(out) } } &lt;environment: namespace:plyr&gt; Q: Write FOs that convert a function to return a matrix instead of a data frame, or a data frame instead of a matrix. If you understand S3, call them as.data.frame.function() and as.matrix.function(). A: as.matrix.function &lt;- function(f){ force(f) function(...){ as.matrix(f(...)) } } as.data.frame.function &lt;- function(f){ force(f) function(...){ as.data.frame(f(...)) } } Q: You’ve seen five functions that modify a function to change its output from one form to another. What are they? Draw a table of the various combinations of types of outputs: what should go in the rows and what should go in the columns? What function operators might you want to write to fill in the missing cells? Come up with example use cases. Q: Look at all the examples of using an anonymous function to partially apply a function in this and the previous chapter. Replace the anonymous function with partial(). What do you think of the result? Is it easier or harder to read? A: The results are easy to read. Especially the Map() examples profit in readability: library(pryr) #&gt; #&gt; Attaching package: &#39;pryr&#39; #&gt; The following object is masked _by_ &#39;.GlobalEnv&#39;: #&gt; #&gt; f ## From Functionals # 1 trims &lt;- c(0, 0.1, 0.2, 0.5) x &lt;- rcauchy(1000) unlist(lapply(trims, function(trim) mean(x, trim = trim))) #&gt; [1] -2.14471243 0.09442859 0.07433510 0.07655498 unlist(lapply(trims, partial(mean, x))) #&gt; [1] -2.14471243 0.09442859 0.07433510 0.07655498 # 2 xs &lt;- replicate(5, runif(10), simplify = FALSE) ws &lt;- replicate(5, rpois(10, 5) + 1, simplify = FALSE) unlist(Map(function(x, w) weighted.mean(x, w, na.rm = TRUE), xs, ws)) #&gt; [1] 0.5024602 0.4685572 0.5303112 0.5839586 0.6122118 unlist(Map(partial(weighted.mean, na.rm = TRUE), xs, ws)) #&gt; [1] 0.5024602 0.4685572 0.5303112 0.5839586 0.6122118 # 3 add &lt;- function(x, y, na.rm = FALSE) { if (na.rm &amp;&amp; (is.na(x) || is.na(y))) rm_na(x, y, 0) else x + y } r_add &lt;- function(xs, na.rm = TRUE) { Reduce(function(x, y) add(x, y, na.rm = na.rm), xs) } r_add_compact &lt;- function(xs, na.rm = TRUE) { Reduce(partial(add, na.rm = na.rm), xs) } r_add(1:4) #&gt; [1] 10 r_add_compact(1:4) #&gt; [1] 10 # 4 v_add1 &lt;- function(x, y, na.rm = FALSE) { stopifnot(length(x) == length(y), is.numeric(x), is.numeric(y)) if (length(x) == 0) return(numeric()) simplify2array( Map(function(x, y) add(x, y, na.rm = na.rm), x, y) ) } v_add1_compact &lt;- function(x, y, na.rm = FALSE) { stopifnot(length(x) == length(y), is.numeric(x), is.numeric(y)) if (length(x) == 0) return(numeric()) simplify2array( Map(partial(add, na.rm = na.rm), x, y) ) } v_add1(1:3, 2:4) #&gt; [1] 3 5 7 v_add1_compact(1:3, 2:4) #&gt; [1] 3 5 7 # 5 c_add &lt;- function(xs, na.rm = FALSE) { Reduce(function(x, y) add(x, y, na.rm = na.rm), xs, accumulate = TRUE) } c_add_compact &lt;- function(xs, na.rm = FALSE) { Reduce(partial(add, na.rm = na.rm), xs, accumulate = TRUE) } c_add(1:3) #&gt; [1] 1 3 6 c_add_compact(1:3) #&gt; [1] 1 3 6 ## From Function operators # 6 f &lt;- function(x) x ^ 2 partial(f) #&gt; function (...) #&gt; f(...) # 7 # Map(function(x, y) f(x, y, zs), xs, ys) # Map(partial(f, zs = zs), xs, yz) # 8 # f &lt;- function(a) g(a, b = 1) # f &lt;- partial(g, b = 1) # 9 compact &lt;- function(x) Filter(Negate(is.null), x) compact &lt;- partial(Filter, Negate(is.null)) # 10 # Map(function(x, y) f(x, y, zs), xs, ys) # Map(partial(f, zs = zs), xs, ys) # 11 funs2 &lt;- list( sum = function(...) sum(..., na.rm = TRUE), mean = function(...) mean(..., na.rm = TRUE), median = function(...) median(..., na.rm = TRUE) ) funs2 &lt;- list( sum = partial(sum, na.rm = TRUE), mean = partial(mean, na.rm = TRUE), median = partial(median, na.rm = TRUE) ) 9.4 Combining FOs Q: Implement your own version of compose() using Reduce and %o%. For bonus points, do it without calling function. A: We use the definition from the textbook: compose &lt;- function(f, g) { function(...) f(g(...)) } &quot;%o%&quot; &lt;- compose And then we build two versions. One via an anonymous function and one via partial(): compose_red &lt;- function(fs) { Reduce(function(f, g) function(...) f(g(...)), fs) } compose_red(c(mean, length, unique))(1:10) #&gt; [1] 10 compose_red_bonus &lt;- function(fs) { Reduce(partial(partial(`%o%`)), fs) } compose_red_bonus(c(mean, length, unique))(1:10) #&gt; [1] 10 Q: Extend and() and or() to deal with any number of input functions. Can you do it with Reduce()? Can you keep them lazy (e.g., for and(), the function returns once it sees the first FALSE)? A: We use and() and or() as defined in the textbook. They are lazy, since they are build up on &amp;&amp; and ||. Also their reduced versions stay lazy, as we will show at the end of the code and &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) &amp;&amp; f2(...) } } and_red &lt;- function(fs){ Reduce(function(f, g) and(f, g), fs) } or &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) || f2(...) } } or_red &lt;- function(fs){ Reduce(function(f, g) or(f, g), fs) } # Errors before the first TRUE will be returned tryCatch( or_red(c(is.logical, is.logical, stop, is.character))(&quot;a&quot;), error = function(e) e ) #&gt; &lt;simpleError in f1(...): a&gt; # Errors after the first TRUE won&#39;t be returned or_red(c(is.logical, is.logical, is.character, stop))(&quot;a&quot;) #&gt; [1] TRUE Q: Implement the xor() binary operator. Implement it using the existing xor() function. Implement it as a combination of and() and or(). What are the advantages and disadvantages of each approach? Also think about what you’ll call the resulting function to avoid a clash with the existing xor() function, and how you might change the names of and(), not(), and or() to keep them consistent. A: Both versions are implemented straight forward, as also the reduced versions. However, the parallel versions need a little bit more care: xor_fb1 &lt;- function(f1, f2){ force(f1); force(f2) function(...){ xor(f1(...), f2(...)) } } xor_fb2 &lt;- function(f1, f2){ force(f1); force(f2) function(...){ or(f1, f2)(...) &amp;&amp; !(and(f1, f2)(...)) } } # binary combination xor_fb1(is.logical, is.character)(&quot;a&quot;) #&gt; [1] TRUE xor_fb2(is.logical, is.character)(&quot;a&quot;) #&gt; [1] TRUE # parallel combination (results in an error) xor_fb1(c(is.logical, is.character), c(is.logical, is.character))(&quot;a&quot;) #&gt; Error in f1(...): could not find function &quot;f1&quot; xor_fb2(c(is.logical, is.character), c(is.logical, is.character))(&quot;a&quot;) #&gt; Error in f1(...): could not find function &quot;f1&quot; # reduced combination (results in an error) xor_fb1(c(is.logical, is.character, is.logical, is.character))(&quot;a&quot;) #&gt; Error in force(f2): argument &quot;f2&quot; is missing, with no default xor_fb2(c(is.logical, is.character, is.logical, is.character))(&quot;a&quot;) #&gt; Error in force(f2): argument &quot;f2&quot; is missing, with no default ### Reduced version xor_fb1_red &lt;- function(fs){ Reduce(function(f, g) xor_fb1(f, g), fs) } xor_fb2_red &lt;- function(fs){ Reduce(function(f, g) xor_fb2(f, g), fs) } # should return TRUE xor_fb1_red(c(is.logical, is.character, is.logical, is.character))(&quot;a&quot;) #&gt; [1] FALSE xor_fb2_red(c(is.logical, is.character, is.logical, is.character))(&quot;a&quot;) #&gt; [1] FALSE # should return FALSE xor_fb1_red(c(is.logical, is.logical, is.character, is.logical))(&quot;a&quot;) #&gt; [1] TRUE xor_fb2_red(c(is.logical, is.logical, is.character, is.logical))(&quot;a&quot;) #&gt; [1] TRUE # should return FALSE xor_fb1_red(c(is.logical, is.logical, is.character, is.character))(&quot;a&quot;) #&gt; [1] FALSE xor_fb2_red(c(is.logical, is.logical, is.character, is.character))(&quot;a&quot;) #&gt; [1] FALSE Q: Above, we implemented boolean algebra for functions that return a logical function. Implement elementary algebra (plus(), minus(), multiply(), divide(), exponentiate(), log()) for functions that return numeric vectors. A: plus &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) + f2(...) } } minus &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) - f2(...) } } multiply &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) * f2(...) } } divide &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) / f2(...) } } exponentiate &lt;- function(f1, f2) { force(f1); force(f2) function(...) { f1(...) ^ f2(...) } } # we rename log to log_ since log() already exists log_ &lt;- function(f1, f2) { force(f1); force(f2) function(...) { log(f1(...), f2(...)) } } # Test mns &lt;- minus(mean, function(x) x^2) mns(1:5) "],
["non-standard-evaluation.html", "10 Non standard evaluation 10.1 Capturing expressions 10.2 Non standard evaluation in subset 10.3 Scoping issues 10.4 Calling from another function 10.5 Substitute 10.6 The downsides of non-standard evaluation", " 10 Non standard evaluation 10.1 Capturing expressions Q: One important feature of deparse() to be aware of when programming is that it can return multiple strings if the input is too long. For example, the following call produces a vector of length two: g &lt;- function(x) deparse(substitute(x)) g(a + b + c + d + e + f + g + h + i + j + k + l + m + n + o + p + q + r + s + t + u + v + w + x + y + z) Why does this happen? Carefully read the documentation for ?deparse. Can you write a wrapper around deparse() so that it always returns a single string? A: deparse() has a width.cutoff argument (default 60 byte), which is according to ?deparse an: integer in [20, 500] determining the cutoff (in bytes) at which line-breaking is tried. Further: width.cutoff is a lower bound for the line lengths: deparsing a line proceeds until at least width.cutoff bytes have been output and e.g. arg = value expressions will not be split across lines. You can wrap it with for example with paste0(): deparse_without_cutoff &lt;- function(x){ paste0(deparse(x), collapse = &quot;&quot;) } It can be a little bit enhanced with a gsub(): gsub(&quot;\\\\s+&quot;, &quot; &quot;, paste0(deparse(substitute(x)))) This formats at least the spaces to a unified single space. However note that it is not possible to capture the exact input in every case: # spaces are unified substitute(1 + 1 + 1 + 1) #&gt; 1 + 1 + 1 + 1 quote(1 + 1 + 1 + 1) #&gt; 1 + 1 + 1 + 1 # leading zeros in numeric input are trimmed substitute(01) #&gt; [1] 1 quote(01) #&gt; [1] 1 Q: Why does as.Date.default() use substitute() and deparse()? Why does pairwise.t.test() use them? Read the source code. A: as.Date.default() uses them to convert unexpected input expressions (neither dates, nor NAs) into a character string and return it within an error message. pairwise.t.test() uses them to convert the names of its datainputs (response vector x and grouping factor g) into character strings to format these further into a part of the desired output. Q: pairwise.t.test() assumes that deparse() always returns a length one character vector. Can you construct an input that violates this expectation? What happens? A: We can pass an expression to one of pairwise.t.test()’s data input arguments, which exceeds the default cutoff width in deparse(). The expression will be split into a character vector of length greater 1. The deparsed data inputs are directly pasted (read the source code!) with “and” as separator and the result is just used to be displayed in the output. Just the data.name output will change (it will include more than one “and”). d=1 pairwise.t.test(2, d+d+d+d+d+d+d+d+d+d+d+d+d+d+d+d+d) #&gt; #&gt; Pairwise comparisons using t tests with pooled SD #&gt; #&gt; data: 2 and d + d + d + d + d + d + d + d + d + d + d + d + d + d + d + d + 2 and d #&gt; #&gt; &lt;0 x 0 matrix&gt; #&gt; #&gt; P value adjustment method: holm Q: f(), defined above, just calls substitute(). Why can’t we use it to define g()? In other words, what will the following code return? First make a prediction. Then run the code and think about the results. f &lt;- function(x) substitute(x) g &lt;- function(x) deparse(f(x)) g(1:10) # -&gt; x g(x) # -&gt; x g(x + y ^ 2 / z + exp(a * sin(b))) # -&gt; x A: All return x, because substitute()’s second argument env is the current evaluation environment environment(). If you call substitute from another function, you may want to set the env argument to parent.frame(), which refers to the calling environment: f &lt;- function(x) substitute(x, env = parent.frame()) g &lt;- function(x) deparse(f(x)) g(1:10) # -&gt; 1:10 g(x) # -&gt; x g(x + y ^ 2 / z + exp(a * sin(b))) # -&gt; x + y ^ 2 / z + exp(a * sin(b)) 10.2 Non standard evaluation in subset Q: Predict the results of the following lines of code: eval(quote(eval(quote(eval(quote(2 + 2)))))) # -&gt; 4 eval(eval(quote(eval(quote(eval(quote(2 + 2))))))) # -&gt; 4 quote(eval(quote(eval(quote(eval(quote(2 + 2))))))) # eval(quote(eval(quote(eval(quote(2 + 2)))))) A: An outside quote() always wins… Q: subset2() has a bug if you use it with a single column data frame. What should the following code return? How can you modify subset2() so it returns the correct type of object? subset2 &lt;- function(x, condition) { condition_call &lt;- substitute(condition) r &lt;- eval(condition_call, x) x[r, ] } sample_df2 &lt;- data.frame(x = 1:10) subset2(sample_df2, x &gt; 8) #&gt; [1] 9 10 A: Well what does base::subset return? subset(sample_df2, x &gt; 8) #&gt; x #&gt; 9 9 #&gt; 10 10 So we want that the output is always a data frame and not an atomic vector like above. To return always a data frame change the last row in subset2() to x[r, , drop = FALSE]. Q: The real subset function (subset.data.frame()) removes missing values in the condition. Modify subset2() to do the same: drop the offending rows. A: This time change the last row to x[!is.na(r) &amp; r, , drop = FALSE]. Alternatively you can also exclude NAs from the subset via setting them to FALSE with r[is.na(r)] &lt;- FALSE. Q: What happens if you use quote() instead of substitute() inside of subset2()? A: R looks for condition within sample_df but can’t find it, so it is looking in the execution environment for condition and evaluates it to a &gt;= 4 (as supplied in the input). In the actual environment and the remaining environments (the global environment and the search path) a can’t be found and we get the error “Error in eval(expr, envir, enclos) : object ‘a’ not found”. To understand this in detail, it is very important to forget about substitute() for a moment and just explore where eval() evaluates its supplied expressions for all kind of supplied envir and enclos arguments. Before you get crazy (since a lot of stuff is coming togetehr here), look also here and here. The above is opposed to substitute(), which isn’t only capturing the symbol condition, but the expression slot of the condition promise object, which means, that substitute() notices, when a promise is assigned as it’s first argument and also stores this information. To be more precise, we quote from R Language Definition A formal argument is really a promise, an object with three slots, one for the expression that defines it, one for the environment in which to evaluate that expression, and one for the value of that expression once evaluated. substitute will recognize a promise variable and substitute the value of its expression slot. Q: The second argument in subset() allows you to select variables. It treats variable names as if they were positions. This allows you to do things like subset(mtcars, , -cyl) to drop the cylinder variable, or subset(mtcars, , disp:drat) to select all the variables between disp and drat. How does this work? I’ve made this easier to understand by extracting it out into its own function. select &lt;- function(df, vars) { vars &lt;- substitute(vars) var_pos &lt;- setNames(as.list(seq_along(df)), names(df)) pos &lt;- eval(vars, var_pos) df[, pos, drop = FALSE] } select(mtcars, -cyl) A: We can comment what happens select &lt;- function(df, vars) { vars &lt;- substitute(vars) var_pos &lt;- setNames(as.list(seq_along(df)), names(df)) # We create a list with # columnnumbers and -names of the original data.frame. pos &lt;- eval(vars, var_pos) # We evaluate the supplied variable names within # the list of all names of the data.frame and return the values of the mathing # variable names and list elements (the positions of supplied variables # within the supplied data.frame). df[, pos, drop = FALSE] # now we just subset the data.frame by its column index. } select(mtcars, -cyl) This works also for ranges, i.e., select(mtcars, cyl:drat) because of the usual precedences cyl:drat becomes 2:5. Q: What does evalq() do? Use it to reduce the amount of typing for the examples above that use both eval() and quote(). A: From the help of eval(): The evalq form is equivalent to eval(quote(expr), …). eval evaluates its first argument in the current scope before passing it to the evaluator: evalq avoids this. In other “words”: identical(eval(quote(x)), evalq(x)) # -&gt; TRUE The examples above can be written as: eval(quote(eval(quote(eval(quote(2 + 2)))))) #-&gt; evalq(evalq(evalq(2 + 2))) eval(eval(quote(eval(quote(eval(quote(2 + 2))))))) #-&gt; eval(evalq(evalq(evalq(2 + 2)))) quote(eval(quote(eval(quote(eval(quote(2 + 2))))))) #-&gt; quote(evalq(evalq(evalq(2 + 2)))) 10.3 Scoping issues Q: plyr::arrange() works similarly to subset(), but instead of selecting rows, it reorders them. How does it work? What does substitute(order(...)) do? Create a function that does only that and experiment with it. A: substitute(order(...)) orders the indices of the supplied columns in ... in the context of the submitted data.frame argument, beginning with the first submitted column. We can just copy the part of the source code from plyr::arrange() and see if it does what we expect: arrange_indices &lt;- function (df, ...){ stopifnot(is.data.frame(df)) ord &lt;- eval(substitute(order(...)), df, parent.frame()) ord } identical(arrange_indices(iris, Species, Sepal.Length), order(iris$Species, iris$Sepal.Length)) Q: What does transform() do? Read the documentation. How does it work? Read the source code for transform.data.frame(). What does substitute(list(...)) do? A: As stated in the next question transform() is similar to plyr::mutate() but plyr::mutate() applies the transformations sequentially so that transformation can refer to columns that were just created. The rest of the question can be answered, by just commenting the source code: # Setting &quot;...&quot; as function argument allows the user to specify any kind of extra # argument to the function. In this case we can expect arguments of the form # new_col1 = foo(col_in_data_argument), new_col2 = foo(col_in_data_argument),... &gt; transform.data.frame function (`_data`, ...) { # subsitute(list(...)) takes the dots into a list and just returns the expression # `list(...)`. Nothing is evaluated until now (which is important). # Evaluation of the expression happens with the `eval()` function. # This means: all the names of the arguments in `...` like new_col1, new_col2,... # become names of the list `e`. # All functions/variables like foo(column_in_data_argument) are evaluated within # the context (environment) of the `_data` argument supplied to the `transform()` # function (this is specified by the second argument of the eval() function). e &lt;- eval(substitute(list(...)), `_data`, parent.frame()) # Everything that happens from now on is just about formatting and # returning the correct columns: # We save the names of the list (the names of the added columns) tags &lt;- names(e) # We create a numeric vector and check if the tags (names of the added columns) # appear in the names of the supplied `_data` argument. If yes, we save the # column number, if not we save an NA. inx &lt;- match(tags, names(`_data`)) # We create a logical vector, which is telling us if a column_name is already in the # data.frame (TRUE) or really new (FALSE) matched &lt;- !is.na(inx) # If any new column is corresponding to an old column name, # the correspong old columns will be overwritten if (any(matched)) { `_data`[inx[matched]] &lt;- e[matched] `_data` &lt;- data.frame(`_data`) } # If there is at least one new column name, all of these new columns will be bound # on the old data.frame (which might have changed a bit during the first if). Then the # transformed `data_` is returned if (!all(matched)) do.call(&quot;data.frame&quot;, c(list(`_data`), e[!matched])) # Also in case of no new column names the transformed `data_` is returned else `_data` } Q: plyr::mutate() is similar to transform() but it applies the transformations sequentially so that transformation can refer to columns that were just created: df &lt;- data.frame(x = 1:5) transform(df, x2 = x * x, x3 = x2 * x) plyr::mutate(df, x2 = x * x, x3 = x2 * x) How does mutate work? What’s the key difference between mutate() and transform()? A: The main difference is the possibility of sequential transformations. Another difference is that unnamed added columns will be thrown away. For the implementation many ideas are are the same. However the key difference is that for the sequential transformations, a for loop is created which iterates over a list of expressions and simultaneously changes the environment for the evaluation of the next expression (which is the supplied data). This should become clear with some comments on the code: &gt; mutate function (.data, ...) { stopifnot(is.data.frame(.data) || is.list(.data) || is.environment(.data)) # we catch everything supplied in `...`. But this time we save this in a list of expressions. # However, again the added column names will be the names of this list. cols &lt;- as.list(substitute(list(...))[-1]) cols &lt;- cols[names(cols) != &quot;&quot;] # all unnamed arguments in `...` will be thrown away, in # contrast to `transform()` above, which just creates new columnnames. # Now a for loop evaluates all added columns iteratively in the context (environment) # of the data. # We start with the first added column:. # If the column name is already in the data, the old column will be overritten. # If the column name is new, it will be created # Since the underlying data (the environment for the evaluation) gets automatically # &quot;updated&quot; in every iteration of the for loop, it will be possible to use the new columns # directly in the next iteration (which relates to the next added column) for (col in names(cols)) { .data[[col]] &lt;- eval(cols[[col]], .data, parent.frame()) } # Afterwards the data gets returned .data } Q: What does with() do? How does it work? Read the source code for with.default(). What does within() do? How does it work? Read the source code for within.data.frame(). Why is the code so much more complex than with()? A: with() is a generic function that allows writing an expression (second argument) that refers to variablenames of data (first argument) as if the corresponding variables were objects themselves. with() evaluates the expression via an eval(substitute(expr), data, enclos = parent.frame()) construct in a temporary environment, which has the calling frame as a parent. This also means that variables that aren’t found in data, will be looked up in with()’s calling environment. As stated in ?with, this is useful for modelling functions. In contrast to with(), which returns the value of the evaluated expression, within() returns the modified object. So within() can be used as an alternative to base::transform(). within() first creates an environment with data as parent and within()’s calling environment as grandparent. This environment becomes changed, since afterwards the expression is evaluated inside of it. The rest of the code converts this environment into a list and ensures that new variables are not overriden by the former ones. 10.4 Calling from another function Q: The following R functions all use NSE. For each, describe how it uses NSE, and read the documentation to determine its escape hatch. rm() library() and require() substitute() data() data.frame() A: For NSE in rm(), we just look at its first two arguments: ... and list = character(). If we supply expressions to ... (which can also be character vectors) , these will be caught by match.call() and become an unevaluated call (in this case a pairlist). However, rm() copies and converts the expressions into a character representation and concatenates these with the character vector supplied to the list argument. Then the removing starts… The escape hatch is to supply the objects to be removed as a character vector to rm()’s list argument. You can supply the input to library()’s and require()’s first argument (package) with or without quotes. In the default case (character.only = FALSE) the input to package will be converted via as.character(substitute(package)). To ommit this, just supply a character vector and set character.only = TRUE. substitute() and eval()/quote are the basic functions for NSE. To see how it’s done one has to understand parse trees and/or look into the underlying C code. The problematic behaviour of substitute() is pretty obvious. There might be some insights that make it predictable, but since substitute() is written for NSE and only contains the arguments expr and env, it seems that no escape hatch exists. Like rm() data() has the first arguments ... and list = character(). Again you can supply unquoted or quoted names to .... These will be caught, converted to character via as.character(substitute(list(...))[-1L]) and concatenated with the character input of the list argument. The escape hatch is similar to rm(): use explicitly the list argument. data.frame()’s first argument, ..., gets caught once via object &lt;- as.list(substitute(list(...)))[-1L] and once x &lt;- list(...). First one is used among others to create rownames. This can be suppressed via the setting of the argument row.names, which lets you supply a vector or specifing a column of the data.frame for the explicit naming of rows. x will be deparsed later and is then used to create the columnnames. Since this process underlies several complex rules in cases of “special namings”, data.frame() provides the check.names argument. One can set check.names = FALSE, to ensure that columns will be named however they are supplied to data.frame(). Q: Base functions match.fun(), page(), and ls() all try to automatically determine whether you want standard or non-standard evaluation. Each uses a different approach. Figure out the essence of each approach then compare and contrast. A: match.fun uses NSE if you pass something other than a length-one character or symbol, and does not use NSE otherwise. page uses NSE if you pass something other than a length-one character. Symbols would still trigger NSE. ls triggers NSE substitute if it cannot evaluate the directory passed as a variable, and triggers NSE deparse if the result is not a character. The ls method seems safest of the three approaches, but is also the least performant. Q: Add an escape hatch to plyr::mutate() by splitting it into two functions. One function should capture the unevaluated inputs. The other should take a data frame and list of expressions and perform the computation. A: We look again at the source code of plyr::mutate(): plyr::mutate #&gt; function (.data, ...) #&gt; { #&gt; stopifnot(is.data.frame(.data) || is.list(.data) || is.environment(.data)) #&gt; cols &lt;- as.list(substitute(list(...))[-1]) #&gt; cols &lt;- cols[names(cols) != &quot;&quot;] #&gt; for (col in names(cols)) { #&gt; .data[[col]] &lt;- eval(cols[[col]], .data, parent.frame()) #&gt; } #&gt; .data #&gt; } #&gt; &lt;environment: namespace:plyr&gt; What we want is to have the local variable “cols” as an argument of our new (wrapped) escape hatch function (analogously as shown with subset2_q() in the textbook). Therefore we create: get_cols &lt;- function(...) { ll &lt;- as.list(substitute(list(...))) ll[names(ll) != &quot;&quot;] } We also want a function, that works with “cols” and performs the computation (the for loop in the original plyr::mutate()): mutate_cols &lt;- function(df, cols) { for (col in names(cols)) { df[[col]] &lt;- eval(cols[[col]], df, parent.frame()) } df } Now we can wrap these with our new mutate function and have a nice interface: mutate2 &lt;- function(df, ...) { mutate_cols(df, get_cols(df, ...)) } # a little test df &lt;- data.frame(x = 1:5) identical( plyr::mutate(df, x2 = x * x, x3 = x2 * x), mutate2(df, x2 = x * x, x3 = x2 * x) ) #&gt; [1] TRUE Q: What’s the escape hatch for ggplot2::aes()? What about plyr::.()? What do they have in common? What are the advantages and disadvantages of their differences? One can call rename_aes directly. plyr::. lets you specify an env in which to evaluate .... Both evaluate ... using match.call() and create a structure out of them. plyr::. probably requires less knowledge about internals, but is also less customizable. Q: The version of subset2_q() I presented is a simplification of real code. Why is the following version better? subset2_q &lt;- function(x, cond, env = parent.frame()) { r &lt;- eval(cond, x, env) x[r, ] } Rewrite subset2() and subscramble() to use this improved version. A: subset2_q_old &lt;- function(x, condition) { r &lt;- eval(condition, x, parent.frame()) x[r, ] } subset2_q &lt;- function(x, cond, env = parent.frame()) { r &lt;- eval(cond, x, env) x[r, ] } The modified version of subset2_q allows you to specify an environment in which to evaluate the condition, which allows you to run subset2_q() in more situations (such as within a dataframe). subset2 &lt;- function(x, condition, env = parent.frame()) { subset2_q(x, substitute(condition), env) } scramble &lt;- function(x) x[sample(nrow(x)), ] subscramble &lt;- function(x, condition, env = parent.frame()) { condition &lt;- substitute(condition, env) scramble(subset2_q(x, condition, env)) } 10.5 Substitute Q: Use pryr::subs() to convert the LHS to the RHS for each of the following pairs: a + b + c -&gt; a * b * c f(g(a, b), c) -&gt; (a + b) * c f(a &lt; b, c, d) -&gt; if (a &lt; b) c else d A: subs(a + b + c, list(&quot;+&quot; = quote(`*`))) # -&gt; `a * b * c` subs(f(g(a, b), c), list(g = quote(`+`), f = quote(`*`))) # -&gt; `(a + b) * c` subs(f(a &lt; b, c, d), list(f = quote(`if`))) # -&gt; `if (a &lt; b) c else d` Q: For each of the following pairs of expressions, describe why you can’t use subs() to convert one to the other. a + b + c -&gt; a + b * c f(a, b) -&gt; f(a, b, c) f(a, b, c) -&gt; f(a, b) A: a + b + c -&gt; a + b * c You can’t convert one “+” to “+” and the other to “*“, because subs() converts either all instances of the”+&quot; or no instances of the “+”. f(a, b) -&gt; f(a, b, c) subs() cannot be used to add new arguments, only convert. f(a, b, c) -&gt; f(a, b) subs() cannot be used to subtract new arguments, only convert. Q: How does pryr::named_dots() work? Read the source. A: It captures the dot arguments using pryr::dots (which is just eval(substitute(alist(...)))), and then gets the names of the arguments, using “” for the arguments without names. If all the args are “”, it simply returns the args. Otherwise, it names the args with their values, and returns the renamed list of args. 10.6 The downsides of non-standard evaluation Q: What does the following function do? What’s the escape hatch? Do you think that this is an appropriate use of NSE? nl &lt;- function(...) { dots &lt;- pryr::named_dots(...) lapply(dots, eval, parent.frame()) } A: nl() extracts the dots, names them, and then evaluates them in the global namespace. This returns a list of arguments that are named by what is literally in the dots, with the values of what the dots evaluate to. For example: nl(1, 2 + 2, mean(c(3, 5))) #&gt; $`1` #&gt; [1] 1 #&gt; #&gt; $`2 + 2` #&gt; [1] 4 #&gt; #&gt; $`mean(c(3, 5))` #&gt; [1] 4 You can always call the underlying lapply directly as an escape hatch. However, it is a toy example and we are not really sure what you would gain from actually using this. Q: Instead of relying on promises, you can use formulas created with ~ to explicitly capture an expression and its environment. What are the advantages and disadvantages of making quoting explicit? How does it impact referential transparency? A: Using formulas in this manner would allow for referential transparency, but it would make working with NSE much more verbose. In any situation in which it is worth using NSE, it would also be worth not using formulas like this. Q: Read the standard non-standard evaluation rules found at http://developer.r-project.org/nonstandard-eval.pdf. "],
["expressions.html", "11 Expressions 11.1 Structure of expressions 11.2 Names 11.3 Calls 11.4 Capturing the current call 11.5 Pairlists 11.6 Parsing and deparsing 11.7 Walking the AST with recursive functions", " 11 Expressions 11.1 Structure of expressions Q: There’s no existing base function that checks if an element is a valid component of an expression (i.e., it’s a constant, name, call, or pairlist). Implement one by guessing the names of the “is” functions for calls, names, and pairlists. A: is.valid &lt;- function(x){ out &lt;- FALSE if(is.atomic(x) &amp; length(x) == 1){out &lt;- TRUE} # another possibility to check for constants would be # identical(x, substitute(x)) if(is.call(x)){out &lt;- TRUE} if(is.name(x)){out &lt;- TRUE} if(is.pairlist(x)){out &lt;- TRUE} out } Q: pryr::ast() uses non-standard evaluation. What’s its escape hatch to standard evaluation? A: You can call pryr::call_tree directly. Q: What does the call tree of an if statement with multiple else conditions look like? A: It depends a little bit how it is written. Here the infix version: pryr::ast(`if`(FALSE, &quot;first&quot;, `if`(TRUE, &quot;second&quot;, `if`(TRUE, &quot;third&quot;, &quot;fourth&quot;)))) #&gt; \\- () #&gt; \\- `if #&gt; \\- FALSE #&gt; \\- &quot;first&quot; #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- &quot;second&quot; #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- &quot;third&quot; #&gt; \\- &quot;fourth&quot; And here the “normal” version: pryr::ast(if (FALSE) { &quot;first&quot; } else ( if (TRUE) { &quot;second&quot; } else ( if (TRUE) { &quot;third&quot; } else ( &quot;fourth&quot; ) ) )) #&gt; \\- () #&gt; \\- `if #&gt; \\- FALSE #&gt; \\- () #&gt; \\- `{ #&gt; \\- &quot;first&quot; #&gt; \\- () #&gt; \\- `( #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- () #&gt; \\- `{ #&gt; \\- &quot;second&quot; #&gt; \\- () #&gt; \\- `( #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- () #&gt; \\- `{ #&gt; \\- &quot;third&quot; #&gt; \\- () #&gt; \\- `( #&gt; \\- &quot;fourth&quot; However, under the hood the language will call another base if statement. So else if seems to be for human readibility. Q: Compare ast(x + y %+% z) to ast(x ^ y %+% z). What do they tell you about the precedence of custom infix functions? A: Comparison of the syntax trees: # for ast(x + y %+% z) # y %+% z will be calculated first and the result will be added to x pryr::ast(x + y %+% z) #&gt; \\- () #&gt; \\- `+ #&gt; \\- `x #&gt; \\- () #&gt; \\- `%+% #&gt; \\- `y #&gt; \\- `z # for ast(x ^ y %+% z) # x^y will be calculated first, and the result will be used as first argument of `%+%()` pryr::ast(x ^ y %+% z) #&gt; \\- () #&gt; \\- `%+% #&gt; \\- () #&gt; \\- `^ #&gt; \\- `x #&gt; \\- `y #&gt; \\- `z So we can conclude that custom infix functions must have a precedence between addition and exponentiation. The general precedence rules can be found for example here Q: Why can’t an expression contain an atomic vector of length greater than one? Which one of the six types of atomic vector can’t appear in an expression? Why? A: Because you can’t type an expression that evaluates to an atomic of greater length than one without using a function, which means that these expressions would be calls. Also raws can’t appear in expressions, because of a similar reason. We think they are impossible to construct without using as.raw, which would mean that we will also end up with a call. Note also that imaginary parts of complex numbers work: pryr::ast(1i) #&gt; \\- 0+1i 11.2 Names Q: You can use formals() to both get and set the arguments of a function. Use formals() to modify the following function so that the default value of x is missing and y is 10. g &lt;- function(x = 20, y) { x + y } A: formals(g) &lt;- alist(x = , y = 10) Similarly one can change the body of the function through body&lt;-() and also the environment via environment&lt;-(). Q: Write an equivalent to get() using as.name() and eval(). Write an equivalent to assign() using as.name(), substitute(), and eval(). (Don’t worry about the multiple ways of choosing an environment; assume that the user supplies it explicitly.) A: get3 &lt;- function(x, env = parent.frame()){ eval(as.name(x), env) } assign3 &lt;- function(x, value, env) { eval(substitute(x &lt;- value,list(x = as.name(x), value = value)), env) if (length(x) &gt; 1) warning(&#39;only the first element is used as variable name&#39;) } 11.3 Calls Q: The following two calls look the same, but are actually different: (a &lt;- call(&quot;mean&quot;, 1:10)) #&gt; mean(1:10) (b &lt;- call(&quot;mean&quot;, quote(1:10))) #&gt; mean(1:10) identical(a, b) #&gt; [1] FALSE What’s the difference? Which one should you prefer? A: call evalulates its ... arguments. So in the first call 1:10 will be evaluated to an integer (1, 2, 3, …, 10) and in the second call quote() compensates the effect of the evaluation, so that b’s second element will be the expression 1:10 (which is again a call): as.list(a) #&gt; [[1]] #&gt; mean #&gt; #&gt; [[2]] #&gt; [1] 1 2 3 4 5 6 7 8 9 10 as.list(b) #&gt; [[1]] #&gt; mean #&gt; #&gt; [[2]] #&gt; 1:10 We can create an example, where we can see the consequences directly: # h &lt;- call(&quot;mean&quot;, z) ##&gt; Error: object &#39;z&#39; not found h &lt;- call(&quot;mean&quot;, quote(z)) # eval(h) ##&gt; Error in mean(z) : object &#39;z&#39; not found z &lt;- 1:10 eval(h) #&gt; [1] 5.5 From my intuition I would prefer the second version, since it behaves more like lazy evaluation, but I am not sure if this is the correct answer as indended by the exercise. Q: Implement a pure R version of do.call(). A: do.call2 &lt;- function(what, args, quote = FALSE, env = parent.frame()){ if(!is.list(args)) stop(&quot;second argument must be a list&quot;) if (quote) args &lt;- lapply(args, enquote) eval(as.call(c(what, args)), env) } Q: Concatenating a call and an expression with c() creates a list. Implement concat() so that the following code works to combine a call and an additional argument. concat(quote(f), a = 1, b = quote(mean(a))) #&gt; f(a = 1, b = mean(a)) A: concat &lt;- function(f, ...){ as.call(c(f, list(...))) } concat(quote(f), a = 1, b = quote(mean(a))) #&gt; f(a = 1, b = mean(a)) Q: Since list()s don’t belong in expressions, we could create a more convenient call constructor that automatically combines lists into the arguments. Implement make_call() so that the following code works. make_call(quote(mean), list(quote(x), na.rm = TRUE)) #&gt; mean(x, na.rm = TRUE) make_call(quote(mean), quote(x), na.rm = TRUE) #&gt; mean(x, na.rm = TRUE) A: make_call &lt;- function(x, ...){ as.call(c(x, ...)) } make_call(quote(mean), list(quote(x), na.rm = TRUE)) #&gt; mean(x, na.rm = TRUE) make_call(quote(mean), quote(x), na.rm = TRUE) #&gt; mean(x, na.rm = TRUE) Q: How does mode&lt;- work? How does it use call()? A: We can explain it best, when we comment the source code: function (x) { # when x is an expression, mode will(x) return &quot;expression&quot; if (is.expression(x)) return(&quot;expression&quot;) # when x is a call (or language, which is exactly the same), the first element # of the call will be coerced to character. # If the call is an autoprinting (like in quote((1))), mode will return &quot;(&quot;. # For any other call, mode will return &quot;call&quot; if (is.call(x)) return(switch(deparse(x[[1L]])[1L], `(` = &quot;(&quot;, &quot;call&quot;)) # if x is a name (or a symbol, which is exactly the same), then mode will return &quot;name&quot; if (is.name(x)) &quot;name&quot; # otherwise, mode will return dependent on typeof(x). If typeof(x) is double or integer, # mode will return &quot;numeric&quot;. If typeof(x) is closure, builtin or special, mode(x) will # return &quot;function&quot;. And in all other cases, mode will just return typeof(x) else switch(tx &lt;- typeof(x), double = , integer = &quot;numeric&quot;, closure = , builtin = , special = &quot;function&quot;, tx) } &lt;bytecode: 0x000000000c4e66e0&gt; &lt;environment: namespace:base&gt; As commented above, mode() uses is.call() to distinguish autoprint- and “normal” calls with the help of a separate switch(). Q: Read the source for pryr::standardise_call(). How does it work? Why is is.primitive() needed? A: It evaluates the first element of the call, which is usually the name of a function, but can also be another call. Then is uses match.call() to get the standard names for all the arguments. is.primitive() is used as an escape to just return the call instead of using match.call() if the function passed is a primitive. This is done because match.call() does not work for primitives. Q: standardise_call() doesn’t work so well for the following calls. Why? library(pryr) standardise_call(quote(mean(1:10, na.rm = TRUE))) #&gt; mean(x = 1:10, na.rm = TRUE) standardise_call(quote(mean(n = T, 1:10))) #&gt; mean(x = 1:10, n = T) standardise_call(quote(mean(x = 1:10, , TRUE))) #&gt; mean(x = 1:10, , TRUE) A: Q: Read the documentation for pryr::modify_call(). How do you think it works? Read the source code. A: Again, we explain by commenting the source function (call, new_args) { # check if call is a call and new_args is a list stopifnot(is.call(call), is.list(new_args)) # standardise the call call &lt;- standardise_call(call) # check if the supplied new_args list has any unnamed elements. # if so, an error occurs. nms &lt;- names(new_args) %||% rep(&quot;&quot;, length(new_args)) if (any(nms == &quot;&quot;)) { stop(&quot;All new arguments must be named&quot;, call. = FALSE) } # every name element of the call, for which a new argument was supplied by the user, # becomes overwritten for (nm in nms) { call[[nm]] &lt;- new_args[[nm]] } # finally the modified call is returned call } &lt;environment: namespace:pryr&gt; Q: Use ast() and experimentation to figure out the three arguments in an if() call. Which components are required? What are the arguments to the for() and while() calls? A: if: ## All these return an error # pryr::ast(if) # pryr::ast(if()) # pryr::ast(if{}) # pryr::ast(if(){}) # pryr::ast(if(TRUE)) ## This is the minimum required pryr::ast(if(TRUE){1}) #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- () #&gt; \\- `{ #&gt; \\- 1 ## One can also supply an alternative expression pryr::ast(if(TRUE){} else {3}) #&gt; \\- () #&gt; \\- `if #&gt; \\- TRUE #&gt; \\- () #&gt; \\- `{ #&gt; \\- () #&gt; \\- `{ #&gt; \\- 3 ## However, one has to supply the compound expression (the first one), ## otherwise we get an error # pryr::ast(if(TRUE) # else {3}) # So this is how if basically works pryr::ast(if(cond)expr) #&gt; \\- () #&gt; \\- `if #&gt; \\- `cond #&gt; \\- `expr # and here within a call eval(call(&quot;if&quot;, TRUE, 1)) #&gt; [1] 1 eval(call(&quot;if&quot;, TRUE, 1, 2)) #&gt; [1] 1 eval(call(&quot;if&quot;, FALSE, 1, 2)) #&gt; [1] 2 for: ## All these return an error # pryr::ast(for) # pryr::ast(for{}) # pryr::ast(for()) # pryr::ast(for(){}) # pryr::ast(for(in){}) # pryr::ast(for(var in){}) # pryr::ast(for(var in 10)) # pryr::ast(for(in 10){}) ## This is the minimum required pryr::ast(for(var in 10){}) #&gt; \\- () #&gt; \\- `for #&gt; \\- `var #&gt; \\- 10 #&gt; \\- () #&gt; \\- `{ ## So this is how for basically works pryr::ast(for(var in seq)expr) #&gt; \\- () #&gt; \\- `for #&gt; \\- `var #&gt; \\- `seq #&gt; \\- `expr ## And here within a call (note that we need quote, since var has to be a nanme ## and expr has to be an expression) eval(call(&quot;for&quot;, var = quote(i), seq = 1:3, expr = quote(print(i)))) #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 ## as infix function it looks a little bit easier `for`(i, 1:3, print(i)) #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 while: ## All these return an error # pryr::ast(while) # pryr::ast(while()) # pryr::ast(while(TRUE)) # pryr::ast(while(){}) # pryr::ast(while()1) # pryr::ast(while(TRUE){}) ## This is the minimum required pryr::ast(while(TRUE)1) #&gt; \\- () #&gt; \\- `while #&gt; \\- TRUE #&gt; \\- 1 ## So this is how while basically works pryr::ast(while(cond)expr) #&gt; \\- () #&gt; \\- `while #&gt; \\- `cond #&gt; \\- `expr ## And here within a call (infinite loop in this case) # eval(call(&quot;while&quot;, TRUE , 1)) 11.4 Capturing the current call Q: Compare and contrast update_model() with update.default(). A: Q: Why doesn’t write.csv(mtcars, &quot;mtcars.csv&quot;, row = FALSE) work? What property of argument matching has the original author forgotten? A: Q: Rewrite update.formula() to use R code instead of C code. A: Q: Sometimes it’s necessary to uncover the function that called the function that called the current function (i.e., the grandparent, not the parent). How can you use sys.call() or match.call() to find this function? A: 11.5 Pairlists Q: How are alist(a) and alist(a = ) different? Think about both the input and the output. A: Q: Read the documentation and source code for pryr::partial(). What does it do? How does it work? Read the documentation and source code for pryr::unenclose(). What does it do and how does it work? A: Q: The actual implementation of curve() looks more like curve3 &lt;- function(expr, xlim = c(0, 1), n = 100, env = parent.frame()) { env2 &lt;- new.env(parent = env) env2$x &lt;- seq(xlim[1], xlim[2], length = n) y &lt;- eval(substitute(expr), env2) plot(env2$x, y, type = &quot;l&quot;, ylab = deparse(substitute(expr))) } How does this approach differ from curve2() defined above? A: 11.6 Parsing and deparsing Q: What are the differences between quote() and expression()? A: Q: Read the help for deparse() and construct a call that deparse() and parse() do not operate symmetrically on. A: Q: Compare and contrast source() and sys.source(). A: Q: Modify simple_source() so it returns the result of every expression, not just the last one. A: Q: The code generated by simple_source() lacks source references. Read the source code for sys.source() and the help for srcfilecopy(), then modify simple_source() to preserve source references. You can test your code by sourcing a function that contains a comment. If successful, when you look at the function, you’ll see the comment and not just the source code. A: 11.7 Walking the AST with recursive functions Q: Why does logical_abbr() use a for loop instead of a functional like lapply()? A: Q: logical_abbr() works when given quoted objects, but doesn’t work when given an existing function, as in the example below. Why not? How could you modify logical_abbr() to work with functions? Think about what components make up a function. f &lt;- function(x = TRUE) { g(x + T) } logical_abbr(f) A: Q: Write a function called ast_type() that returns either “constant”, “name”, “call”, or “pairlist”. Rewrite logical_abbr(), find_assign(), and bquote2() to use this function with switch() instead of nested if statements. A: Q: Write a function that extracts all calls to a function. Compare your function to pryr::fun_calls(). A: Q: Write a wrapper around bquote2() that does non-standard evaluation so that you don’t need to explicitly quote() the input. A: Q: Compare bquote2() to bquote(). There is a subtle bug in bquote(): it won’t replace calls to functions with no arguments. Why? bquote(.(x)(), list(x = quote(f))) #&gt; .(x)() bquote(.(x)(1), list(x = quote(f))) #&gt; f(1) A: Q: Improve the base recurse_call() template to also work with lists of functions and expressions (e.g., as from parse(path_to_file)). A: "],
["domain-specific-languages.html", "12 Domain specific languages 12.1 HTML 12.2 LaTeX", " 12 Domain specific languages 12.1 HTML Q: The escaping rules for &lt;script&gt; and &lt;style&gt; tags are different: you don’t want to escape angle brackets or ampersands, but you do want to escape &lt;/script&gt; or &lt;/style&gt;. Adapt the code above to follow these rules. A: Q: The use of ... for all functions has some big downsides. There’s no input validation and there will be little information in the documentation or autocomplete about how they are used in the function. Create a new function that, when given a named list of tags and their attribute names (like below), creates functions which address this problem. list( a = c(&quot;href&quot;), img = c(&quot;src&quot;, &quot;width&quot;, &quot;height&quot;) ) All tags should get class and id attributes. A: Q: Currently the HTML doesn’t look terribly pretty, and it’s hard to see the structure. How could you adapt tag() to do indenting and formatting? A: 12.2 LaTeX Q: Add escaping. The special symbols that should be escaped by adding a backslash in front of them are \\, $, and %. Just as with HTML, you’ll need to make sure you don’t end up double-escaping. So you’ll need to create a small S3 class and then use that in function operators. That will also allow you to embed arbitrary LaTeX if needed. A: Q: Complete the DSL to support all the functions that plotmath supports. A: Q: There’s a repeating pattern in latex_env(): we take a character vector, do something to each piece, convert it to a list, and then convert the list to an environment. Write a function that automates this task, and then rewrite latex_env(). A: Q: Study the source code for dplyr. An important part of its structure is partial_eval() which helps manage expressions when some of the components refer to variables in the database while others refer to local R objects. Note that you could use very similar ideas if you needed to translate small R expressions into other languages, like JavaScript or Python. A: "],
["performance.html", "13 Performance 13.1 Microbenchmarking 13.2 Language performance 13.3 Implementations performance", " 13 Performance 13.1 Microbenchmarking Q: Instead of using microbenchmark(), you could use the built-in function system.time(). But system.time() is much less precise, so you’ll need to repeat each operation many times with a loop, and then divide to find the average time of each operation, as in the code below. n &lt;- 1:1e6 system.time(for (i in n) sqrt(x)) / length(n) system.time(for (i in n) x ^ 0.5) / length(n) How do the estimates from system.time() compare to those from microbenchmark()? Why are they different? Q: Here are two other ways to compute the square root of a vector. Which do you think will be fastest? Which will be slowest? Use microbenchmarking to test your answers. x ^ (1 / 2) exp(log(x) / 2) A: The second one looks more complex, but you never know…unless you test it. x &lt;- runif(100) microbenchmark::microbenchmark( sqrt(x), x ^ 0.5, x ^ (1 / 2), exp(log(x) / 2) ) #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq max neval cld #&gt; sqrt(x) 367 367 649.34 367 734.0 11364 100 a #&gt; x^0.5 3666 4033 4120.82 4033 4033.0 6599 100 b #&gt; x^(1/2) 4032 4033 4377.28 4399 4399.5 9898 100 b #&gt; exp(log(x)/2) 8064 8431 8666.02 8432 8798.0 14663 100 c Q: Use microbenchmarking to rank the basic arithmetic operators (+, -, *, /, and ^) in terms of their speed. Visualise the results. Compare the speed of arithmetic on integers vs. doubles. A: Since I am on a Windows system, where these short execution times are hard to measure, I just ran the following code on a linux and paste the results here: mb_integer &lt;- microbenchmark::microbenchmark( 1L + 1L, 1L - 1L, 1L * 1L, 1L / 1L, 1L ^ 1L, times = 1000000, control = list(order = &quot;random&quot;, warmup = 20000) mb_double &lt;- microbenchmark::microbenchmark( 1 + 1, 1 - 1, 1 * 1, 1 / 1, 1 ^ 1, times = 1000000, control = list(order = &quot;random&quot;, warmup = 20000) mb_integer # and got the following output: # Unit: nanoseconds # expr min lq mean median uq max neval # 1L + 1L 50 66 96.45262 69 73 7006051 1e+06 # 1L - 1L 52 69 88.76438 71 76 587594 1e+06 # 1L * 1L 51 68 88.51854 70 75 582521 1e+06 # 1L/1L 50 65 94.40669 68 74 7241972 1e+06 # 1L^1L 67 77 102.96209 84 92 574519 1e+06 mb_double # Unit: nanoseconds # expr min lq mean median uq max neval # 1 + 1 48 66 92.44331 69 75 7217242 1e+06 # 1 - 1 50 66 88.13654 68 77 625462 1e+06 # 1 * 1 48 66 135.88379 70 77 42974915 1e+06 # 1/1 48 65 87.11615 69 77 659032 1e+06 # 1^1 79 92 127.07686 103 135 641524 1e+06 To visualise and compare the results, we make some short spaghetties: mb_median &lt;- data.frame(operator = c(&quot;+&quot;, &quot;-&quot;, &quot;*&quot;, &quot;/&quot;, &quot;^&quot;), int = c(69, 71, 70, 68, 84), dbl = c(69, 68, 70, 69, 103), stringsAsFactors = FALSE) mb_median &lt;- tidyr::gather(mb_median, type, time, int, dbl) mb_median &lt;- dplyr::mutate(mb_median, type = factor(type, levels = c(&quot;int&quot;, &quot;dbl&quot;))) library(ggplot2) ggplot(mb_median, aes(x = type, y = time, group = operator, color = operator)) + geom_point(show.legend = FALSE) + geom_line(show.legend = FALSE, size = 1.5) + geom_label(aes(label = operator), show.legend = FALSE) + theme_minimal() + ylab(&quot;time in nanoseconds&quot;) + theme(axis.title.x = element_blank(), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 14), axis.text.y = element_text(size = 10)) + scale_y_continuous(breaks=seq(0, max(mb_median$time), 10)) Q: You can change the units in which the microbenchmark results are expressed with the unit parameter. Use unit = &quot;eps&quot; to show the number of evaluations needed to take 1 second. Repeat the benchmarks above with the eps unit. How does this change your intuition for performance? 13.2 Language performance Q: scan() has the most arguments (21) of any base function. About how much time does it take to make 21 promises each time scan is called? Given a simple input (e.g., scan(text = &quot;1 2 3&quot;, quiet = T)) what proportion of the total run time is due to creating those promises? A: According to the textbook every extra argument slows the function down by approximately 20 nanoseconds, which I can’t reproduce on my system: f5 &lt;- function(a = 1, b = 2, c = 4, d = 4, e = 5) NULL f6 &lt;- function(a = 1, b = 2, c = 4, d = 4, e = 5, f = 6) NULL f7 &lt;- function(a = 1, b = 2, c = 4, d = 4, e = 5, f = 6, g = 7) NULL f8 &lt;- function(a = 1, b = 2, c = 4, d = 4, e = 5, f = 6, g = 7, h = 8) NULL microbenchmark::microbenchmark(f5(), f6(), f7(), f8(), times = 10000) #&gt; Warning in microbenchmark::microbenchmark(f5(), f6(), f7(), f8(), times = #&gt; 10000): Could not measure a positive execution time for 1249 evaluations. #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq max neval cld #&gt; f5() 0 0 221.0407 1 367 718094 10000 a #&gt; f6() 0 0 249.4341 1 367 480562 10000 a #&gt; f7() 0 0 289.4435 1 367 494492 10000 a #&gt; f8() 0 1 340.5510 367 367 514286 10000 a However, for now we just assume that 20 nanosecods are correct and in kind of doubt, we recommend to benchmark this value individually. With this assumption we calculate 21 * 20 = 420 nanoseconds of extra time for each call of scan(). For a percentage, we first benchmark a simple call of scan(): (mb_prom &lt;- microbenchmark::microbenchmark( scan(text = &quot;1 2 3&quot;, quiet = T), times = 100000, unit = &quot;ns&quot;, control = list(warmup = 1000) )) #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq #&gt; scan(text = &quot;1 2 3&quot;, quiet = T) 30058 34824 45014.1 36657 39956 #&gt; max neval #&gt; 133242818 1e+05 mb_prom_median &lt;- broom::tidy(mb_prom)[2,]$median This lets us calculate, that ~1.15% of the median run time are caused by the extra arguments. Q: Read “Evaluating the Design of the R Language”. What other aspects of the R-language slow it down? Construct microbenchmarks to illustrate. Q: How does the performance of S3 method dispatch change with the length of the class vector? How does performance of S4 method dispatch change with number of superclasses? How about RC? Q: What is the cost of multiple inheritance and multiple dispatch on S4 method dispatch? Q: Why is the cost of name lookup less for functions in the base package? 13.3 Implementations performance Q: The performance characteristics of squish_ife(), squish_p(), and squish_in_place() vary considerably with the size of x. Explore the differences. Which sizes lead to the biggest and smallest differences? Q: Compare the performance costs of extracting an element from a list, a column from a matrix, and a column from a data frame. Do the same for rows. "],
["profiling.html", "14 Profiling 14.1 Has somebody already solved the problem? 14.2 Do as little as possible 14.3 Vectorise", " 14 Profiling 14.1 Has somebody already solved the problem? Q: What are faster alternatives to lm? Which are specifically designed to work with larger datasets? A: Within the Cran task view for HighPerformanceComputing we can find for example the speedglm package and it’s speedlm() function. We might not gain any performance improvements on small datasets: stopifnot(all.equal( coef(speedglm::speedlm(Sepal.Length ~ Sepal.Width + Species, data = iris)), coef(lm(Sepal.Length ~ Sepal.Width + Species, data = iris)))) microbenchmark::microbenchmark( speedglm::speedlm(Sepal.Length ~ Sepal.Width + Species, data = iris), lm(Sepal.Length ~ Sepal.Width + Species, data = iris) ) #&gt; Unit: microseconds #&gt; expr #&gt; speedglm::speedlm(Sepal.Length ~ Sepal.Width + Species, data = iris) #&gt; lm(Sepal.Length ~ Sepal.Width + Species, data = iris) #&gt; min lq mean median uq max neval cld #&gt; 1124.244 1217.168 2297.108 1300.743 1379.371 98657.030 100 a #&gt; 932.533 1044.150 1166.039 1095.652 1189.858 3520.454 100 a However on bigger datasets it can make a difference: eps &lt;- rnorm(100000) x1 &lt;- rnorm(100000, 5, 3) x2 &lt;- rep(c(&quot;a&quot;, &quot;b&quot;), 50000) y &lt;- 7 * x1 + (x2 == &quot;a&quot;) + eps td &lt;- data.frame(y = y, x1 = x1, x2 = x2, eps = eps) stopifnot(all.equal( coef(speedglm::speedlm(y ~ x1 + x2, data = td)), coef(lm(y ~ x1 + x2, data = td)))) microbenchmark::microbenchmark( speedglm::speedlm(y ~ x1 + x2, data = td), lm(y ~ x1 + x2, data = td) ) #&gt; Unit: milliseconds #&gt; expr min lq mean #&gt; speedglm::speedlm(y ~ x1 + x2, data = td) 52.68108 60.56802 77.98273 #&gt; lm(y ~ x1 + x2, data = td) 84.96633 96.51705 119.38080 #&gt; median uq max neval cld #&gt; 64.56005 67.87945 187.9931 100 a #&gt; 100.50945 111.25207 223.0764 100 b For further speedinprovements, you might consider switching your linear algebra libraries as stated in ?speedglm::speedlm The functions of class ‘speedlm’ may speed up the fitting of LMs to large data sets. High performances can be obtained especially if R is linked against an optimized BLAS, such as ATLAS. Note that there are many other opportunities mentioned in the task view, also some that make it possible to handle data which is not in memory. When it comes to pure speed a quick google search on r fastest lm provides a stackoverflow thread where someone already solved this problem for us… Q: What package implements a version of match() that’s faster for repeated lookups? How much faster is it? A: Again google gives a good recommendation for the searchterm r faster match: set.seed(1) table &lt;- 1L:100000L x &lt;- sample(table, 10000, replace=TRUE) stopifnot(all.equal(match(x, table), fastmatch::fmatch(x, table))) microbenchmark::microbenchmark( match(x, table), fastmatch::fmatch(x, table) ) #&gt; Unit: microseconds #&gt; expr min lq mean median #&gt; match(x, table) 15880.167 16143.3580 16917.3927 16492.5080 #&gt; fastmatch::fmatch(x, table) 429.977 481.1125 687.6512 637.0835 #&gt; uq max neval cld #&gt; 16993.048 22822.10 100 b #&gt; 825.313 1172.63 100 a On my laptop fastmatch::fmatch() is around 25 times as fast as match(). Q: List four functions (not just those in base R) that convert a string into a date time object. What are their strengths and weaknesses? A: At least these functions will do the trick: as.POSIXct(), as.POSIXlt(), strftime(), strptime(), lubridate::ymd_hms(). There might also be some in the timeseries packages xts or zoo and in anytime. An update on this will follow… Q: How many different ways can you compute a 1d density estimate in R? A: According to Deng and Wickham (2011) density estimation is implemented in over 20 R packages. Q: Which packages provide the ability to compute a rolling mean? A: Again google r rolling mean provides us with enough information and guides our attention on solutions in the following packages: zoo zoo::rollmean(1:10, 2, na.pad = TRUE, align = &quot;left&quot;) #&gt; [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 NA zoo::rollapply(1:10, 2, mean, fill = NA, align = &quot;left&quot;) #&gt; [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 NA TTR TTR::SMA(1:10, 2) #&gt; [1] NA 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 RcppRoll RcppRoll::roll_mean(1:10, n = 2, fill = NA, align = &quot;left&quot;) #&gt; [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 NA caTools caTools::runmean(1:10, k = 2, endrule = &quot;NA&quot;, align = &quot;left&quot;) #&gt; [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 NA Note that an exhaustive example on how to create a rolling mean function is provided in the textbook. Q: What are the alternatives to optim()? A: Depending on the usecase a lot of different options might be considered. For a general overview we would suggest the corresponding taskview on Optimization. 14.2 Do as little as possible Q: How do the results change if you compare mean() and mean.default() on 10,000 observations, rather than on 100? A: We start with 100 observations as shown in the textbook: x &lt;- runif(1e2) microbenchmark::microbenchmark( mean(x), mean.default(x) ) #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq max neval cld #&gt; mean(x) 2566 2933 3684.53 3299 3300 44721 100 b #&gt; mean.default(x) 733 734 1103.85 1100 1101 3666 100 a In case of 10000 observations we can observe that using mean.default() preserves only a small advantage over the use of mean(): x &lt;- runif(1e4) microbenchmark::microbenchmark( mean(x), mean.default(x), unit = &quot;ns&quot; ) #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq max neval cld #&gt; mean(x) 19428 19795 20634.33 20161 20528 44721 100 a #&gt; mean.default(x) 17228 17595 19157.02 17596 17962 122433 100 a When using even more observations - like in the next lines - it seems that mean.default doesn’t preserve anymore any advantage at all: x &lt;- runif(1e6) microbenchmark::microbenchmark( mean(x), mean.default(x), unit = &quot;ns&quot; ) #&gt; Unit: nanoseconds #&gt; expr min lq mean median uq max neval cld #&gt; mean(x) 1736402 1769759 1885408 1870563 1949923 2489318 100 a #&gt; mean.default(x) 1713675 1786620 1880863 1870196 1956705 2330597 100 a Q: The following code provides an alternative implementation of rowSums(). Why is it faster for this input? rowSums2 &lt;- function(df) { out &lt;- df[[1L]] if (ncol(df) == 1) return(out) for (i in 2:ncol(df)) { out &lt;- out + df[[i]] } out } df &lt;- as.data.frame( replicate(1e3, sample(100, 1e4, replace = TRUE)) ) system.time(rowSums(df)) #&gt; user system elapsed #&gt; 0.05 0.00 0.05 system.time(rowSums2(df)) #&gt; user system elapsed #&gt; 0.03 0.00 0.03 A: Q: What’s the difference between rowSums() and .rowSums()? A: .rowSums() is defined as .rowSums #&gt; function (x, m, n, na.rm = FALSE) #&gt; .Internal(rowSums(x, m, n, na.rm)) #&gt; &lt;bytecode: 0x000000001eda1f70&gt; #&gt; &lt;environment: namespace:base&gt; this means, that the internal rowSums() function is called via .Internal(). .Internal performs a call to an internal code which is built in to the R interpreter. The internal rowSums() is a complete different function than the “normal” rowSums() function. Of course (since they have the same name) in this case these functions are heavily related with each other: If we look into the source code of rowSums(), we see that it is a wrapper around the internal rowSums(). Just some input checkings, conversions and the special cases (complex numbers) are added: rowSums #&gt; function (x, na.rm = FALSE, dims = 1L) #&gt; { #&gt; if (is.data.frame(x)) #&gt; x &lt;- as.matrix(x) #&gt; if (!is.array(x) || length(dn &lt;- dim(x)) &lt; 2L) #&gt; stop(&quot;&#39;x&#39; must be an array of at least two dimensions&quot;) #&gt; if (dims &lt; 1L || dims &gt; length(dn) - 1L) #&gt; stop(&quot;invalid &#39;dims&#39;&quot;) #&gt; p &lt;- prod(dn[-(id &lt;- seq_len(dims))]) #&gt; dn &lt;- dn[id] #&gt; z &lt;- if (is.complex(x)) #&gt; .Internal(rowSums(Re(x), prod(dn), p, na.rm)) + (0+1i) * #&gt; .Internal(rowSums(Im(x), prod(dn), p, na.rm)) #&gt; else .Internal(rowSums(x, prod(dn), p, na.rm)) #&gt; if (length(dn) &gt; 1L) { #&gt; dim(z) &lt;- dn #&gt; dimnames(z) &lt;- dimnames(x)[id] #&gt; } #&gt; else names(z) &lt;- dimnames(x)[[1L]] #&gt; z #&gt; } #&gt; &lt;bytecode: 0x000000001a374778&gt; #&gt; &lt;environment: namespace:base&gt; Q: Make a faster version of chisq.test() that only computes the chi-square test statistic when the input is two numeric vectors with no missing values. You can try simplifying chisq.test() or by coding from the mathematical definition. A: Since chisq.test() has a relatively long source code, we try a new implementation from scratch: chisq.test2 &lt;- function(x, y){ # Input if(!is.numeric(x)){ stop(&quot;x must be numeric&quot;)} if(!is.numeric(y)){ stop(&quot;y must be numeric&quot;)} if(length(x) != length(y)){ stop(&quot;x and y must have the same length&quot;)} if(length(x) &lt;= 1){ stop(&quot;length of x must be greater one&quot;)} if(any(c(x,y) &lt; 0)){ stop(&quot;all entries of x and y must be greater or equal zero&quot;)} if(sum(complete.cases(x, y)) != length(x)){ stop(&quot;there must be no missing values in x and y&quot;)} if(any(is.null(c(x,y)))){ stop(&quot;entries of x and y must not be NULL&quot;)} # Help variables m &lt;- rbind(x, y) margin1 &lt;- rowSums(m) margin2 &lt;- colSums(m) n &lt;- sum(m) me &lt;- tcrossprod(margin1, margin2) / n # Output x_stat = sum((m - me)^2 / me) dof &lt;- (length(margin1) - 1) * (length(margin2) - 1) p &lt;- pchisq(x_stat, df = dof, lower.tail = FALSE) return(list(x_stat = x_stat, df = dof, `p-value` = p)) } We check if our new implementation returns the same results a &lt;- 21:25 b &lt;- c(21,23,25,27,29) m_test &lt;- cbind(a, b) chisq.test(m_test) #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: m_test #&gt; X-squared = 0.16194, df = 4, p-value = 0.9969 chisq.test2(a, b) #&gt; $x_stat #&gt; [1] 0.1619369 #&gt; #&gt; $df #&gt; [1] 4 #&gt; #&gt; $`p-value` #&gt; [1] 0.9968937 Finally we benchmark this implementation against a compiled version of itself and the original stats::chisq.test(): chisq.test2c &lt;- compiler::cmpfun(chisq.test2) microbenchmark::microbenchmark( chisq.test(m_test), chisq.test2(a, b), chisq.test2c(a, b) ) #&gt; Unit: microseconds #&gt; expr min lq mean median uq max neval #&gt; chisq.test(m_test) 65.982 68.914 77.14699 71.480 76.9785 229.834 100 #&gt; chisq.test2(a, b) 17.229 18.695 21.58368 20.161 23.8270 41.422 100 #&gt; chisq.test2c(a, b) 16.129 18.329 22.24348 19.978 23.6435 50.586 100 #&gt; cld #&gt; b #&gt; a #&gt; a Q: Can you make a faster version of table() for the case of an input of two integer vectors with no missing values? Can you use it to speed up your chi-square test? A: Q: Imagine you want to compute the bootstrap distribution of a sample correlation using cor_df() and the data in the example below. Given that you want to run this many times, how can you make this code faster? (Hint: the function has three components that you can speed up.) n &lt;- 1e6 df &lt;- data.frame(a = rnorm(n), b = rnorm(n)) cor_df &lt;- function(df, n) { i &lt;- sample(seq(n), n, replace = FALSE ) cor(df[i, , drop = FALSE])[2,1] # note also that in the last line the textbook says q[] instead of df[]. Since # this is probably just a typo, we changed this to df[]. } Is there a way to vectorise this procedure? A: The three components (mentioned in the questions hint) are: sampling of indices subsetting the data frame/conversion to matrix (or vector input) the cor() function itself. Since a run of lineprof like shown in the textbook suggests that as.matrix() within the cor() function is the biggest bottleneck, we start with that: n &lt;- 1e6 df &lt;- data.frame(a = rnorm(n), b = rnorm(n)) Remember the outgoing function: cor_df &lt;- function() { i &lt;- sample(seq(n), n, replace = FALSE) cor(df[i, , drop = FALSE])[2,1] } First we want to optimise the second line (without attention to the cor() function itself). Therefore we exclude the first line from our optimisation approaches and define i within the global environment: i &lt;- sample(seq(n), n) Then we define our approaches, check that their behaviour is correct and do the first benchmark: # old version cor_v1 &lt;- function() { cor(df[i, , drop = FALSE])[2,1] } # cbind instead of internal as.matrix cor_v2 &lt;- function() { m &lt;- cbind(df$a[i], df$b[i]) cor(m)[2, 1] } # cbind + vector subsetting of the output matrix cor_v3 &lt;- function() { m &lt;- cbind(df$a[i], df$b[i]) cor(m)[2] } # Use vector input within the cor function, so that no conversion is needed cor_v4 &lt;- function() { cor(df$a[i], df$b[i]) } # check if all return the same result cor_list &lt;- list(cor_v1, cor_v2, cor_v3, cor_v4) ulapply &lt;- function(X, FUN, ...) unlist(lapply(X, FUN, ...)) ulapply(cor_list, function(x) identical(x(), cor_v1())) #&gt; [1] TRUE TRUE TRUE TRUE # benchmark set.seed(1) microbenchmark::microbenchmark( cor_v1(), cor_v2(), cor_v3(), cor_v4() ) #&gt; Unit: milliseconds #&gt; expr min lq mean median uq max neval #&gt; cor_v1() 577.70494 639.77457 693.54709 657.90616 714.82927 897.5469 100 #&gt; cor_v2() 56.33607 66.16119 119.65917 91.91469 103.74398 328.4110 100 #&gt; cor_v3() 56.69566 86.69540 122.43481 92.29628 127.05618 310.4690 100 #&gt; cor_v4() 51.65435 53.57824 86.62202 57.03712 89.26371 273.1739 100 #&gt; cld #&gt; c #&gt; b #&gt; b #&gt; a According to the resulting medians, lower and upper quartiles of our benchmark all three new versions seem to provide more or less the same speed benefit (note that the maximum and mean can vary a lot for these approaches). Since the second version is most similar to the code we started, we implement this line into a second version of cor_df() (if this sounds too arbitrary, note that in the final solution we will come back to the vector input version anyway) and do a benchmark to get the overall speedup: cor_df2 &lt;- function() { i &lt;- sample(seq(n), n) m &lt;- cbind(df$a[i], df$b[i]) cor(m)[2, 1] } microbenchmark::microbenchmark( cor_df(), cor_df2() ) #&gt; Unit: milliseconds #&gt; expr min lq mean median uq max neval #&gt; cor_df() 637.16631 799.0702 870.8128 853.1700 921.7613 1259.3293 100 #&gt; cor_df2() 85.92746 118.3267 198.0209 159.6917 271.9692 424.2026 100 #&gt; cld #&gt; b #&gt; a Now we can focus on a speedup for the random generation of indices. (Note that a run of linepfrof suggests to optimize cbind(). However, after rewriting cor() to a version that only works with vector input, this step will be unnecessary anyway). We could try differnt approaches for the sequence generation within sample() (like seq(n), seq.int(n), seq_len(n), a:n) and a direct call of sample.int(). In the following, we will see, that sample.int() is always faster (since we don’t include the generation of the sequence into our benchmark). When we look into sample.int() we see that it calls two different internal sample versions depending on the input. Since in our usecase always the second version will be called, we also provide this version in our benchmark: seq_n &lt;- seq(n) microbenchmark::microbenchmark( sample(seq_n, n), sample.int(n, n), .Internal(sample(n, n, replace = FALSE, prob = NULL)) ) #&gt; Unit: milliseconds #&gt; expr min lq #&gt; sample(seq_n, n) 27.72120 29.33608 #&gt; sample.int(n, n) 16.38456 17.76539 #&gt; .Internal(sample(n, n, replace = FALSE, prob = NULL)) 17.00478 17.82661 #&gt; mean median uq max neval cld #&gt; 33.84649 30.76310 37.06283 64.79227 100 b #&gt; 20.49919 18.41036 22.72442 39.22095 100 a #&gt; 20.18159 18.53957 21.33441 37.93359 100 a The sample.int() versions give clearly the biggest improvement. Since the internal version doesn’t provide any clear improvement, but restricts the general scope of our function, we choose to implement sample.int() in a third version of cor_df() and benchmark our actual achievements: cor_df3 &lt;- function() { i &lt;- sample.int(n, n) m &lt;- cbind(df$a[i], df$b[i]) cor(m)[2, 1] } microbenchmark::microbenchmark( cor_df(), cor_df2(), cor_df3() ) #&gt; Unit: milliseconds #&gt; expr min lq mean median uq max neval #&gt; cor_df() 648.18844 751.7812 849.9867 800.1750 920.4157 1293.7189 100 #&gt; cor_df2() 85.96851 105.5772 173.8860 133.1477 220.8880 627.3645 100 #&gt; cor_df3() 75.20261 80.8077 172.3101 112.0728 209.8121 879.0678 100 #&gt; cld #&gt; b #&gt; a #&gt; a As a last step, we try to speedup the calculation of the pearson correlation coefficient. Since quite a lot of functionality is build into the stats::cor() function this seems like a reasonable approach. We try this by working with another cor() function from the WGNA package and an own implementation which should give a small improvement, because we use sum(x) / length(x) instead of mean(x) for internal calculations: #WGCNA version (matrix and vector). Note that I don&#39;t use a local setup which uses #the full potential of this function. For furter information see ?WGCNA::cor cor_df4m &lt;- function() { i &lt;- sample.int(n, n) m &lt;- cbind(df$a[i], df$b[i]) WGCNA::cor(m)[2] } cor_df4v &lt;- function() { i &lt;- sample.int(n, n) WGCNA::cor(df$a[i], df$b[i], quick = 1)[1] } #New implementation of underlying cor function #A definition can be found for example here #http://www.socscistatistics.com/tests/pearson/ cor2 &lt;- function(x, y){ xm &lt;- sum(x) / length(x) ym &lt;- sum(y) / length(y) x_xm &lt;- x - xm y_ym &lt;- y - ym numerator &lt;- sum((x_xm) * (y_ym)) denominator &lt;- sqrt(sum(x_xm^2)) * sqrt(sum(y_ym^2)) return(numerator / denominator) } cor2 &lt;- compiler::cmpfun(cor2) cor_df5 &lt;- function() { i &lt;- sample.int(n, n) cor2(df$a[i], df$b[i]) } In our final benchmark, we also include compiled verions of all our attempts: cor_df_c &lt;- compiler::cmpfun(cor_df) cor_df2_c &lt;- compiler::cmpfun(cor_df2) cor_df3_c &lt;- compiler::cmpfun(cor_df3) cor_df4m_c &lt;- compiler::cmpfun(cor_df4m) cor_df4v_c &lt;- compiler::cmpfun(cor_df4v) cor_df5_c &lt;- compiler::cmpfun(cor_df5) microbenchmark::microbenchmark( cor_df(), cor_df2(), cor_df3(), cor_df4m(), cor_df4v(), cor_df5(), cor_df_c(), cor_df2_c(), cor_df3_c(), cor_df4m_c(), cor_df4v_c(), cor_df5_c() ) #&gt; #&gt; Unit: milliseconds #&gt; expr min lq mean median uq max #&gt; cor_df() 7.885838 9.146994 12.739322 9.844561 10.447188 83.08044 #&gt; cor_df2() 1.951941 3.178821 6.101036 3.339742 3.485085 36.25404 #&gt; cor_df3() 1.288831 1.943510 4.353773 2.018105 2.145119 66.74022 #&gt; cor_df4m() 1.534061 2.156848 6.344015 2.243540 2.370921 234.17307 #&gt; cor_df4v() 1.639997 2.271949 5.755720 2.349477 2.453214 196.49897 #&gt; cor_df5() 1.281133 1.879911 6.263500 1.932696 2.064292 237.83135 #&gt; cor_df_c() 7.600654 9.337239 13.613901 10.009330 10.965688 41.17146 #&gt; cor_df2_c() 2.009124 2.878242 5.645224 3.298138 3.469871 34.29037 #&gt; cor_df3_c() 1.312291 1.926281 4.426418 1.986948 2.094532 87.97220 #&gt; cor_df4m_c() 1.548357 2.179025 3.306796 2.242991 2.355709 23.87195 #&gt; cor_df4v_c() 1.669689 2.255087 27.148456 2.341962 2.490419 2263.33230 #&gt; cor_df5_c() 1.284065 1.888892 3.884798 1.953774 2.078955 25.81583 #&gt; neval cld #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a #&gt; 100 a Our final solution benefits most from the switch from data frames to vectors. Working with sample.int gives only little improvement. Reimplementing and compiling a new correlation function adds only minimal speedup. To trust our final result we include a last check for similar return values: set.seed(1) cor_df() #&gt; [1] -0.001441277 set.seed(1) cor_df5_c() #&gt; [1] -0.001441277 Vectorisation of this problem seems rather difficult, since attempts of using matrix calculus, always depend on building and handling big matrices in the first place. We can for example rewrite our correlation function to work with matrices and build a new (vectorised) version of cor_df() on top of that cor2m &lt;- function(x, y){ n_row &lt;- nrow(x) xm &lt;- colSums(x) / n_row ym &lt;- colSums(y) / n_row x_xm &lt;- t(t(x) - xm) y_ym &lt;- t(t(y) - ym) numerator &lt;- colSums((x_xm) * (y_ym)) denominator &lt;- sqrt(colSums(x_xm^2)) * sqrt(colSums(y_ym^2)) return(numerator / denominator) } cor_df_v &lt;- function(i){ indices &lt;- replicate(i, sample.int(n, n), simplify = &quot;array&quot;) x &lt;- matrix(df$a[indices], ncol = i) y &lt;- matrix(df$b[indices], ncol = i) cor2m(x, y) } cor_df_v &lt;- compiler::cmpfun(cor_df_v) However this still doesn’t provide any improvement over the use of lapply(): ulapply2 &lt;- function(X, FUN, ...) unlist(lapply(X, FUN, ...), use.names = FALSE) microbenchmark::microbenchmark( cor_df5_c(), ulapply2(1:100, function(x) cor_df5_c()), cor_df_v(100) ) #&gt; Unit: milliseconds #&gt; expr min lq mean #&gt; cor_df5_c() 1.098219 1.148988 2.06762 #&gt; ulapply2(1:100, function(x) cor_df5_c()) 228.250897 233.052303 256.56849 #&gt; cor_df_v(100) 263.158918 272.988449 312.43802 #&gt; median uq max neval cld #&gt; 1.864515 2.030201 13.2325 100 a #&gt; 238.665277 247.184900 410.0768 100 b #&gt; 278.648158 291.164035 581.2834 100 c Further improvements can be achieved using parallelisation (for example via parallel::parLapply()) 14.3 Vectorise Q: The density functions, e.g., dnorm(), have a common interface. Which arguments are vectorised over? What does rnorm(10, mean = 10:1) do? A: We can see the interface of these functions via ?dnorm: dnorm(x, mean = 0, sd = 1, log = FALSE) pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) rnorm(n, mean = 0, sd = 1). They are vectorised over their numeric arguments, which is always the first argument (x, a, p, n), mean and sd. Note that it’s dangerous to supply a vector to n in the rnorm() function, since the behaviour will change, when n has length 1 (like in the second part of this question). rnorm(10, mean = 10:1) generates ten random numbers from different normal distributions. The normal distributions differ in their means. The first has mean ten, the second has mean nine, the third mean 8 etc. Q: Compare the speed of apply(x, 1, sum) with rowSums(x) for varying sizes of x. A: We compare regarding different sizes for square matrices: library(microbenchmark) dimensions &lt;- c(1e0, 1e1, 1e2, 1e3, 0.5e4, 1e4) matrices &lt;- lapply(dimensions, function(x) tcrossprod(rnorm(x), rnorm(x))) bench_rs &lt;- lapply(matrices, function(x) fivenum(microbenchmark(rowSums(x), unit = &quot;ns&quot;)$time)) bench_rs &lt;- data.frame(time = unlist(bench_rs), call = &quot;rowSums&quot;, stringsAsFactors = FALSE) bench_apply &lt;- lapply(matrices, function(x) fivenum(microbenchmark(apply(x, 1, sum), unit = &quot;ns&quot;)$time)) bench_apply &lt;- data.frame(time = unlist(bench_apply), call = &quot;apply&quot;, stringsAsFactors = FALSE) df &lt;- rbind(bench_rs, bench_apply) df$dimension &lt;- rep(dimensions, each = 5) df$aggr &lt;- rep(c(&quot;min&quot;, &quot;lq&quot;, &quot;median&quot;, &quot;uq&quot;, &quot;max&quot;), times = length(dimensions)) df$aggr_size &lt;- rep(c(1,2,3,2,1), times = length(dimensions)) df$group &lt;- paste(as.character(df$call), as.character(df$aggr), sep = &quot; &quot;) library(ggplot2) ggplot(df, aes(x = dimension, y = time, colour = call, group = group)) + geom_point() + geom_line(aes(linetype = factor(aggr_size, levels = c(&quot;3&quot;, &quot;2&quot;, &quot;1&quot;))), show.legend = FALSE) The graph is a good indicator to notice, that apply() is not “vectorised for performance”. Q: How can you use crossprod() to compute a weighted sum? How much faster is it than the naive sum(x * w)? A: We can just give the vectors to crossprod() which converts them to row- and columnvectors and then multiplies these. The result is the dot product which is also a weighted sum. a &lt;- rnorm(10) b &lt;- rnorm(10) sum(a * b) - crossprod(a, b)[1] #&gt; [1] 0 A benchmark of both alternatives for different vector lengths indicates, that the crossprod() variant is about 2.5 times faster than sum(): dimensions &lt;- c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 0.5e7, 1e7) xvector &lt;- lapply(dimensions, rnorm) weights &lt;- lapply(dimensions, rnorm) bench_sum &lt;- Map(function(x, y) fivenum(microbenchmark(sum(x * y))$time), xvector, weights) bench_sum &lt;- data.frame(time = unlist(bench_sum), call = &quot;sum&quot;, stringsAsFactors = FALSE) bench_cp &lt;- Map(function(x, y) fivenum(microbenchmark(crossprod(x, y)[1])$time), xvector, weights) bench_cp &lt;- data.frame(time = unlist(bench_cp), call = &quot;crossproduct&quot;, stringsAsFactors = FALSE) df &lt;- rbind(bench_sum, bench_cp) df$dimension &lt;- rep(dimensions, each = 5) df$aggr &lt;- rep(c(&quot;min&quot;, &quot;lq&quot;, &quot;median&quot;, &quot;uq&quot;, &quot;max&quot;), times = length(dimensions)) df$aggr_size &lt;- rep(c(1,2,3,2,1), times = length(dimensions)) df$group &lt;- paste(as.character(df$call), as.character(df$aggr), sep = &quot; &quot;) ggplot(df, aes(x = dimension, y = time, colour = call, group = group)) + geom_point() + geom_line(aes(linetype = factor(aggr_size, levels = c(&quot;3&quot;, &quot;2&quot;, &quot;1&quot;))), show.legend = FALSE) + scale_y_continuous(expand = c(0,0)) "],
["memory.html", "15 Memory 15.1 Object size 15.2 Memory profiling with lineprof 15.3 Modification in place", " 15 Memory 15.1 Object size Q: Repeat the analysis above for numeric, logical, and complex vectors. A: numeric: library(pryr) sizes &lt;- sapply(0:50, function(n) object_size(vector(&quot;numeric&quot;, n))) plot(0:50, sizes, xlab = &quot;Length&quot;, ylab = &quot;Size (bytes)&quot;, type = &quot;s&quot;) plot(0:50, sizes - 40, xlab = &quot;Length&quot;, ylab = &quot;Bytes excluding overhead&quot;, type = &quot;n&quot;) abline(h = 0, col = &quot;grey80&quot;) abline(h = c(8, 16, 32, 48, 64, 128), col = &quot;grey80&quot;) abline(a = 0, b = 4, col = &quot;grey90&quot;, lwd = 4) lines(sizes - 40, type = &quot;s&quot;) x &lt;- numeric(1e6) object_size(x) #&gt; 8 MB y &lt;- list(x, x, x) object_size(y) #&gt; 8 MB logical: sizes &lt;- sapply(0:50, function(n) object_size(vector(&quot;logical&quot;, n))) plot(0:50, sizes, xlab = &quot;Length&quot;, ylab = &quot;Size (bytes)&quot;, type = &quot;s&quot;) plot(0:50, sizes - 40, xlab = &quot;Length&quot;, ylab = &quot;Bytes excluding overhead&quot;, type = &quot;n&quot;) abline(h = 0, col = &quot;grey80&quot;) abline(h = c(8, 16, 32, 48, 64, 128), col = &quot;grey80&quot;) abline(a = 0, b = 4, col = &quot;grey90&quot;, lwd = 4) lines(sizes - 40, type = &quot;s&quot;) x &lt;- logical(1e6) object_size(x) #&gt; 4 MB y &lt;- list(x, x, x) object_size(y) #&gt; 4 MB complex: sizes &lt;- sapply(0:50, function(n) object_size(vector(&quot;complex&quot;, n))) plot(0:50, sizes, xlab = &quot;Length&quot;, ylab = &quot;Size (bytes)&quot;, type = &quot;s&quot;) plot(0:50, sizes - 40, xlab = &quot;Length&quot;, ylab = &quot;Bytes excluding overhead&quot;, type = &quot;n&quot;) abline(h = 0, col = &quot;grey80&quot;) abline(h = c(8, 16, 32, 48, 64, 128), col = &quot;grey80&quot;) abline(a = 0, b = 4, col = &quot;grey90&quot;, lwd = 4) lines(sizes - 40, type = &quot;s&quot;) x &lt;- complex(1e6) object_size(x) #&gt; 16 MB y &lt;- list(x, x, x) object_size(y) #&gt; 16 MB Q: If a data frame has one million rows, and three variables (two numeric, and one integer), how much space will it take up? Work it out from theory, then verify your work by creating a data frame and measuring its size. A: From the textbook we now that an integer`s size is 40 byte plus 4 byte per allocated entry, a numerics`s size is 40 byte plus 8 byte per allocated entry. So we can calculate the size via: object_size(df) = 1 * (40 + 4 * 1.000.000) + 2 * (40 + 8 * 1.000.000) = 20.000.120 bytes. And test this via: df &lt;- data.frame(int1 = integer(1000000), num1 = numeric(1000000), num2 = numeric(1000000)) as.integer(object_size(df)) #&gt; [1] 20000896 Note that we observe a small difference, because we didn’t include the costs for creating the data.frame() in our previous calculations. Q: Compare the sizes of the elements in the following two lists. Each contains basically the same data, but one contains vectors of small strings while the other contains a single long string. vec &lt;- lapply(0:50, function(i) c(&quot;ba&quot;, rep(&quot;na&quot;, i))) str &lt;- lapply(vec, paste0, collapse = &quot;&quot;) A: vec &lt;- lapply(0:50, function(i) c(&quot;ba&quot;, rep(&quot;na&quot;, i))) str &lt;- lapply(vec, paste0, collapse = &quot;&quot;) object_size(vec) #&gt; 13.4 kB object_size(str) #&gt; 8.74 kB object_size(vec, str) #&gt; 22.1 kB Q: Which takes up more memory: a factor (x) or the equivalent character vector (as.character(x))? Why? A: To be exact: it depends on the length of unique elements in relation to the overall length of the vector. In case of a long vector with only a few levels, the character takes approximately twice the memory of a factor: object_size(rep(letters[1:20], 1000)) #&gt; 161 kB object_size(factor(rep(letters[1:20], 1000))) #&gt; 81.5 kB That is, because a character allocates 8 bytes per entry (if the entry has less than 8 signs, otherwise roughly one byte per sign) and a factor equals an integer (allocates only 4 byte per entry) with a character vector attribute that contains the levels (unique elements) of the vector: object_size(1:20000) #&gt; 80 kB object_size(letters[1:20]) #&gt; 1.16 kB Of course the factor will allocate more memory, if all entries are unique: object_size(letters[1:20]) #&gt; 1.16 kB object_size(factor(letters[1:20])) #&gt; 1.65 kB Q: Explain the difference in size between 1:5 and list(1:5). A: An empty list needs 40 bytes. For each entry 8 bytes are added (note that for short lists memory is allocated in chunks, similar as explained for integers in the textbook). We can see this via: object_size(vector(&quot;list&quot;,0)) #&gt; 40 B object_size(vector(&quot;list&quot;,1)) #&gt; 48 B Since c(1:5) needs 48 bytes, list(1:5) takes 96. So in general the cost for saving atomics within a list is 40 bytes for the list plus 8 bytes per atomic/listentry. 15.2 Memory profiling with lineprof Q: When the input is a list, we can make a more efficient as.data.frame() by using special knowledge. A data frame is a list with class data.frame and row.names attribute. row.names is either a character vector or vector of sequential integers, stored in a special format created by .set_row_names(). This leads to an alternative as.data.frame(): to_df &lt;- function(x) { class(x) &lt;- &quot;data.frame&quot; attr(x, &quot;row.names&quot;) &lt;- .set_row_names(length(x[[1]])) x } What impact does this function have on read_delim()? What are the downsides of this function? Q: Line profile the following function with torture = TRUE. What is surprising? Read the source code of rm() to figure out what’s going on. f &lt;- function(n = 1e5) { x &lt;- rep(1, n) rm(x) } 15.3 Modification in place Q: The code below makes one duplication. Where does it occur and why? (Hint: look at refs(y).) x &lt;- data.frame(matrix(runif(100 * 1e4), ncol = 100)) medians &lt;- vapply(x, median, numeric(1)) y &lt;- as.list(x) for(i in seq_along(medians)) { y[[i]] &lt;- y[[i]] - medians[i] } A: It occurs in the first iteration of the for loop. refs(y) is 2 before the for loop, because y is created via as.list(), which is not a primitive and so sets the refs counter up to two. Therefore R makes a copy, refs(y) becomes 1 and the following modifications will occur in place. The following code illustrates this behaviour, when run in the RGui. (Note that refs() will always return 2, when run in RStudio, as stated in the textbook. Note also, that you could detect this behaviour with the tracemem() function). library(pryr) rm(list = ls(all = TRUE)) x &lt;- data.frame(matrix(runif(100 * 1e4), ncol = 4)) medians &lt;- vapply(x, median, numeric(1)) y &lt;- as.list(x) is.primitive(as.list) # [1] FALSE for(i in seq_along(medians)) { print(c(address(y), refs(y))) y[[i]] &lt;- y[[i]] - medians[i] } # [1] &quot;0x46c4a98&quot; &quot;2&quot; # [1] &quot;0x11de30c8&quot; &quot;1&quot; # [1] &quot;0x11de30c8&quot; &quot;1&quot; # [1] &quot;0x11de30c8&quot; &quot;1&quot; Q: The implementation of as.data.frame() in the previous section has one big downside. What is it and how could you avoid it? "],
["rcpp.html", "16 Rcpp 16.1 Getting started with C++ 16.2 Missing values 16.3 The STL", " 16 Rcpp 16.1 Getting started with C++ Q: With the basics of C++ in hand, it’s now a great time to practice by reading and writing some simple C++ functions. For each of the following functions, read the code and figure out what the corresponding base R function is. You might not understand every part of the code yet, but you should be able to figure out the basics of what the function does. double f1(NumericVector x) { int n = x.size(); double y = 0; for(int i = 0; i &lt; n; ++i) { y += x[i] / n; } return y; } NumericVector f2(NumericVector x) { int n = x.size(); NumericVector out(n); out[0] = x[0]; for(int i = 1; i &lt; n; ++i) { out[i] = out[i - 1] + x[i]; } return out; } bool f3(LogicalVector x) { int n = x.size(); for(int i = 0; i &lt; n; ++i) { if (x[i]) return true; } return false; } int f4(Function pred, List x) { int n = x.size(); for(int i = 0; i &lt; n; ++i) { LogicalVector res = pred(x[i]); if (res[0]) return i + 1; } return 0; } NumericVector f5(NumericVector x, NumericVector y) { int n = std::max(x.size(), y.size()); NumericVector x1 = rep_len(x, n); NumericVector y1 = rep_len(y, n); NumericVector out(n); for (int i = 0; i &lt; n; ++i) { out[i] = std::min(x1[i], y1[i]); } return out; } A: The R equivalents are: f1: mean() f2: cumsum() f3: any() f4: Position() f5: pmin() Q: To practice your function writing skills, convert the following functions into C++. For now, assume the inputs have no missing values. all() cppFunction(&#39; bool allC(LogicalVector x) { int n = x.size(); for(int i = 0; i &lt; n; ++i) { if (!x[i]) return false; } return true; }&#39;) cumprod(), cummin(), cummax(). NumericVector cumprodC(NumericVector x) { int n = x.size(); NumericVector out(n); out[0] = x[0]; for(int i = 1; i &lt; n; ++i) { out[i] = out[i - 1] * x[i]; } return out; }&#39;) cppFunction(&#39; NumericVector cumminC(NumericVector x) { int n = x.size(); NumericVector out(n); out[0] = x[0]; for(int i = 1; i &lt; n; ++i) { out[i] = std::min(out[i - 1], x[i]); } return out; }&#39;) cppFunction(&#39; NumericVector cummaxC(NumericVector x) { int n = x.size(); NumericVector out(n); out[0] = x[0]; for(int i = 1; i &lt; n; ++i) { out[i] = std::max(out[i - 1], x[i]); } return out; }&#39;) diff(). Start by assuming lag 1, and then generalise for lag n. cppFunction(&#39; NumericVector diffC(NumericVector x){ int n = x.size(); NumericVector out(n - 1); for(int i = 1; i &lt; n; i++){ out[i - 1] = x[i] - x[i - 1]; } return out ; }&#39;) cppFunction(&#39; NumericVector difflagC(NumericVector x, int lag){ int n = x.size(); NumericVector out(n - lag); for(int i = lag; i &lt; n; i++){ out[i - lag] = x[i] - x[i - lag]; } return out; }&#39;) range. cppFunction(&#39;NumericVector rangeC(NumericVector x){ double omin, omax; int n = x.size(); NumericVector out(2); omin = x[0]; omax = x[0]; for(int i = 1; i &lt; n; i++){ omin = std::min(x[i], omin); omax = std::max(x[i], omax); } out[0] = omin; out[1] = omax; return out; }&#39;) var. Read about the approaches you can take on wikipedia. Whenever implementing a numerical algorithm, it’s always good to check what is already known about the problem. 16.2 Missing values Rewrite any of the functions from the first exercise to deal with missing values. If na.rm is true, ignore the missing values. If na.rm is false, return a missing value if the input contains any missing values. Some good functions to practice with are min(), max(), range(), mean(), and var(). cppFunction(&#39;NumericVector minC(NumericVector x, bool narm){ int n = x.size(); LogicalVector index = is_na(x); NumericVector omin(1); bool na_check = false; bool na_check_all = true; for(int i; i&lt;n; i++){ if (index[i]) na_check = true; } for(int i; i&lt;n; i++){ if (!index[i]) na_check_all = false; } if (narm) { for(int i = n-1; i &gt;= 0; i--){ if (!index[i]) omin[0] = x[i]; } for(int i = 1; i &lt; n; i++) { if (!index[i]) omin[0] = std::min(x[i], omin[0]); } if (na_check_all) { omin[0] = NA_REAL; } } else if (na_check) { omin[0] = NA_REAL; } else { omin[0] = x[0]; for(int i = 1; i &lt; n; i++){ omin = std::min(x[i], omin[0]); } } return omin; }&#39;) cppFunction(&#39;NumericVector maxC(NumericVector x, bool narm){ int n = x.size(); LogicalVector index = is_na(x); NumericVector omax(1); bool na_check = false; bool na_check_all = true; for(int i; i&lt;n; i++){ if (index[i]) na_check = true; } for(int i; i&lt;n; i++){ if (!index[i]) na_check_all = false; } if (narm) { for(int i = n-1; i &gt;= 0; i--){ if (!index[i]) omax[0] = x[i]; } for(int i = 1; i &lt; n; i++) { if (!index[i]) omax[0] = std::max(x[i], omax[0]); } if (na_check_all) { omax[0] = NA_REAL; } } else if (na_check) { omax[0] = NA_REAL; } else { omax[0] = x[0]; for(int i = 1; i &lt; n; i++){ omax = std::max(x[i], omax[0]); } } return omax; }&#39;) cppFunction(&#39;NumericVector rangeC(NumericVector x, bool narm){ int n = x.size(); LogicalVector index = is_na(x); NumericVector out(2); NumericVector omin(1); NumericVector omax(1); bool na_check = false; bool na_check_all = true; for(int i; i&lt;n; i++){ if (index[i]) na_check = true; } for(int i; i&lt;n; i++){ if (!index[i]) na_check_all = false; } /* Minimum */ if (narm) { for(int i = n-1; i &gt;= 0; i--){ if (!index[i]) omin[0] = x[i]; } for(int i = 1; i &lt; n; i++) { if (!index[i]) omin[0] = std::min(x[i], omin[0]); } if (na_check_all) { omin[0] = NA_REAL; } } else if (na_check) { omin[0] = NA_REAL; } else { omin[0] = x[0]; for(int i = 1; i &lt; n; i++){ omin = std::min(x[i], omin[0]); } } /* Maximum */ if (narm) { for(int i = n-1; i &gt;= 0; i--){ if (!index[i]) omax[0] = x[i]; } for(int i = 1; i &lt; n; i++) { if (!index[i]) omax[0] = std::max(x[i], omax[0]); } if (na_check_all) { omax[0] = NA_REAL; } } else if (na_check) { omax[0] = NA_REAL; } else { omax[0] = x[0]; for(int i = 1; i &lt; n; i++){ omax = std::max(x[i], omax[0]); } } out[0] = omin[0]; out[1] = omax[0]; return out; }&#39;) cppFunction(&#39;NumericVector meanC(NumericVector x, bool narm){ int n = x.size(); LogicalVector index = is_na(x); bool na_check = false; bool na_check_all = true; int n_corrected = 0; NumericVector out(1); for(int i; i&lt;n; i++){ if (index[i]) na_check = true; } for(int i; i&lt;n; i++){ if (!index[i]) na_check_all = false; } for(int i; i&lt;n; i++){ if (!index[i]) n_corrected++; } /* narm = T */ if (narm){ if (na_check_all) { out[0] = NA_REAL; } else { out[0] = 0; for(int i = 0; i &lt; n; ++i) { if (!index[i]) out[0] += x[i] / n_corrected; } } } /* narm = F */ if (!narm){ if (na_check) { out[0] = NA_REAL; } else { for(int i = 0; i &lt; n; ++i) { out[0] += x[i] / n; } } } return out; }&#39;) Rewrite cumsum() and diff() so they can handle missing values. Note that these functions have slightly more complicated behaviour. cppFunction(&#39;NumericVector cumsumC(NumericVector x) { int n = x.size(); NumericVector out(n); LogicalVector index = is_na(x); out[0] = x[0]; for(int i = 1; i &lt; n; ++i) { if (index[i - 1]) { out[i] = NA_REAL; } else{ out[i] = out[i - 1] + x[i]; } } return out; }&#39;) cppFunction(&#39; NumericVector difflagC(NumericVector x, int lag){ int n = x.size(); NumericVector out(n - lag); LogicalVector index = is_na(x); for(int i = lag; i &lt; n; i++){ if ((index[i]) || (index[i - lag])) { out[i - lag] = NA_REAL; } else { out[i - lag] = x[i] - x[i - lag]; } } return out; }&#39;) 16.3 The STL To practice using the STL algorithms and data structures, implement the following using R functions in C++, using the hints provided: median.default() using partial_sort. #include &lt;algorithm&gt; #include &lt;Rcpp.h&gt; using namespace Rcpp; // [[Rcpp::export]] double medianC(NumericVector x) { int n = x.size(); double out; if (n % 2 == 0){ std::partial_sort (x.begin(), x.begin() + n / 2 + 1, x.end()); out = (x[n / 2 - 1] + x[n / 2]) / 2; } else { std::partial_sort (x.begin(), x.begin() + (n + 1) / 2, x.end()); out = x[(n + 1) / 2 - 1]; } return out; } %in% using unordered_set and the find() or count() methods. unique() using an unordered_set (challenge: do it in one line!). // [[Rcpp::plugins(cpp11)]] #include &lt;Rcpp.h&gt; #include &lt;unordered_set&gt; using namespace Rcpp; // [[Rcpp::export]] NumericVector uniqueC(NumericVector x) { std::unordered_set&lt;int&gt; seen; int n = x.size(); LogicalVector dup(n); std::vector&lt;double&gt; out; for (int i = 0; i &lt; n; ++i) { dup[i] = !seen.insert(x[i]).second; if (!dup[i]) { out.push_back(x[i]); } } return wrap(out); } min() using std::min(), or max() using std::max(). #include &lt;Rcpp.h&gt; using namespace Rcpp; // [[Rcpp::export]] double minC(NumericVector x){ int n = x.size(); double out; for (int i = 0; i &lt; n; i++){ out = std::min(out, x[i]); } return out; } which.min() using min_element, or which.max() using max_element. #include &lt;Rcpp.h&gt; #include &lt;algorithm&gt; #include &lt;iterator&gt; using namespace Rcpp; // [[Rcpp::export]] double which_minC(NumericVector x){ int out; out = std::distance(x.begin(),std::min_element(x.begin(),x.end())); out++; return out; } setdiff(), union(), and intersect() for integers using sorted ranges and set_union, set_intersection and set_difference. "],
["testchapter.html", "17 Testchapter", " 17 Testchapter "],
["s3-1.html", "18 S3 18.1 Basics 18.2 Classes 18.3 Generics and methods 18.4 Method dispatch 18.5 Inheritance 18.6 Dispatch details", " 18 S3 18.1 Basics The most important S3 objects in base R are factors, data frames, and date/times (Dates, POSIXct, POSIXlt). You’ve already seen the attributes and base type that factors are built on. What base types and attributes are the others built on? Describe the difference in behaviour in these two calls. some_days &lt;- as.Date(&quot;2017-01-31&quot;) + sample(10, 5) mean(some_days) #&gt; [1] &quot;2017-02-05&quot; mean(unclass(some_days)) #&gt; [1] 17202.8 Draw a Venn diagram illustrating the relationships between functions, generics, and methods. What does the as.data.frame.data.frame() method do? Why is it confusing? How should you avoid this confusion in your own code? What does the following code return? What base type is built on? What attributes does it use? x &lt;- ecdf(rpois(100, 10)) x #&gt; Empirical CDF #&gt; Call: ecdf(rpois(100, 10)) #&gt; x[1:17] = 2, 3, 4, ..., 17, 18 18.2 Classes Categorise the objects returned by lm(), factor(), table(), as.Date(), ecdf(), ordered(), I() into “vector”, “scalar”, and “other”. Write a constructor for difftime objects. What base type are they built on? What attributes do they use? You’ll need to consult the documentation, read some code, and perform some experiments. Write a constructor for data.frame objects. What base type is a data frame built on? What attributes does it use? What are the restrictions placed on the individual elements? What about the names? Enhance our factor() helper to have better behaviour when one or more values is not found in levels. What does base::factor() do in this situation? Carefully read the source code of factor(). What does it do that our constructor does not? What would a constructor function for lm objects, new_lm(), look like? Why is a constructor function less useful for linear models? 18.3 Generics and methods Read the source code for t() and t.test() and confirm that t.test() is an S3 generic and not an S3 method. What happens if you create an object with class test and call t() with it? Why? x &lt;- structure(1:10, class = &quot;test&quot;) t(x) #&gt; #&gt; One Sample t-test #&gt; #&gt; data: x #&gt; t = 5.7446, df = 9, p-value = 0.0002782 #&gt; alternative hypothesis: true mean is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 3.334149 7.665851 #&gt; sample estimates: #&gt; mean of x #&gt; 5.5 Carefully read the documentation for UseMethod() and explain why the following code returns the results that it does. What two usual rules of function evaluation does UseMethod() violate? g &lt;- function(x) { x &lt;- 10 y &lt;- 10 UseMethod(&quot;g&quot;) } g.default &lt;- function(x) c(x = x, y = y) x &lt;- 1 y &lt;- 1 g(x) #&gt; x y #&gt; 1 10 18.4 Method dispatch Which base generic has the greatest number of defined methods? Explain what is happening in the following code. generic2 &lt;- function(x) UseMethod(&quot;generic2&quot;) generic2.a1 &lt;- function(x) &quot;a1&quot; generic2.a2 &lt;- function(x) &quot;a2&quot; generic2.b &lt;- function(x) { class(x) &lt;- &quot;a1&quot; NextMethod() } generic2(S3::new_s3_scalar(class = c(&quot;b&quot;, &quot;a2&quot;))) #&gt; [1] &quot;a2&quot; 18.5 Inheritance The ordered class is a subclass of factor, but it’s implemented in a very ad hoc way in base R. Implement it in a principled way by building a constructor and an as_ordered generic. f1 &lt;- factor(&quot;a&quot;, c(&quot;a&quot;, &quot;b&quot;)) as.factor(f1) #&gt; [1] a #&gt; Levels: a b as.ordered(f1) # loses levels #&gt; [1] a #&gt; Levels: a 18.6 Dispatch details Math.difftime() is more complicated than I described. Why? "],
["s4-1.html", "19 S4 19.1 Classes 19.2 Generics and methods 19.3 Method dispatch 19.4 S4 and existing code", " 19 S4 19.1 Classes What happens if you define a new S4 class that doesn’t “contain” an existing class? (Hint: read about virtual classes in ?setClass.) Imagine you were going to rewrite ordered factors, dates, and data frames in S4. Sketch out the setClass() calls that you would use to define the classes. 19.2 Generics and methods In the defintion of the generic, why is it necessary to repeat the name of the generic twice? What happens if you define a method with different argument names to the generic? What other ways can you find help for a method? Read ?&quot;?&quot; and summarise the details. 19.3 Method dispatch Take the last example which shows multiple dispatch over two classes that use multiple inheritance. What happens if you define a method for all terminal classes? Why does method dispatch not save us much work here? 19.4 S4 and existing code 19.4.1 Exercises "]
]
